# ü§ñ Fase B2: AI Agent (LLM Trading)

## Documento de Implementaci√≥n

**Versi√≥n:** 1.0  
**Duraci√≥n estimada:** 1 semana  
**Dependencias:** Fase B1 (Estrategias Swing) completada  
**Prerrequisito:** ETF Momentum funcional, interfaces TradingStrategy y Signal definidas

---

## 1. Contexto y Motivaci√≥n

### 1.1 Situaci√≥n Actual

La Fase B1 ha establecido:
- Interfaz `TradingStrategy` ABC con m√©todos `generate_signals()` y `should_close()`
- Dataclass `Signal` con estructura completa para se√±ales de trading
- `StrategyRegistry` para registro din√°mico de estrategias
- `StrategyRunner` para ejecuci√≥n coordinada
- ETF Momentum como estrategia base funcionando en r√©gimen BULL

### 1.2 Objetivo de Esta Fase

Implementar un **AI Agent basado en LLM** (inicialmente Claude) que:
- Toma decisiones de trading basadas en contexto completo del mercado
- Opera con diferentes niveles de autonom√≠a (conservative/moderate/experimental)
- Se integra como otra estrategia m√°s en el sistema existente
- Es intercambiable (Claude ‚Üî GPT-4 ‚Üî Gemini) mediante interfaces comunes

```
FILOSOF√çA CLAVE:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
1. El LLM es UNA estrategia m√°s, no un sistema paralelo
   - Implementa TradingStrategy ABC
   - Genera Signal como cualquier otra estrategia
   - Se registra en StrategyRegistry

2. Autonom√≠a como par√°metro, no como dise√±o diferente
   - conservative: Solo informaci√≥n, humano decide
   - moderate: Sugiere con sizing, confirmaci√≥n requerida
   - experimental: Ejecuta dentro de l√≠mites estrictos

3. Context is King
   - El LLM recibe TODO el contexto: r√©gimen, portfolio, indicadores, noticias
   - Mejores decisiones = mejor contexto, no mejor modelo

4. Trazabilidad completa
   - Cada decisi√≥n incluye reasoning
   - Todo se registra en metrics.trades
   - A/B testing con otras estrategias
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
```

### 1.3 Decisiones de Dise√±o

| Decisi√≥n | Justificaci√≥n |
|----------|---------------|
| ABC para LLMAgent | Contrato uniforme, f√°cil swap Claude ‚Üî GPT-4 |
| Implementa TradingStrategy | Integraci√≥n nativa con sistema existente |
| Dataclass AgentDecision | Output estructurado, serializable, tipado |
| Prompts por autonom√≠a | Mismo c√≥digo, diferente comportamiento por config |
| Context builder modular | F√°cil a√±adir/quitar fuentes de contexto |
| Cache de decisiones | Evita llamadas repetidas, respeta rate limits |
| Async by default | No bloquea mientras espera respuesta del LLM |

### 1.4 Por Qu√© Claude Primero

| Raz√≥n | Explicaci√≥n |
|-------|-------------|
| API estable | Anthropic API bien documentada y estable |
| Sonnet costo-efectivo | Buen balance rendimiento/precio para trading |
| Context window amplio | 200K tokens permite contexto extenso |
| Structured output | Buen seguimiento de instrucciones JSON |
| Espa√±ol nativo | Mejor para tu workflow mixto ES/EN |

### 1.5 Flujo de Decisi√≥n del AI Agent

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        AI AGENT DECISION FLOW                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                          ‚îÇ
‚îÇ  1. CONTEXT GATHERING                                                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                                                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   R√©gimen    ‚îÇ  ‚îÇ  Portfolio   ‚îÇ  ‚îÇ  Indicadores ‚îÇ             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   (HMM)      ‚îÇ  ‚îÇ  (posiciones)‚îÇ  ‚îÇ  (t√©cnicos)  ‚îÇ             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ                 ‚îÇ                 ‚îÇ                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                      ‚ñº                                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ               ‚îÇ   Context    ‚îÇ                                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ               ‚îÇ   Builder    ‚îÇ                                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                      ‚îÇ                                             ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                         ‚îÇ                                                ‚îÇ
‚îÇ  2. PROMPT CONSTRUCTION ‚îÇ                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                      ‚ñº                                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ   Autonomy Level       ‚îÇ                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ   (conservative/       ‚îÇ                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ    moderate/           ‚îÇ                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ    experimental)       ‚îÇ                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                     ‚îÇ                                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                     ‚ñº                                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ    System Prompt       ‚îÇ +   ‚îÇ   User Context      ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ    (por autonom√≠a)     ‚îÇ     ‚îÇ   (datos mercado)   ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                ‚îÇ                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                   ‚îÇ                                      ‚îÇ
‚îÇ  3. LLM INFERENCE                 ‚îÇ                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                                ‚ñº                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ     Claude API        ‚îÇ                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ     (Sonnet 4)        ‚îÇ                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                ‚îÇ                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                ‚ñº                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ   Response Parser     ‚îÇ                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ   (JSON ‚Üí Decision)   ‚îÇ                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                ‚îÇ                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                   ‚îÇ                                      ‚îÇ
‚îÇ  4. OUTPUT                        ‚îÇ                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                                ‚ñº                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ   AgentDecision       ‚îÇ                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ   ‚îú‚îÄ actions: Signal[]‚îÇ                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ   ‚îú‚îÄ reasoning        ‚îÇ                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ   ‚îú‚îÄ market_view      ‚îÇ                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ   ‚îî‚îÄ confidence       ‚îÇ                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                ‚îÇ                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ   Signal[]            ‚îÇ‚óÑ‚îÄ‚îÄ Compatible con     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ   (para Strategy      ‚îÇ    sistema estrategias‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ    Runner)            ‚îÇ                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 2. Objetivos de la Fase

| Objetivo | Criterio de √âxito |
|----------|-------------------|
| Interfaz LLMAgent ABC | Definida con todos los m√©todos abstractos |
| AgentDecision dataclass | Estructura completa con validaciones |
| AgentContext dataclass | Contexto estructurado para el LLM |
| Sistema de prompts | 3 niveles de autonom√≠a implementados |
| ClaudeAgent funcional | Genera decisiones v√°lidas con Claude API |
| Integraci√≥n TradingStrategy | `AIAgentStrategy` usa `LLMAgent` internamente |
| Config YAML | Autonom√≠a y modelo configurables |
| Tests unitarios | > 80% cobertura en `src/agents/llm/` |
| Rate limiting | Respeta l√≠mites de API de Anthropic |

---

## 3. Arquitectura del AI Agent

### 3.1 Diagrama de Componentes

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                              AI AGENT SYSTEM                                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                                  ‚îÇ
‚îÇ  config/agents.yaml                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                             ‚îÇ
‚îÇ  ‚îÇ ai_agent:                       ‚îÇ                                             ‚îÇ
‚îÇ  ‚îÇ   active: "claude"              ‚îÇ                                             ‚îÇ
‚îÇ  ‚îÇ   autonomy_level: "moderate"    ‚îÇ                                             ‚îÇ
‚îÇ  ‚îÇ   models:                       ‚îÇ                                             ‚îÇ
‚îÇ  ‚îÇ     claude:                     ‚îÇ                                             ‚îÇ
‚îÇ  ‚îÇ       model: "claude-sonnet-4"  ‚îÇ                                             ‚îÇ
‚îÇ  ‚îÇ       max_tokens: 2000          ‚îÇ                                             ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                             ‚îÇ
‚îÇ              ‚îÇ                                                                   ‚îÇ
‚îÇ              ‚ñº                                                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                             ‚îÇ
‚îÇ  ‚îÇ       LLMAgentFactory           ‚îÇ                                             ‚îÇ
‚îÇ  ‚îÇ       .create_agent()           ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Lee config, instancia agente       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                             ‚îÇ
‚îÇ              ‚îÇ                                                                   ‚îÇ
‚îÇ      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                                           ‚îÇ
‚îÇ      ‚ñº               ‚ñº                                                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                  ‚îÇ
‚îÇ  ‚îÇ   Claude   ‚îÇ  ‚îÇ   GPT-4    ‚îÇ  ‚îÇ   Gemini   ‚îÇ  ‚óÑ‚îÄ‚îÄ Futuro                      ‚îÇ
‚îÇ  ‚îÇ   Agent    ‚îÇ  ‚îÇ   Agent    ‚îÇ  ‚îÇ   Agent    ‚îÇ                                  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                  ‚îÇ
‚îÇ        ‚îÇ                                                                         ‚îÇ
‚îÇ        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ                        ‚îÇ                                                     ‚îÇ   ‚îÇ
‚îÇ                        ‚ñº                                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ   ‚îÇ
‚îÇ  ‚îÇ     LLMAgent (ABC)              ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ     AgentDecision            ‚îÇ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ     - agent_id                  ‚îÇ        ‚îÇ     (dataclass output)        ‚îÇ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ     - decide()                  ‚îÇ        ‚îÇ     - actions: list[Signal]   ‚îÇ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ     - get_system_prompt()       ‚îÇ        ‚îÇ     - reasoning               ‚îÇ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ     - build_context()           ‚îÇ        ‚îÇ     - market_view             ‚îÇ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ     - confidence              ‚îÇ‚îÇ   ‚îÇ
‚îÇ                        ‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ   ‚îÇ
‚îÇ                        ‚îÇ                                                     ‚îÇ   ‚îÇ
‚îÇ                        ‚ñº                                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    AIAgentStrategy              ‚îÇ                                         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    (TradingStrategy impl)       ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Adapta LLMAgent al sistema     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    - generate_signals()         ‚îÇ          de estrategias                 ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    - should_close()             ‚îÇ                                         ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                         ‚îÇ   ‚îÇ
‚îÇ                        ‚îÇ                                                     ‚îÇ   ‚îÇ
‚îÇ                        ‚ñº                                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    StrategyRegistry             ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Se registra como estrategia    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    (de Fase B1)                 ‚îÇ          m√°s en el sistema              ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                         ‚îÇ   ‚îÇ
‚îÇ                                                                              ‚îÇ   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 3.2 Integraci√≥n con Sistema Existente

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    INTEGRACI√ìN AI AGENT ‚Üî STRATEGY SYSTEM                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ                        StrategyRunner (Fase B1)                         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                        .run_all_active()                                ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                      ‚îÇ                                         ‚îÇ
‚îÇ          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îÇ
‚îÇ          ‚îÇ                          ‚îÇ                        ‚îÇ                ‚îÇ
‚îÇ          ‚ñº                          ‚ñº                        ‚ñº                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ   ETFMomentum     ‚îÇ    ‚îÇ  AIAgentStrategy  ‚îÇ    ‚îÇ   MeanReversion   ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ   Strategy        ‚îÇ    ‚îÇ  (usa LLMAgent)   ‚îÇ    ‚îÇ   (futuro)        ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ                   ‚îÇ    ‚îÇ                   ‚îÇ    ‚îÇ                   ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ required_regime:  ‚îÇ    ‚îÇ required_regime:  ‚îÇ    ‚îÇ required_regime:  ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ   [BULL]          ‚îÇ    ‚îÇ   [BULL, SIDEWAYS]‚îÇ    ‚îÇ   [SIDEWAYS]      ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ            ‚îÇ                        ‚îÇ                        ‚îÇ                ‚îÇ
‚îÇ            ‚îÇ                        ‚îÇ                        ‚îÇ                ‚îÇ
‚îÇ            ‚ñº                        ‚ñº                        ‚ñº                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                            Signal[]                                      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   Todas las estrategias emiten el mismo tipo de output                   ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                      ‚îÇ                                         ‚îÇ
‚îÇ                                      ‚ñº                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                    Risk Manager ‚Üí Orchestrator                           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                    (Fase 3 - flujo existente)                            ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 3.3 Estructura de Directorios

```
src/agents/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ base.py                    # (Fase 3 - existente)
‚îú‚îÄ‚îÄ messaging.py               # (Fase 3 - existente)
‚îú‚îÄ‚îÄ schemas.py                 # (Fase 3 - existente)
‚îú‚îÄ‚îÄ technical.py               # (Fase 3 - existente)
‚îú‚îÄ‚îÄ risk_manager.py            # (Fase 3 - existente)
‚îú‚îÄ‚îÄ orchestrator.py            # (Fase 3 - existente)
‚îî‚îÄ‚îÄ llm/                       # ‚óÑ‚îÄ‚îÄ NUEVO: m√≥dulo AI Agent
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ interfaces.py          # LLMAgent ABC, AgentDecision, AgentContext
    ‚îú‚îÄ‚îÄ factory.py             # LLMAgentFactory
    ‚îú‚îÄ‚îÄ config.py              # Carga config/agents.yaml
    ‚îú‚îÄ‚îÄ context_builder.py     # Construye contexto para LLM
    ‚îú‚îÄ‚îÄ rate_limiter.py        # Rate limiting para APIs
    ‚îú‚îÄ‚îÄ agents/
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ claude_agent.py    # Implementaci√≥n Claude
    ‚îÇ   ‚îî‚îÄ‚îÄ openai_agent.py    # Placeholder GPT-4 (futuro)
    ‚îî‚îÄ‚îÄ prompts/
        ‚îú‚îÄ‚îÄ __init__.py
        ‚îú‚îÄ‚îÄ base.py            # Prompts compartidos
        ‚îú‚îÄ‚îÄ conservative.py    # Prompt nivel conservative
        ‚îú‚îÄ‚îÄ moderate.py        # Prompt nivel moderate
        ‚îî‚îÄ‚îÄ experimental.py    # Prompt nivel experimental

src/strategies/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ interfaces.py              # (Fase B1 - existente)
‚îú‚îÄ‚îÄ registry.py                # (Fase B1 - existente)
‚îú‚îÄ‚îÄ swing/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ etf_momentum.py        # (Fase B1 - existente)
‚îÇ   ‚îî‚îÄ‚îÄ ai_agent_strategy.py   # ‚óÑ‚îÄ‚îÄ NUEVO: Wrapper TradingStrategy

config/
‚îú‚îÄ‚îÄ agents.yaml                # ‚óÑ‚îÄ‚îÄ NUEVO: Config AI Agent
‚îî‚îÄ‚îÄ strategies.yaml            # ACTUALIZAR: a√±adir ai_agent_swing

tests/agents/llm/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ test_interfaces.py
‚îú‚îÄ‚îÄ test_context_builder.py
‚îú‚îÄ‚îÄ test_claude_agent.py
‚îú‚îÄ‚îÄ test_prompts.py
‚îú‚îÄ‚îÄ test_factory.py
‚îî‚îÄ‚îÄ test_integration.py
```

---

## 4. Dependencias Entre Tareas

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                           FASE B2: AI AGENT                                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                                ‚îÇ
‚îÇ  ‚îÇ B2.1: Interfaces         ‚îÇ                                                ‚îÇ
‚îÇ  ‚îÇ (ABC + Dataclasses)      ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ PRIMERO: Define contrato            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                                ‚îÇ
‚îÇ              ‚îÇ                                                               ‚îÇ
‚îÇ              ‚ñº                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                                ‚îÇ
‚îÇ  ‚îÇ B2.2: Context Builder    ‚îÇ                                                ‚îÇ
‚îÇ  ‚îÇ (recopilar datos)        ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Segundo: Prepara input LLM          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                                ‚îÇ
‚îÇ              ‚îÇ                                                               ‚îÇ
‚îÇ              ‚ñº                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                                ‚îÇ
‚îÇ  ‚îÇ B2.3: Sistema Prompts    ‚îÇ                                                ‚îÇ
‚îÇ  ‚îÇ (3 niveles autonom√≠a)    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Define comportamiento               ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                                ‚îÇ
‚îÇ              ‚îÇ                                                               ‚îÇ
‚îÇ              ‚ñº                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
‚îÇ  ‚îÇ B2.4: Claude Agent       ‚îÇ     ‚îÇ B2.5: Rate Limiter       ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ (implementaci√≥n)         ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ (protecci√≥n API)         ‚îÇ               ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ              ‚îÇ                              ‚îÇ                                ‚îÇ
‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                ‚îÇ
‚îÇ                             ‚ñº                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                ‚îÇ
‚îÇ  ‚îÇ B2.6: AIAgentStrategy + Factory          ‚îÇ                                ‚îÇ
‚îÇ  ‚îÇ (integraci√≥n con sistema estrategias)    ‚îÇ                                ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                ‚îÇ
‚îÇ                             ‚îÇ                                                ‚îÇ
‚îÇ                             ‚ñº                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                ‚îÇ
‚îÇ  ‚îÇ B2.7: Configuraci√≥n y Verificaci√≥n       ‚îÇ                                ‚îÇ
‚îÇ  ‚îÇ (config YAML + scripts verificaci√≥n)     ‚îÇ                                ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

LEYENDA:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
B2.1 debe completarse primero (define interfaces)
B2.2-B2.3 pueden desarrollarse en paralelo
B2.4-B2.5 dependen de B2.1-B2.3
B2.6 integra todo
B2.7 verifica sistema completo
```

---

## 5. Resumen de Cambios

### 5.1 Nuevos Archivos

| Archivo | Prop√≥sito |
|---------|-----------|
| `src/agents/llm/interfaces.py` | ABC y dataclasses |
| `src/agents/llm/factory.py` | Factory para crear agentes |
| `src/agents/llm/config.py` | Carga configuraci√≥n YAML |
| `src/agents/llm/context_builder.py` | Construye contexto para LLM |
| `src/agents/llm/rate_limiter.py` | Rate limiting APIs |
| `src/agents/llm/agents/claude_agent.py` | Implementaci√≥n Claude |
| `src/agents/llm/prompts/*.py` | Prompts por autonom√≠a |
| `src/strategies/swing/ai_agent_strategy.py` | Wrapper TradingStrategy |
| `config/agents.yaml` | Configuraci√≥n AI Agent |

### 5.2 Archivos Modificados

| Archivo | Cambio |
|---------|--------|
| `config/strategies.yaml` | A√±adir `ai_agent_swing` |
| `src/strategies/__init__.py` | Export AIAgentStrategy |

### 5.3 Dependencias Externas

```
# Nuevas dependencias en requirements.txt
anthropic>=0.40.0        # Cliente oficial Anthropic
aiolimiter>=1.1.0        # Rate limiting async
tenacity>=8.2.0          # Retry logic
tiktoken>=0.7.0          # Conteo de tokens (opcional, para estimaci√≥n)
```

---

## 6. Niveles de Autonom√≠a

### 6.1 Comparativa de Niveles

| Aspecto | Conservative | Moderate | Experimental |
|---------|-------------|----------|--------------|
| **Descripci√≥n** | Solo informaci√≥n | Sugerencias con sizing | Ejecuci√≥n aut√≥noma |
| **Output** | An√°lisis + opini√≥n | Signal con detalles | Signal lista para ejecutar |
| **Confirmaci√≥n** | Siempre requerida | Requerida | Solo alertas |
| **Sizing** | No incluye | Sugiere % portfolio | Calcula con l√≠mites |
| **Stop Loss** | Informativo | Recomendado | Hardcoded en Signal |
| **Max posici√≥n** | N/A | 5% portfolio | 2% portfolio |
| **Max diario** | N/A | 3 trades | 5 trades |
| **Caso de uso** | Aprendizaje | Paper trading | Live limitado |

### 6.2 Transici√≥n Entre Niveles

```
PROGRESI√ìN RECOMENDADA:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

 Mes 1-2          Mes 3-4              Mes 5+
    ‚îÇ                ‚îÇ                    ‚îÇ
    ‚ñº                ‚ñº                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇConservative‚îÇ‚îÄ‚îÄ‚ñ∂‚îÇ Moderate   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇExperimental‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ                ‚îÇ                    ‚îÇ
    ‚ñº                ‚ñº                    ‚ñº
 "Entender"     "Validar"           "Confiar"

CRITERIOS PARA AVANZAR:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Conservative ‚Üí Moderate:
  - 30+ decisiones analizadas
  - Entiendes su l√≥gica
  - Win rate > 50% en paper

Moderate ‚Üí Experimental:
  - 100+ trades en paper
  - Sharpe > 0.5
  - Max drawdown < 15%
  - Confianza en kill switches

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
```

---

*Fin de Parte 1 - Contexto, Objetivos, Arquitectura y Dependencias*

---

*Documento de Implementaci√≥n - Fase B2: AI Agent*  
*Nexus Trading - Bot de Trading Aut√≥nomo con IA*  
*Versi√≥n 1.0 - Diciembre 2024*
-e 

---

## Interfaces y Dataclasses

---

## 7. Tarea B2.1: Interfaces Base

**Objetivo:** Definir el contrato que todos los LLM agents deben cumplir.

**Archivos a crear:**
- `src/agents/llm/__init__.py`
- `src/agents/llm/interfaces.py`

---

### 7.1 Dataclass: AgentContext

El contexto es TODO lo que el LLM necesita para tomar una decisi√≥n informada.

```python
# src/agents/llm/interfaces.py
from __future__ import annotations

from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Optional, Any
import json


class AutonomyLevel(str, Enum):
    """Niveles de autonom√≠a del AI Agent."""
    CONSERVATIVE = "conservative"   # Solo informaci√≥n
    MODERATE = "moderate"           # Sugerencias con sizing
    EXPERIMENTAL = "experimental"   # Ejecuci√≥n aut√≥noma limitada


class MarketView(str, Enum):
    """Visi√≥n del mercado del agente."""
    BULLISH = "bullish"
    BEARISH = "bearish"
    NEUTRAL = "neutral"
    UNCERTAIN = "uncertain"


@dataclass(frozen=True)
class PortfolioPosition:
    """Posici√≥n actual en portfolio."""
    symbol: str
    quantity: int
    avg_entry_price: float
    current_price: float
    unrealized_pnl: float
    unrealized_pnl_pct: float
    holding_days: int
    
    @property
    def market_value(self) -> float:
        return self.quantity * self.current_price


@dataclass(frozen=True)
class PortfolioSummary:
    """Resumen del estado del portfolio."""
    total_value: float
    cash_available: float
    invested_value: float
    positions: tuple[PortfolioPosition, ...]  # tuple para inmutabilidad
    daily_pnl: float
    daily_pnl_pct: float
    total_pnl: float
    total_pnl_pct: float
    
    @property
    def cash_pct(self) -> float:
        if self.total_value == 0:
            return 100.0
        return (self.cash_available / self.total_value) * 100
    
    @property
    def num_positions(self) -> int:
        return len(self.positions)


@dataclass(frozen=True)
class SymbolData:
    """Datos de mercado para un s√≠mbolo espec√≠fico."""
    symbol: str
    name: str
    current_price: float
    change_pct: float
    volume: int
    avg_volume_20d: int
    
    # Indicadores t√©cnicos
    rsi_14: float
    macd: float
    macd_signal: float
    macd_histogram: float
    sma_20: float
    sma_50: float
    sma_200: float
    bb_upper: float
    bb_middle: float
    bb_lower: float
    atr_14: float
    adx_14: float
    
    # Niveles clave
    support_1: Optional[float] = None
    resistance_1: Optional[float] = None
    
    # Momentum
    momentum_1m: Optional[float] = None  # 1 mes
    momentum_3m: Optional[float] = None  # 3 meses
    momentum_6m: Optional[float] = None  # 6 meses
    
    def to_summary(self) -> str:
        """Genera resumen legible para el LLM."""
        trend = "alcista" if self.current_price > self.sma_50 else "bajista"
        rsi_status = "sobrecompra" if self.rsi_14 > 70 else ("sobreventa" if self.rsi_14 < 30 else "neutral")
        
        return (
            f"{self.symbol} ({self.name}): ${self.current_price:.2f} ({self.change_pct:+.2f}%)\n"
            f"  Tendencia: {trend} | RSI: {self.rsi_14:.1f} ({rsi_status})\n"
            f"  MACD: {self.macd:.3f} | ADX: {self.adx_14:.1f}\n"
            f"  Volumen: {self.volume:,} vs avg {self.avg_volume_20d:,}"
        )


@dataclass(frozen=True)
class RegimeInfo:
    """Informaci√≥n del r√©gimen de mercado actual."""
    regime: str                     # "BULL", "BEAR", "SIDEWAYS", "VOLATILE"
    confidence: float               # 0.0 - 1.0
    probabilities: dict[str, float] # {"BULL": 0.7, "BEAR": 0.1, ...}
    model_id: str                   # "hmm_v1", "rules_v1"
    last_change: Optional[datetime] = None
    days_in_regime: int = 0
    
    def to_summary(self) -> str:
        """Genera resumen legible para el LLM."""
        return (
            f"R√©gimen: {self.regime} (confianza: {self.confidence:.0%})\n"
            f"  D√≠as en r√©gimen: {self.days_in_regime}\n"
            f"  Probabilidades: BULL={self.probabilities.get('BULL', 0):.0%}, "
            f"BEAR={self.probabilities.get('BEAR', 0):.0%}, "
            f"SIDEWAYS={self.probabilities.get('SIDEWAYS', 0):.0%}"
        )


@dataclass(frozen=True)
class RiskLimits:
    """L√≠mites de riesgo actuales."""
    max_position_pct: float         # % m√°ximo por posici√≥n
    max_portfolio_risk_pct: float   # % riesgo total portfolio
    max_daily_trades: int           # N√∫mero m√°ximo de trades por d√≠a
    max_daily_loss_pct: float       # % p√©rdida m√°xima diaria
    current_daily_trades: int       # Trades ejecutados hoy
    current_daily_pnl_pct: float    # P&L del d√≠a
    
    @property
    def can_trade(self) -> bool:
        """Verifica si se puede operar seg√∫n l√≠mites."""
        return (
            self.current_daily_trades < self.max_daily_trades and
            self.current_daily_pnl_pct > -self.max_daily_loss_pct
        )
    
    @property
    def remaining_trades(self) -> int:
        return max(0, self.max_daily_trades - self.current_daily_trades)


@dataclass(frozen=True)
class MarketContext:
    """Contexto general del mercado (√≠ndices, VIX, etc.)."""
    spy_change_pct: float           # S&P 500 cambio %
    qqq_change_pct: float           # Nasdaq cambio %
    vix_level: float                # Nivel VIX
    vix_change_pct: float           # Cambio VIX %
    market_breadth: float           # % acciones sobre SMA50 (-1 a 1)
    sector_rotation: dict[str, float]  # Performance por sector
    
    def to_summary(self) -> str:
        """Genera resumen legible para el LLM."""
        market_sentiment = "risk-on" if self.vix_level < 20 else ("risk-off" if self.vix_level > 30 else "neutral")
        return (
            f"Mercado General:\n"
            f"  SPY: {self.spy_change_pct:+.2f}% | QQQ: {self.qqq_change_pct:+.2f}%\n"
            f"  VIX: {self.vix_level:.1f} ({self.vix_change_pct:+.2f}%) - {market_sentiment}\n"
            f"  Breadth: {self.market_breadth:.0%} acciones sobre SMA50"
        )


@dataclass
class AgentContext:
    """
    Contexto completo para el AI Agent.
    
    Este es el INPUT principal del LLM. Contiene toda la informaci√≥n
    necesaria para tomar decisiones de trading informadas.
    """
    # Identificadores
    context_id: str
    timestamp: datetime
    
    # Estado del mercado
    regime: RegimeInfo
    market: MarketContext
    
    # Portfolio
    portfolio: PortfolioSummary
    
    # S√≠mbolos a analizar
    watchlist: tuple[SymbolData, ...]
    
    # L√≠mites de riesgo
    risk_limits: RiskLimits
    
    # Configuraci√≥n
    autonomy_level: AutonomyLevel
    
    # Historial reciente (opcional)
    recent_trades: tuple[dict, ...] = field(default_factory=tuple)
    recent_signals: tuple[dict, ...] = field(default_factory=tuple)
    
    # Notas adicionales (noticias, eventos, etc.)
    notes: Optional[str] = None
    
    def to_prompt_text(self) -> str:
        """
        Convierte el contexto completo a texto para el prompt del LLM.
        
        Returns:
            String formateado con toda la informaci√≥n relevante
        """
        sections = []
        
        # 1. Fecha y hora
        sections.append(f"üìÖ FECHA Y HORA: {self.timestamp.strftime('%Y-%m-%d %H:%M:%S UTC')}")
        
        # 2. R√©gimen de mercado
        sections.append(f"\nüéØ R√âGIMEN DE MERCADO:\n{self.regime.to_summary()}")
        
        # 3. Contexto general del mercado
        sections.append(f"\nüìä MERCADO GENERAL:\n{self.market.to_summary()}")
        
        # 4. Portfolio
        sections.append(f"\nüíº PORTFOLIO:")
        sections.append(f"  Valor total: ‚Ç¨{self.portfolio.total_value:,.2f}")
        sections.append(f"  Cash disponible: ‚Ç¨{self.portfolio.cash_available:,.2f} ({self.portfolio.cash_pct:.1f}%)")
        sections.append(f"  P&L del d√≠a: {self.portfolio.daily_pnl_pct:+.2f}%")
        sections.append(f"  Posiciones abiertas: {self.portfolio.num_positions}")
        
        if self.portfolio.positions:
            sections.append("\n  Posiciones actuales:")
            for pos in self.portfolio.positions:
                sections.append(
                    f"    - {pos.symbol}: {pos.quantity} @ ‚Ç¨{pos.avg_entry_price:.2f} "
                    f"‚Üí ‚Ç¨{pos.current_price:.2f} ({pos.unrealized_pnl_pct:+.2f}%)"
                )
        
        # 5. L√≠mites de riesgo
        sections.append(f"\n‚ö†Ô∏è L√çMITES DE RIESGO:")
        sections.append(f"  Max posici√≥n: {self.risk_limits.max_position_pct:.1f}% portfolio")
        sections.append(f"  Trades restantes hoy: {self.risk_limits.remaining_trades}")
        sections.append(f"  P&L diario: {self.risk_limits.current_daily_pnl_pct:+.2f}% (l√≠mite: -{self.risk_limits.max_daily_loss_pct:.1f}%)")
        if not self.risk_limits.can_trade:
            sections.append("  ‚ùå TRADING PAUSADO POR L√çMITES")
        
        # 6. Watchlist con an√°lisis
        sections.append(f"\nüìà WATCHLIST ({len(self.watchlist)} s√≠mbolos):")
        for symbol_data in self.watchlist:
            sections.append(f"\n{symbol_data.to_summary()}")
        
        # 7. Trades recientes
        if self.recent_trades:
            sections.append(f"\nüìú TRADES RECIENTES ({len(self.recent_trades)} √∫ltimos):")
            for trade in self.recent_trades[-5:]:  # √öltimos 5
                sections.append(
                    f"  - {trade.get('symbol')}: {trade.get('direction')} "
                    f"@ ‚Ç¨{trade.get('entry_price', 0):.2f} ‚Üí {trade.get('pnl_pct', 0):+.2f}%"
                )
        
        # 8. Notas adicionales
        if self.notes:
            sections.append(f"\nüìù NOTAS:\n{self.notes}")
        
        # 9. Nivel de autonom√≠a
        autonomy_desc = {
            AutonomyLevel.CONSERVATIVE: "Solo an√°lisis e informaci√≥n",
            AutonomyLevel.MODERATE: "Sugerencias con sizing recomendado",
            AutonomyLevel.EXPERIMENTAL: "Decisiones aut√≥nomas dentro de l√≠mites"
        }
        sections.append(f"\nü§ñ NIVEL DE AUTONOM√çA: {self.autonomy_level.value}")
        sections.append(f"   ({autonomy_desc[self.autonomy_level]})")
        
        return "\n".join(sections)
    
    def to_dict(self) -> dict:
        """Serializa el contexto a diccionario."""
        return {
            "context_id": self.context_id,
            "timestamp": self.timestamp.isoformat(),
            "regime": {
                "regime": self.regime.regime,
                "confidence": self.regime.confidence,
                "probabilities": self.regime.probabilities,
                "model_id": self.regime.model_id,
            },
            "portfolio": {
                "total_value": self.portfolio.total_value,
                "cash_available": self.portfolio.cash_available,
                "num_positions": self.portfolio.num_positions,
            },
            "risk_limits": {
                "can_trade": self.risk_limits.can_trade,
                "remaining_trades": self.risk_limits.remaining_trades,
            },
            "watchlist_count": len(self.watchlist),
            "autonomy_level": self.autonomy_level.value,
        }
```

---

### 7.2 Dataclass: AgentDecision

El output estructurado del LLM.

```python
# Continuaci√≥n de src/agents/llm/interfaces.py

from src.strategies.interfaces import Signal  # Import de Fase B1


@dataclass
class AgentDecision:
    """
    Decisi√≥n del AI Agent.
    
    Este es el OUTPUT del LLM despu√©s de analizar el contexto.
    Incluye acciones concretas (Signal[]) m√°s metadatos para trazabilidad.
    """
    # Identificadores
    decision_id: str
    context_id: str                 # Referencia al AgentContext usado
    timestamp: datetime
    
    # Acciones a tomar
    actions: list[Signal]           # Se√±ales generadas (puede estar vac√≠o)
    
    # An√°lisis del agente
    market_view: MarketView         # Visi√≥n general del mercado
    reasoning: str                  # Explicaci√≥n detallada de la decisi√≥n
    key_factors: list[str]          # Factores clave considerados
    
    # Confianza
    confidence: float               # 0.0 - 1.0, confianza en la decisi√≥n
    
    # Metadatos
    model_used: str                 # "claude-sonnet-4-20250514"
    autonomy_level: AutonomyLevel   # Nivel con el que se tom√≥ la decisi√≥n
    tokens_used: int                # Tokens consumidos
    latency_ms: float               # Tiempo de respuesta
    
    # Warnings o notas
    warnings: list[str] = field(default_factory=list)
    
    def __post_init__(self):
        """Validaciones post-inicializaci√≥n."""
        if not 0.0 <= self.confidence <= 1.0:
            raise ValueError(f"Confidence must be between 0 and 1, got {self.confidence}")
        
        if self.actions and self.autonomy_level == AutonomyLevel.CONSERVATIVE:
            # En modo conservative, las acciones son solo informativas
            pass  # OK, pero se debe comunicar al usuario
    
    @property
    def has_actions(self) -> bool:
        return len(self.actions) > 0
    
    @property
    def action_summary(self) -> str:
        if not self.actions:
            return "No actions recommended"
        
        summaries = []
        for action in self.actions:
            summaries.append(
                f"{action.direction} {action.symbol} @ {action.entry_price:.2f} "
                f"(SL: {action.stop_loss:.2f}, TP: {action.take_profit:.2f})"
            )
        return "; ".join(summaries)
    
    def to_dict(self) -> dict:
        """Serializa la decisi√≥n a diccionario para logging/BD."""
        return {
            "decision_id": self.decision_id,
            "context_id": self.context_id,
            "timestamp": self.timestamp.isoformat(),
            "actions": [
                {
                    "strategy_id": a.strategy_id,
                    "symbol": a.symbol,
                    "direction": a.direction,
                    "confidence": a.confidence,
                    "entry_price": a.entry_price,
                    "stop_loss": a.stop_loss,
                    "take_profit": a.take_profit,
                }
                for a in self.actions
            ],
            "market_view": self.market_view.value,
            "reasoning": self.reasoning,
            "key_factors": self.key_factors,
            "confidence": self.confidence,
            "model_used": self.model_used,
            "autonomy_level": self.autonomy_level.value,
            "tokens_used": self.tokens_used,
            "latency_ms": self.latency_ms,
            "warnings": self.warnings,
        }
    
    def to_json(self) -> str:
        """Serializa a JSON string."""
        return json.dumps(self.to_dict(), indent=2, ensure_ascii=False)
```

---

### 7.3 Abstract Base Class: LLMAgent

```python
# Continuaci√≥n de src/agents/llm/interfaces.py

class LLMAgent(ABC):
    """
    Clase base abstracta para agentes basados en LLM.
    
    Define el contrato que todas las implementaciones (Claude, GPT-4, Gemini)
    deben cumplir para ser intercambiables.
    """
    
    @property
    @abstractmethod
    def agent_id(self) -> str:
        """
        Identificador √∫nico del agente.
        
        Returns:
            String identificador, ej: "claude_sonnet_v1", "gpt4_turbo_v1"
        """
        pass
    
    @property
    @abstractmethod
    def model_name(self) -> str:
        """
        Nombre del modelo LLM usado.
        
        Returns:
            String con nombre del modelo, ej: "claude-sonnet-4-20250514"
        """
        pass
    
    @property
    @abstractmethod
    def supports_streaming(self) -> bool:
        """
        Indica si el agente soporta streaming de respuestas.
        
        Returns:
            True si soporta streaming
        """
        pass
    
    @abstractmethod
    async def decide(
        self,
        context: AgentContext,
        autonomy_level: Optional[AutonomyLevel] = None
    ) -> AgentDecision:
        """
        Toma una decisi√≥n de trading basada en el contexto.
        
        Este es el m√©todo principal del agente. Recibe todo el contexto
        necesario y devuelve una decisi√≥n estructurada.
        
        Args:
            context: AgentContext con toda la informaci√≥n del mercado
            autonomy_level: Nivel de autonom√≠a (override del config si se provee)
        
        Returns:
            AgentDecision con acciones y razonamiento
        
        Raises:
            LLMAPIError: Si hay error en la llamada al LLM
            LLMRateLimitError: Si se excede el rate limit
            LLMParseError: Si no se puede parsear la respuesta
        """
        pass
    
    @abstractmethod
    def get_system_prompt(self, autonomy_level: AutonomyLevel) -> str:
        """
        Obtiene el system prompt para el nivel de autonom√≠a dado.
        
        Args:
            autonomy_level: Nivel de autonom√≠a
        
        Returns:
            String con el system prompt completo
        """
        pass
    
    @abstractmethod
    async def health_check(self) -> dict:
        """
        Verifica el estado del agente y conexi√≥n al LLM.
        
        Returns:
            Dict con status y detalles
            {
                "status": "healthy" | "degraded" | "unhealthy",
                "model": "claude-sonnet-4-20250514",
                "latency_ms": 150,
                "rate_limit_remaining": 95,
                "last_error": null
            }
        """
        pass
    
    @abstractmethod
    def estimate_tokens(self, context: AgentContext) -> int:
        """
        Estima los tokens que consumir√° una llamada con este contexto.
        
        √ötil para:
        - Verificar que no excedemos context window
        - Estimar costos
        - Decidir si truncar contexto
        
        Args:
            context: AgentContext a evaluar
        
        Returns:
            N√∫mero estimado de tokens
        """
        pass
    
    # M√©todos opcionales con implementaci√≥n por defecto
    
    def validate_context(self, context: AgentContext) -> tuple[bool, list[str]]:
        """
        Valida que el contexto sea adecuado para el agente.
        
        Args:
            context: Contexto a validar
        
        Returns:
            Tuple (is_valid, list of issues)
        """
        issues = []
        
        # Verificar que hay watchlist
        if not context.watchlist:
            issues.append("Watchlist vac√≠a - nada que analizar")
        
        # Verificar l√≠mites de riesgo
        if not context.risk_limits.can_trade:
            issues.append("Trading pausado por l√≠mites de riesgo")
        
        # Verificar r√©gimen
        if context.regime.confidence < 0.5:
            issues.append(f"Confianza de r√©gimen baja: {context.regime.confidence:.0%}")
        
        return len(issues) == 0, issues
    
    def should_skip_decision(self, context: AgentContext) -> tuple[bool, str]:
        """
        Determina si se debe omitir la decisi√≥n por alguna raz√≥n.
        
        Args:
            context: Contexto actual
        
        Returns:
            Tuple (should_skip, reason)
        """
        # Skip si no se puede operar
        if not context.risk_limits.can_trade:
            return True, "Risk limits reached - trading paused"
        
        # Skip si r√©gimen es VOLATILE
        if context.regime.regime == "VOLATILE":
            return True, "Market regime is VOLATILE - waiting for clarity"
        
        # Skip si VIX muy alto
        if context.market.vix_level > 35:
            return True, f"VIX too high ({context.market.vix_level}) - extreme fear"
        
        return False, ""
```

---

### 7.4 Excepciones Espec√≠ficas

```python
# Continuaci√≥n de src/agents/llm/interfaces.py (o en exceptions.py separado)

class LLMAgentError(Exception):
    """Base exception para errores del LLM Agent."""
    pass


class LLMAPIError(LLMAgentError):
    """Error en la llamada a la API del LLM."""
    def __init__(self, message: str, status_code: Optional[int] = None, response: Optional[str] = None):
        super().__init__(message)
        self.status_code = status_code
        self.response = response


class LLMRateLimitError(LLMAgentError):
    """Rate limit excedido."""
    def __init__(self, message: str, retry_after: Optional[int] = None):
        super().__init__(message)
        self.retry_after = retry_after  # Segundos hasta retry


class LLMParseError(LLMAgentError):
    """Error parseando la respuesta del LLM."""
    def __init__(self, message: str, raw_response: Optional[str] = None):
        super().__init__(message)
        self.raw_response = raw_response


class LLMContextTooLargeError(LLMAgentError):
    """El contexto excede el l√≠mite de tokens."""
    def __init__(self, message: str, tokens_needed: int, tokens_available: int):
        super().__init__(message)
        self.tokens_needed = tokens_needed
        self.tokens_available = tokens_available


class LLMTimeoutError(LLMAgentError):
    """Timeout en la llamada al LLM."""
    def __init__(self, message: str, timeout_seconds: float):
        super().__init__(message)
        self.timeout_seconds = timeout_seconds
```

---

### 7.5 Archivo __init__.py

```python
# src/agents/llm/__init__.py
"""
LLM Agent Module - AI-powered trading decisions.

Este m√≥dulo implementa agentes de trading basados en Large Language Models.
Actualmente soporta Claude (Anthropic), con arquitectura preparada para
GPT-4 (OpenAI) y Gemini (Google).

Uso b√°sico:
    from src.agents.llm import LLMAgentFactory, AgentContext, AutonomyLevel
    
    # Crear agente desde config
    agent = LLMAgentFactory.create_from_config()
    
    # Construir contexto
    context = build_agent_context(...)
    
    # Obtener decisi√≥n
    decision = await agent.decide(context, AutonomyLevel.MODERATE)
"""

from .interfaces import (
    # Enums
    AutonomyLevel,
    MarketView,
    
    # Dataclasses de contexto
    PortfolioPosition,
    PortfolioSummary,
    SymbolData,
    RegimeInfo,
    RiskLimits,
    MarketContext,
    AgentContext,
    
    # Output
    AgentDecision,
    
    # ABC
    LLMAgent,
    
    # Exceptions
    LLMAgentError,
    LLMAPIError,
    LLMRateLimitError,
    LLMParseError,
    LLMContextTooLargeError,
    LLMTimeoutError,
)

# Lazy imports para evitar ciclos
def get_factory():
    from .factory import LLMAgentFactory
    return LLMAgentFactory

def get_context_builder():
    from .context_builder import ContextBuilder
    return ContextBuilder


__all__ = [
    # Enums
    "AutonomyLevel",
    "MarketView",
    
    # Dataclasses
    "PortfolioPosition",
    "PortfolioSummary", 
    "SymbolData",
    "RegimeInfo",
    "RiskLimits",
    "MarketContext",
    "AgentContext",
    "AgentDecision",
    
    # ABC
    "LLMAgent",
    
    # Exceptions
    "LLMAgentError",
    "LLMAPIError",
    "LLMRateLimitError",
    "LLMParseError",
    "LLMContextTooLargeError",
    "LLMTimeoutError",
    
    # Factories
    "get_factory",
    "get_context_builder",
]
```

---

## 8. Tarea B2.2: Context Builder

**Objetivo:** Construir el AgentContext recopilando datos de m√∫ltiples fuentes.

**Archivo:** `src/agents/llm/context_builder.py`

```python
# src/agents/llm/context_builder.py
"""
Context Builder - Construye AgentContext desde m√∫ltiples fuentes de datos.

Este m√≥dulo es responsable de:
1. Consultar mcp-ml-models para r√©gimen
2. Consultar mcp-market-data para datos de mercado
3. Consultar mcp-ibkr para portfolio
4. Consolidar todo en AgentContext
"""

from __future__ import annotations

import asyncio
import uuid
from datetime import datetime, timedelta
from typing import Optional, Protocol
import logging

from .interfaces import (
    AgentContext,
    AutonomyLevel,
    PortfolioPosition,
    PortfolioSummary,
    SymbolData,
    RegimeInfo,
    RiskLimits,
    MarketContext,
)


logger = logging.getLogger(__name__)


class MCPClient(Protocol):
    """Protocolo para cliente MCP (duck typing)."""
    async def call(self, server: str, tool: str, params: dict) -> dict: ...


class ContextBuilder:
    """
    Construye AgentContext recopilando datos de m√∫ltiples fuentes.
    
    Dise√±ado para ser modular - cada fuente de datos es independiente
    y puede fallar sin afectar las dem√°s.
    """
    
    def __init__(
        self,
        mcp_client: MCPClient,
        default_autonomy: AutonomyLevel = AutonomyLevel.MODERATE,
        cache_ttl_seconds: int = 60
    ):
        """
        Args:
            mcp_client: Cliente para llamadas MCP
            default_autonomy: Nivel de autonom√≠a por defecto
            cache_ttl_seconds: TTL del cache de contexto
        """
        self.mcp = mcp_client
        self.default_autonomy = default_autonomy
        self.cache_ttl = cache_ttl_seconds
        self._cache: dict[str, tuple[datetime, any]] = {}
    
    async def build(
        self,
        watchlist: list[str],
        autonomy_level: Optional[AutonomyLevel] = None,
        notes: Optional[str] = None
    ) -> AgentContext:
        """
        Construye un AgentContext completo.
        
        Args:
            watchlist: Lista de s√≠mbolos a analizar
            autonomy_level: Nivel de autonom√≠a (usa default si no se provee)
            notes: Notas adicionales para el contexto
        
        Returns:
            AgentContext completo listo para el LLM
        """
        context_id = f"ctx_{uuid.uuid4().hex[:12]}"
        timestamp = datetime.utcnow()
        autonomy = autonomy_level or self.default_autonomy
        
        logger.info(f"Building context {context_id} for {len(watchlist)} symbols")
        
        # Ejecutar todas las consultas en paralelo
        results = await asyncio.gather(
            self._get_regime(),
            self._get_market_context(),
            self._get_portfolio(),
            self._get_watchlist_data(watchlist),
            self._get_risk_limits(),
            self._get_recent_trades(),
            return_exceptions=True  # No fallar si una consulta falla
        )
        
        regime, market, portfolio, watchlist_data, risk_limits, recent_trades = results
        
        # Manejar errores individuales con defaults
        if isinstance(regime, Exception):
            logger.warning(f"Error getting regime: {regime}, using default")
            regime = self._default_regime()
        
        if isinstance(market, Exception):
            logger.warning(f"Error getting market context: {market}, using default")
            market = self._default_market_context()
        
        if isinstance(portfolio, Exception):
            logger.warning(f"Error getting portfolio: {portfolio}, using default")
            portfolio = self._default_portfolio()
        
        if isinstance(watchlist_data, Exception):
            logger.warning(f"Error getting watchlist data: {watchlist_data}")
            watchlist_data = ()
        
        if isinstance(risk_limits, Exception):
            logger.warning(f"Error getting risk limits: {risk_limits}, using conservative")
            risk_limits = self._conservative_risk_limits()
        
        if isinstance(recent_trades, Exception):
            logger.warning(f"Error getting recent trades: {recent_trades}")
            recent_trades = ()
        
        return AgentContext(
            context_id=context_id,
            timestamp=timestamp,
            regime=regime,
            market=market,
            portfolio=portfolio,
            watchlist=tuple(watchlist_data),
            risk_limits=risk_limits,
            autonomy_level=autonomy,
            recent_trades=tuple(recent_trades) if recent_trades else (),
            notes=notes
        )
    
    async def _get_regime(self) -> RegimeInfo:
        """Obtiene r√©gimen actual de mcp-ml-models."""
        # Check cache
        cached = self._get_cached("regime")
        if cached:
            return cached
        
        response = await self.mcp.call(
            "mcp-ml-models",
            "get_regime",
            {}
        )
        
        regime = RegimeInfo(
            regime=response["regime"],
            confidence=response["confidence"],
            probabilities=response.get("probabilities", {}),
            model_id=response.get("model_id", "unknown"),
            last_change=response.get("last_change"),
            days_in_regime=response.get("days_in_regime", 0)
        )
        
        self._set_cached("regime", regime)
        return regime
    
    async def _get_market_context(self) -> MarketContext:
        """Obtiene contexto general del mercado."""
        cached = self._get_cached("market")
        if cached:
            return cached
        
        # Obtener datos de √≠ndices principales
        spy_data = await self.mcp.call(
            "mcp-market-data",
            "get_quote",
            {"symbol": "SPY"}
        )
        
        qqq_data = await self.mcp.call(
            "mcp-market-data", 
            "get_quote",
            {"symbol": "QQQ"}
        )
        
        vix_data = await self.mcp.call(
            "mcp-market-data",
            "get_quote", 
            {"symbol": "VIX"}
        )
        
        # Market breadth (simplificado)
        breadth = await self._calculate_market_breadth()
        
        market = MarketContext(
            spy_change_pct=spy_data.get("change_pct", 0),
            qqq_change_pct=qqq_data.get("change_pct", 0),
            vix_level=vix_data.get("price", 20),
            vix_change_pct=vix_data.get("change_pct", 0),
            market_breadth=breadth,
            sector_rotation={}  # TODO: Implementar
        )
        
        self._set_cached("market", market)
        return market
    
    async def _get_portfolio(self) -> PortfolioSummary:
        """Obtiene estado actual del portfolio de IBKR."""
        response = await self.mcp.call(
            "mcp-ibkr",
            "get_portfolio",
            {}
        )
        
        positions = []
        for pos in response.get("positions", []):
            positions.append(PortfolioPosition(
                symbol=pos["symbol"],
                quantity=pos["quantity"],
                avg_entry_price=pos["avg_entry_price"],
                current_price=pos["current_price"],
                unrealized_pnl=pos["unrealized_pnl"],
                unrealized_pnl_pct=pos["unrealized_pnl_pct"],
                holding_days=pos.get("holding_days", 0)
            ))
        
        return PortfolioSummary(
            total_value=response["total_value"],
            cash_available=response["cash_available"],
            invested_value=response["invested_value"],
            positions=tuple(positions),
            daily_pnl=response.get("daily_pnl", 0),
            daily_pnl_pct=response.get("daily_pnl_pct", 0),
            total_pnl=response.get("total_pnl", 0),
            total_pnl_pct=response.get("total_pnl_pct", 0)
        )
    
    async def _get_watchlist_data(self, symbols: list[str]) -> list[SymbolData]:
        """Obtiene datos de mercado para cada s√≠mbolo del watchlist."""
        tasks = [self._get_symbol_data(symbol) for symbol in symbols]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        valid_data = []
        for symbol, result in zip(symbols, results):
            if isinstance(result, Exception):
                logger.warning(f"Error getting data for {symbol}: {result}")
                continue
            valid_data.append(result)
        
        return valid_data
    
    async def _get_symbol_data(self, symbol: str) -> SymbolData:
        """Obtiene datos completos de un s√≠mbolo."""
        # Datos de quote
        quote = await self.mcp.call(
            "mcp-market-data",
            "get_quote",
            {"symbol": symbol}
        )
        
        # Indicadores t√©cnicos
        indicators = await self.mcp.call(
            "mcp-technical",
            "get_indicators",
            {"symbol": symbol, "indicators": ["RSI", "MACD", "SMA", "BB", "ATR", "ADX"]}
        )
        
        return SymbolData(
            symbol=symbol,
            name=quote.get("name", symbol),
            current_price=quote["price"],
            change_pct=quote["change_pct"],
            volume=quote["volume"],
            avg_volume_20d=quote.get("avg_volume_20d", quote["volume"]),
            rsi_14=indicators.get("RSI", {}).get("value", 50),
            macd=indicators.get("MACD", {}).get("macd", 0),
            macd_signal=indicators.get("MACD", {}).get("signal", 0),
            macd_histogram=indicators.get("MACD", {}).get("histogram", 0),
            sma_20=indicators.get("SMA", {}).get("sma_20", quote["price"]),
            sma_50=indicators.get("SMA", {}).get("sma_50", quote["price"]),
            sma_200=indicators.get("SMA", {}).get("sma_200", quote["price"]),
            bb_upper=indicators.get("BB", {}).get("upper", quote["price"] * 1.02),
            bb_middle=indicators.get("BB", {}).get("middle", quote["price"]),
            bb_lower=indicators.get("BB", {}).get("lower", quote["price"] * 0.98),
            atr_14=indicators.get("ATR", {}).get("value", quote["price"] * 0.02),
            adx_14=indicators.get("ADX", {}).get("value", 25),
            support_1=indicators.get("levels", {}).get("support_1"),
            resistance_1=indicators.get("levels", {}).get("resistance_1"),
            momentum_1m=indicators.get("momentum", {}).get("1m"),
            momentum_3m=indicators.get("momentum", {}).get("3m"),
            momentum_6m=indicators.get("momentum", {}).get("6m"),
        )
    
    async def _get_risk_limits(self) -> RiskLimits:
        """Obtiene l√≠mites de riesgo actuales."""
        response = await self.mcp.call(
            "mcp-risk",
            "get_limits",
            {}
        )
        
        return RiskLimits(
            max_position_pct=response.get("max_position_pct", 5.0),
            max_portfolio_risk_pct=response.get("max_portfolio_risk_pct", 2.0),
            max_daily_trades=response.get("max_daily_trades", 5),
            max_daily_loss_pct=response.get("max_daily_loss_pct", 3.0),
            current_daily_trades=response.get("current_daily_trades", 0),
            current_daily_pnl_pct=response.get("current_daily_pnl_pct", 0),
        )
    
    async def _get_recent_trades(self) -> list[dict]:
        """Obtiene trades recientes para contexto hist√≥rico."""
        # Pseudo-implementaci√≥n - conectar a metrics.trades
        return []
    
    async def _calculate_market_breadth(self) -> float:
        """Calcula market breadth simplificado."""
        # Pseudo-implementaci√≥n
        # Idealmente: % de acciones del S&P500 sobre su SMA50
        return 0.6  # Default: 60% bullish
    
    # M√©todos de cache
    def _get_cached(self, key: str) -> Optional[any]:
        if key in self._cache:
            timestamp, value = self._cache[key]
            if datetime.utcnow() - timestamp < timedelta(seconds=self.cache_ttl):
                return value
        return None
    
    def _set_cached(self, key: str, value: any):
        self._cache[key] = (datetime.utcnow(), value)
    
    # Defaults para manejo de errores
    def _default_regime(self) -> RegimeInfo:
        return RegimeInfo(
            regime="SIDEWAYS",
            confidence=0.5,
            probabilities={"BULL": 0.25, "BEAR": 0.25, "SIDEWAYS": 0.25, "VOLATILE": 0.25},
            model_id="default_fallback"
        )
    
    def _default_market_context(self) -> MarketContext:
        return MarketContext(
            spy_change_pct=0,
            qqq_change_pct=0,
            vix_level=20,
            vix_change_pct=0,
            market_breadth=0.5,
            sector_rotation={}
        )
    
    def _default_portfolio(self) -> PortfolioSummary:
        return PortfolioSummary(
            total_value=25000,  # Paper trading default
            cash_available=25000,
            invested_value=0,
            positions=(),
            daily_pnl=0,
            daily_pnl_pct=0,
            total_pnl=0,
            total_pnl_pct=0
        )
    
    def _conservative_risk_limits(self) -> RiskLimits:
        """L√≠mites conservadores cuando hay error."""
        return RiskLimits(
            max_position_pct=2.0,   # Muy conservador
            max_portfolio_risk_pct=1.0,
            max_daily_trades=2,
            max_daily_loss_pct=1.0,
            current_daily_trades=0,
            current_daily_pnl_pct=0
        )
```

---

## 9. Validaci√≥n de Interfaces

### 9.1 Test de Estructura

```python
# tests/agents/llm/test_interfaces.py
"""Tests para interfaces del LLM Agent."""

import pytest
from datetime import datetime
from src.agents.llm.interfaces import (
    AutonomyLevel,
    MarketView,
    PortfolioPosition,
    PortfolioSummary,
    SymbolData,
    RegimeInfo,
    RiskLimits,
    AgentContext,
    AgentDecision,
)
from src.strategies.interfaces import Signal


class TestAutonomyLevel:
    def test_enum_values(self):
        assert AutonomyLevel.CONSERVATIVE.value == "conservative"
        assert AutonomyLevel.MODERATE.value == "moderate"
        assert AutonomyLevel.EXPERIMENTAL.value == "experimental"


class TestPortfolioPosition:
    def test_market_value(self):
        pos = PortfolioPosition(
            symbol="AAPL",
            quantity=10,
            avg_entry_price=150.0,
            current_price=160.0,
            unrealized_pnl=100.0,
            unrealized_pnl_pct=6.67,
            holding_days=5
        )
        assert pos.market_value == 1600.0
    
    def test_immutability(self):
        pos = PortfolioPosition(
            symbol="AAPL",
            quantity=10,
            avg_entry_price=150.0,
            current_price=160.0,
            unrealized_pnl=100.0,
            unrealized_pnl_pct=6.67,
            holding_days=5
        )
        with pytest.raises(AttributeError):
            pos.quantity = 20


class TestRiskLimits:
    def test_can_trade_true(self):
        limits = RiskLimits(
            max_position_pct=5.0,
            max_portfolio_risk_pct=2.0,
            max_daily_trades=5,
            max_daily_loss_pct=3.0,
            current_daily_trades=2,
            current_daily_pnl_pct=-1.0
        )
        assert limits.can_trade is True
        assert limits.remaining_trades == 3
    
    def test_can_trade_false_max_trades(self):
        limits = RiskLimits(
            max_position_pct=5.0,
            max_portfolio_risk_pct=2.0,
            max_daily_trades=5,
            max_daily_loss_pct=3.0,
            current_daily_trades=5,  # Alcanz√≥ m√°ximo
            current_daily_pnl_pct=0
        )
        assert limits.can_trade is False
        assert limits.remaining_trades == 0
    
    def test_can_trade_false_max_loss(self):
        limits = RiskLimits(
            max_position_pct=5.0,
            max_portfolio_risk_pct=2.0,
            max_daily_trades=5,
            max_daily_loss_pct=3.0,
            current_daily_trades=1,
            current_daily_pnl_pct=-4.0  # Excede p√©rdida m√°xima
        )
        assert limits.can_trade is False


class TestAgentContext:
    @pytest.fixture
    def sample_context(self):
        return AgentContext(
            context_id="ctx_test123",
            timestamp=datetime.utcnow(),
            regime=RegimeInfo(
                regime="BULL",
                confidence=0.75,
                probabilities={"BULL": 0.75, "BEAR": 0.1, "SIDEWAYS": 0.1, "VOLATILE": 0.05},
                model_id="hmm_v1"
            ),
            market=MarketContext(
                spy_change_pct=0.5,
                qqq_change_pct=0.8,
                vix_level=18.5,
                vix_change_pct=-2.0,
                market_breadth=0.65,
                sector_rotation={}
            ),
            portfolio=PortfolioSummary(
                total_value=25000,
                cash_available=20000,
                invested_value=5000,
                positions=(),
                daily_pnl=50,
                daily_pnl_pct=0.2,
                total_pnl=500,
                total_pnl_pct=2.0
            ),
            watchlist=(),
            risk_limits=RiskLimits(
                max_position_pct=5.0,
                max_portfolio_risk_pct=2.0,
                max_daily_trades=5,
                max_daily_loss_pct=3.0,
                current_daily_trades=1,
                current_daily_pnl_pct=0.2
            ),
            autonomy_level=AutonomyLevel.MODERATE
        )
    
    def test_to_prompt_text_not_empty(self, sample_context):
        text = sample_context.to_prompt_text()
        assert len(text) > 100
        assert "R√âGIMEN" in text
        assert "PORTFOLIO" in text
        assert "BULL" in text
    
    def test_to_dict_serializable(self, sample_context):
        d = sample_context.to_dict()
        import json
        json_str = json.dumps(d)  # No debe lanzar excepci√≥n
        assert "context_id" in d


class TestAgentDecision:
    def test_confidence_validation(self):
        with pytest.raises(ValueError):
            AgentDecision(
                decision_id="dec_test",
                context_id="ctx_test",
                timestamp=datetime.utcnow(),
                actions=[],
                market_view=MarketView.BULLISH,
                reasoning="Test",
                key_factors=["factor1"],
                confidence=1.5,  # Inv√°lido
                model_used="test",
                autonomy_level=AutonomyLevel.MODERATE,
                tokens_used=100,
                latency_ms=150
            )
    
    def test_has_actions(self):
        decision = AgentDecision(
            decision_id="dec_test",
            context_id="ctx_test",
            timestamp=datetime.utcnow(),
            actions=[],
            market_view=MarketView.NEUTRAL,
            reasoning="No opportunities",
            key_factors=[],
            confidence=0.8,
            model_used="test",
            autonomy_level=AutonomyLevel.MODERATE,
            tokens_used=100,
            latency_ms=150
        )
        assert decision.has_actions is False
```

---

*Fin de Parte 2 - Interfaces y Dataclasses*

---

*Documento de Implementaci√≥n - Fase B2: AI Agent*  
*Nexus Trading - Bot de Trading Aut√≥nomo con IA*  
*Versi√≥n 1.0 - Diciembre 2024*
-e 

---

## Implementaci√≥n Claude Agent + Sistema de Prompts

---

## 10. Tarea B2.3: Sistema de Prompts

**Objetivo:** Definir los system prompts que controlan el comportamiento del AI Agent seg√∫n el nivel de autonom√≠a.

**Archivos:**
- `src/agents/llm/prompts/__init__.py`
- `src/agents/llm/prompts/base.py`
- `src/agents/llm/prompts/conservative.py`
- `src/agents/llm/prompts/moderate.py`
- `src/agents/llm/prompts/experimental.py`

---

### 10.1 Prompt Base (Compartido)

```python
# src/agents/llm/prompts/base.py
"""
Base prompts compartidos entre todos los niveles de autonom√≠a.

Estos componentes se combinan con prompts espec√≠ficos de autonom√≠a
para formar el system prompt completo.
"""

# Identidad del agente
AGENT_IDENTITY = """Eres un asistente de trading profesional especializado en an√°lisis t√©cnico y gesti√≥n de riesgo.
Tu objetivo es ayudar a tomar decisiones de trading informadas basadas en datos objetivos.

PRINCIPIOS FUNDAMENTALES:
1. La preservaci√≥n del capital es la prioridad n√∫mero uno
2. Nunca recomiendes operaciones que excedan los l√≠mites de riesgo establecidos
3. S√© honesto sobre la incertidumbre - si no est√°s seguro, dilo claramente
4. Basa tus an√°lisis en datos concretos, no en especulaciones
5. El r√©gimen de mercado determina qu√© tipo de operaciones son apropiadas"""

# Descripci√≥n de reg√≠menes
REGIME_DESCRIPTIONS = """
REG√çMENES DE MERCADO:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚Ä¢ BULL (Alcista):
  - Tendencia clara al alza
  - Estrategias recomendadas: Momentum, seguimiento de tendencia
  - Riesgo: Medio - buscar pullbacks para entrar

‚Ä¢ BEAR (Bajista):
  - Tendencia clara a la baja
  - Estrategias recomendadas: SOLO cierres de posiciones largas
  - Riesgo: Alto - preservar capital, no abrir nuevas posiciones largas

‚Ä¢ SIDEWAYS (Lateral):
  - Sin tendencia clara, rango definido
  - Estrategias recomendadas: Mean reversion, comprar soporte, vender resistencia
  - Riesgo: Medio - stops ajustados

‚Ä¢ VOLATILE (Vol√°til):
  - Alta incertidumbre, movimientos err√°ticos
  - Estrategias recomendadas: NINGUNA - esperar claridad
  - Riesgo: Muy alto - quedarse en cash
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"""

# Instrucciones de an√°lisis t√©cnico
TECHNICAL_ANALYSIS_GUIDE = """
GU√çA DE AN√ÅLISIS T√âCNICO:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
RSI (Relative Strength Index):
  ‚Ä¢ < 30: Sobreventa - posible rebote
  ‚Ä¢ 30-70: Zona neutral
  ‚Ä¢ > 70: Sobrecompra - posible correcci√≥n

MACD:
  ‚Ä¢ Histograma positivo creciente: Momentum alcista fuerte
  ‚Ä¢ Histograma negativo decreciente: Momentum bajista fuerte
  ‚Ä¢ Cruce de l√≠nea de se√±al: Posible cambio de tendencia

Medias M√≥viles (SMA):
  ‚Ä¢ Precio > SMA50 > SMA200: Tendencia alcista confirmada
  ‚Ä¢ Precio < SMA50 < SMA200: Tendencia bajista confirmada
  ‚Ä¢ Golden Cross (SMA50 cruza SMA200 al alza): Se√±al alcista
  ‚Ä¢ Death Cross (SMA50 cruza SMA200 a la baja): Se√±al bajista

ADX (Average Directional Index):
  ‚Ä¢ < 20: Tendencia d√©bil o inexistente
  ‚Ä¢ 20-40: Tendencia moderada
  ‚Ä¢ > 40: Tendencia fuerte

Bollinger Bands:
  ‚Ä¢ Precio en banda superior: Posible sobreextensi√≥n
  ‚Ä¢ Precio en banda inferior: Posible sobreventa
  ‚Ä¢ Bandas estrech√°ndose: Volatilidad baja, posible ruptura pr√≥xima

Volumen:
  ‚Ä¢ > 1.5x promedio: Confirma movimiento
  ‚Ä¢ < 0.5x promedio: Movimiento sospechoso, falta convicci√≥n
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"""

# Formato de respuesta JSON
RESPONSE_FORMAT_BASE = """
FORMATO DE RESPUESTA:
Tu respuesta DEBE ser un JSON v√°lido con la siguiente estructura exacta:

```json
{
  "market_view": "bullish" | "bearish" | "neutral" | "uncertain",
  "confidence": 0.0-1.0,
  "reasoning": "Explicaci√≥n detallada de tu an√°lisis...",
  "key_factors": [
    "Factor 1 considerado",
    "Factor 2 considerado",
    ...
  ],
  "actions": [
    {
      "symbol": "TICKER",
      "direction": "LONG" | "SHORT" | "CLOSE",
      "entry_price": 123.45,
      "stop_loss": 120.00,
      "take_profit": 130.00,
      "size_suggestion": 0.05,
      "reasoning": "Por qu√© esta acci√≥n espec√≠fica"
    }
  ],
  "warnings": [
    "Advertencia 1 si aplica",
    ...
  ]
}
```

IMPORTANTE:
- "actions" puede ser una lista vac√≠a [] si no hay oportunidades claras
- "confidence" refleja tu confianza general en el an√°lisis
- "size_suggestion" es un porcentaje del portfolio (0.05 = 5%)
- NO incluyas comentarios o texto fuera del JSON
"""

# Restricciones de seguridad
SAFETY_RESTRICTIONS = """
RESTRICCIONES DE SEGURIDAD (NUNCA VIOLAR):
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ùå NUNCA sugieras operaciones si risk_limits.can_trade es False
‚ùå NUNCA sugieras posiciones que excedan max_position_pct del portfolio
‚ùå NUNCA sugieras m√°s trades si se alcanz√≥ max_daily_trades
‚ùå NUNCA sugieras operaciones en r√©gimen VOLATILE
‚ùå NUNCA sugieras posiciones largas nuevas en r√©gimen BEAR
‚ùå NUNCA ignores un stop loss - toda posici√≥n DEBE tener stop loss
‚ùå NUNCA sugieras apalancamiento
‚ùå NUNCA bases decisiones solo en una se√±al - busca confluencia
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"""


def build_base_prompt() -> str:
    """Construye la parte base del prompt (com√∫n a todos los niveles)."""
    return "\n\n".join([
        AGENT_IDENTITY,
        REGIME_DESCRIPTIONS,
        TECHNICAL_ANALYSIS_GUIDE,
        SAFETY_RESTRICTIONS,
    ])
```

---

### 10.2 Prompt Conservative

```python
# src/agents/llm/prompts/conservative.py
"""
Prompt para nivel de autonom√≠a CONSERVATIVE.

En este nivel:
- El agente proporciona an√°lisis e informaci√≥n
- NO toma decisiones de trading
- El humano siempre decide
- Enfoque educativo
"""

from .base import build_base_prompt, RESPONSE_FORMAT_BASE

CONSERVATIVE_SPECIFIC = """
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                    NIVEL DE AUTONOM√çA: CONSERVATIVE
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Tu rol en este nivel es INFORMATIVO y EDUCATIVO:

1. AN√ÅLISIS: Proporciona un an√°lisis completo y objetivo del mercado
2. OPINI√ìN: Comparte tu visi√≥n del mercado (bullish/bearish/neutral)
3. OPORTUNIDADES: Identifica posibles oportunidades, pero NO las ejecutes
4. EDUCACI√ìN: Explica el razonamiento detr√°s de cada observaci√≥n

‚ö†Ô∏è IMPORTANTE EN ESTE NIVEL:
- NO debes incluir acciones ejecutables en tu respuesta
- El campo "actions" SIEMPRE debe estar vac√≠o: []
- Tu rol es informar, el humano decide
- S√© detallado en el reasoning para que el humano aprenda

EJEMPLO DE RESPUESTA CORRECTA:
```json
{
  "market_view": "bullish",
  "confidence": 0.7,
  "reasoning": "El r√©gimen actual es BULL con alta confianza (75%). SPY muestra momentum positivo con RSI en 58 (neutral-alcista). VWCE.DE presenta una oportunidad interesante: precio sobre SMA50, MACD positivo, y volumen 20% sobre media. Sin embargo, est√° cerca de resistencia en 112‚Ç¨. Un pullback hacia 108‚Ç¨ ser√≠a una mejor entrada.",
  "key_factors": [
    "R√©gimen BULL confirmado",
    "VIX bajo (18.5) indica baja volatilidad",
    "VWCE.DE con momentum positivo",
    "Resistencia cercana limita upside inmediato"
  ],
  "actions": [],
  "warnings": [
    "Resistencia en 112‚Ç¨ podr√≠a limitar subida a corto plazo",
    "Considerar esperar pullback para mejor R/R"
  ]
}
```

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"""

CONSERVATIVE_RESPONSE_FORMAT = """
FORMATO DE RESPUESTA (CONSERVATIVE):
Tu respuesta DEBE ser JSON v√°lido:

```json
{
  "market_view": "bullish" | "bearish" | "neutral" | "uncertain",
  "confidence": 0.0-1.0,
  "reasoning": "An√°lisis detallado y educativo...",
  "key_factors": ["Factor 1", "Factor 2", ...],
  "actions": [],  // SIEMPRE vac√≠o en este nivel
  "warnings": ["Advertencia si aplica"]
}
```

Recuerda: actions = [] siempre. Tu rol es informar.
"""


def get_conservative_prompt() -> str:
    """Obtiene el system prompt completo para nivel CONSERVATIVE."""
    return "\n\n".join([
        build_base_prompt(),
        CONSERVATIVE_SPECIFIC,
        CONSERVATIVE_RESPONSE_FORMAT,
    ])
```

---

### 10.3 Prompt Moderate

```python
# src/agents/llm/prompts/moderate.py
"""
Prompt para nivel de autonom√≠a MODERATE.

En este nivel:
- El agente sugiere operaciones concretas
- Incluye sizing recomendado
- El humano debe confirmar antes de ejecutar
- Balance entre autonom√≠a y control
"""

from .base import build_base_prompt

MODERATE_SPECIFIC = """
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                    NIVEL DE AUTONOM√çA: MODERATE
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Tu rol en este nivel es de ASESOR ACTIVO:

1. AN√ÅLISIS: Proporciona an√°lisis completo del mercado
2. RECOMENDACIONES: Sugiere operaciones concretas cuando veas oportunidades
3. SIZING: Calcula tama√±o de posici√≥n apropiado (respetando l√≠mites)
4. NIVELES: Define entry, stop loss y take profit espec√≠ficos
5. CONFIRMACI√ìN: El humano revisar√° y confirmar√° antes de ejecutar

REGLAS PARA SUGERIR OPERACIONES:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚úì Solo sugiere cuando hay confluencia de se√±ales (m√≠nimo 2-3 indicadores)
‚úì Risk/Reward m√≠nimo de 1:1.5 (preferible 1:2 o mejor)
‚úì Stop loss m√°ximo: 2% del precio de entrada
‚úì size_suggestion m√°ximo: 5% del portfolio
‚úì M√°ximo 2 operaciones por an√°lisis
‚úì Prioriza calidad sobre cantidad

CU√ÅNDO NO SUGERIR OPERACIONES:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚úó R√©gimen VOLATILE o BEAR (para longs)
‚úó VIX > 25 (alta incertidumbre)
‚úó Se√±ales contradictorias entre indicadores
‚úó Cerca de earnings o eventos importantes
‚úó Volumen muy bajo (< 0.5x promedio)
‚úó L√≠mites de riesgo alcanzados
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

C√ÅLCULO DE SIZE SUGGESTION:
1. Determina riesgo por trade: (entry - stop_loss) / entry
2. Si riesgo > 2%, reduce position size o ajusta stop
3. size_suggestion = min(max_position_pct, risk_budget / trade_risk)
4. Nunca exceder 5% del portfolio en una sola posici√≥n

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"""

MODERATE_RESPONSE_FORMAT = """
FORMATO DE RESPUESTA (MODERATE):
Tu respuesta DEBE ser JSON v√°lido:

```json
{
  "market_view": "bullish" | "bearish" | "neutral" | "uncertain",
  "confidence": 0.0-1.0,
  "reasoning": "An√°lisis completo y justificaci√≥n de recomendaciones...",
  "key_factors": [
    "Factor 1 que soporta la decisi√≥n",
    "Factor 2...",
    ...
  ],
  "actions": [
    {
      "symbol": "VWCE.DE",
      "direction": "LONG",
      "entry_price": 108.50,
      "stop_loss": 106.35,
      "take_profit": 114.20,
      "size_suggestion": 0.04,
      "reasoning": "Pullback a SMA20 en tendencia alcista, RSI 45 desde sobreventa, MACD positivo. R/R = 1:2.6"
    }
  ],
  "warnings": [
    "Requiere confirmaci√≥n del usuario",
    "Earnings de componentes importantes pr√≥xima semana"
  ]
}
```

IMPORTANTE:
- size_suggestion entre 0.01 (1%) y 0.05 (5%)
- Stop loss OBLIGATORIO en cada acci√≥n
- Risk/Reward impl√≠cito debe ser ‚â• 1.5
- Si no hay buenas oportunidades, actions = []
"""


def get_moderate_prompt() -> str:
    """Obtiene el system prompt completo para nivel MODERATE."""
    return "\n\n".join([
        build_base_prompt(),
        MODERATE_SPECIFIC,
        MODERATE_RESPONSE_FORMAT,
    ])
```

---

### 10.4 Prompt Experimental

```python
# src/agents/llm/prompts/experimental.py
"""
Prompt para nivel de autonom√≠a EXPERIMENTAL.

En este nivel:
- El agente puede tomar decisiones aut√≥nomas
- L√≠mites m√°s estrictos como salvaguarda
- Solo para usuarios experimentados
- Requiere kill switches activos
"""

from .base import build_base_prompt

EXPERIMENTAL_SPECIFIC = """
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                    NIVEL DE AUTONOM√çA: EXPERIMENTAL
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚ö†Ô∏è MODO DE ALTA AUTONOM√çA - L√çMITES ESTRICTOS ACTIVOS ‚ö†Ô∏è

Tu rol en este nivel es de OPERADOR AUT√ìNOMO con l√≠mites:

1. AN√ÅLISIS: Eval√∫a el mercado de forma continua
2. DECISI√ìN: Toma decisiones de trading dentro de l√≠mites
3. EJECUCI√ìN: Las acciones se enviar√°n para ejecuci√≥n autom√°tica
4. RESPONSABILIDAD: Cada decisi√≥n debe estar bien fundamentada

L√çMITES ESTRICTOS (NUNCA EXCEDER):
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚Ä¢ size_suggestion M√ÅXIMO: 2% del portfolio (m√°s conservador que moderate)
‚Ä¢ Stop loss M√ÅXIMO: 1.5% del precio de entrada
‚Ä¢ Risk/Reward M√çNIMO: 1:2 (m√°s exigente)
‚Ä¢ M√ÅXIMO 1 operaci√≥n nueva por an√°lisis
‚Ä¢ Solo operar en r√©gimen BULL o SIDEWAYS
‚Ä¢ VIX debe ser < 22
‚Ä¢ Confianza m√≠nima: 0.7 para ejecutar
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

CRITERIOS PARA ACCI√ìN AUTOM√ÅTICA:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Para que una acci√≥n se ejecute autom√°ticamente TODOS estos criterios:

‚úì R√©gimen = BULL o SIDEWAYS
‚úì risk_limits.can_trade = True
‚úì VIX < 22
‚úì Confluencia de 3+ indicadores
‚úì Volumen > promedio
‚úì No hay resistencia/soporte importante en camino al target
‚úì R/R ‚â• 2
‚úì Tu confianza ‚â• 0.7
‚úì size_suggestion ‚â§ 0.02 (2%)

Si CUALQUIER criterio no se cumple ‚Üí actions = []
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

CUANDO ALGO SALE MAL:
Si tienes CUALQUIER duda sobre una operaci√≥n ‚Üí NO la hagas
Es mejor perder una oportunidad que perder capital
La preservaci√≥n del capital es siempre la prioridad

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"""

EXPERIMENTAL_RESPONSE_FORMAT = """
FORMATO DE RESPUESTA (EXPERIMENTAL):
Tu respuesta DEBE ser JSON v√°lido:

```json
{
  "market_view": "bullish" | "bearish" | "neutral" | "uncertain",
  "confidence": 0.0-1.0,
  "reasoning": "An√°lisis detallado con justificaci√≥n clara de cada decisi√≥n...",
  "key_factors": [
    "Criterio 1 cumplido",
    "Criterio 2 cumplido",
    "Criterio 3 cumplido",
    ...
  ],
  "actions": [
    {
      "symbol": "VWCE.DE",
      "direction": "LONG",
      "entry_price": 108.50,
      "stop_loss": 106.90,
      "take_profit": 112.70,
      "size_suggestion": 0.02,
      "reasoning": "Todos los criterios cumplidos: R√©gimen BULL (75%), VIX 18.5, RSI 42, MACD+, Vol 1.2x. R/R = 2.6. Stop 1.5%, Size 2%."
    }
  ],
  "warnings": [
    "‚ö†Ô∏è MODO AUTOM√ÅTICO - Verificar kill switch activo",
    "Earnings de ASML (componente) en 5 d√≠as"
  ]
}
```

CR√çTICO:
- confidence < 0.7 ‚Üí actions DEBE ser []
- size_suggestion > 0.02 ‚Üí RECHAZADO
- Solo 1 acci√≥n m√°ximo
- Incluir SIEMPRE warning sobre modo autom√°tico
"""

KILL_SWITCH_REMINDER = """
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                        üõë KILL SWITCH REMINDER üõë
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Antes de operar en modo EXPERIMENTAL, verificar que:

1. Kill switch de emergencia est√° ACTIVO y accesible
2. L√≠mites diarios configurados en el broker
3. Stop losses est√°n siendo respetados por el sistema
4. Alertas de Telegram configuradas y funcionando
5. El usuario ha revisado y aceptado los riesgos

Si cualquiera de estos puntos no est√° confirmado ‚Üí NO OPERAR
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"""


def get_experimental_prompt() -> str:
    """Obtiene el system prompt completo para nivel EXPERIMENTAL."""
    return "\n\n".join([
        build_base_prompt(),
        EXPERIMENTAL_SPECIFIC,
        EXPERIMENTAL_RESPONSE_FORMAT,
        KILL_SWITCH_REMINDER,
    ])
```

---

### 10.5 Prompt Manager

```python
# src/agents/llm/prompts/__init__.py
"""
Prompt Manager - Gesti√≥n centralizada de prompts por nivel de autonom√≠a.
"""

from typing import Callable
from src.agents.llm.interfaces import AutonomyLevel

from .conservative import get_conservative_prompt
from .moderate import get_moderate_prompt
from .experimental import get_experimental_prompt


# Registry de prompts por nivel
_PROMPT_REGISTRY: dict[AutonomyLevel, Callable[[], str]] = {
    AutonomyLevel.CONSERVATIVE: get_conservative_prompt,
    AutonomyLevel.MODERATE: get_moderate_prompt,
    AutonomyLevel.EXPERIMENTAL: get_experimental_prompt,
}


def get_system_prompt(autonomy_level: AutonomyLevel) -> str:
    """
    Obtiene el system prompt para el nivel de autonom√≠a dado.
    
    Args:
        autonomy_level: Nivel de autonom√≠a
    
    Returns:
        System prompt completo
    
    Raises:
        ValueError: Si el nivel no est√° registrado
    """
    if autonomy_level not in _PROMPT_REGISTRY:
        raise ValueError(f"Unknown autonomy level: {autonomy_level}")
    
    return _PROMPT_REGISTRY[autonomy_level]()


def get_prompt_token_estimate(autonomy_level: AutonomyLevel) -> int:
    """
    Estima tokens del system prompt (aproximado).
    
    Args:
        autonomy_level: Nivel de autonom√≠a
    
    Returns:
        Estimaci√≥n de tokens (chars / 4 aproximadamente)
    """
    prompt = get_system_prompt(autonomy_level)
    return len(prompt) // 4


__all__ = [
    "get_system_prompt",
    "get_prompt_token_estimate",
]
```

---

## 11. Tarea B2.4: Claude Agent Implementation

**Objetivo:** Implementar el agente concreto para Claude/Anthropic.

**Archivo:** `src/agents/llm/agents/claude_agent.py`

```python
# src/agents/llm/agents/claude_agent.py
"""
Claude Agent - Implementaci√≥n del LLM Agent usando Anthropic Claude.

Esta es la implementaci√≥n principal del AI Agent para trading.
"""

from __future__ import annotations

import json
import time
import uuid
import logging
from datetime import datetime
from typing import Optional, Any

import anthropic
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
)

from src.agents.llm.interfaces import (
    LLMAgent,
    AgentContext,
    AgentDecision,
    AutonomyLevel,
    MarketView,
    LLMAPIError,
    LLMRateLimitError,
    LLMParseError,
    LLMTimeoutError,
    LLMContextTooLargeError,
)
from src.agents.llm.prompts import get_system_prompt
from src.strategies.interfaces import Signal


logger = logging.getLogger(__name__)


class ClaudeAgent(LLMAgent):
    """
    Implementaci√≥n del LLM Agent usando Claude de Anthropic.
    
    Caracter√≠sticas:
    - Soporte para claude-sonnet-4-20250514 (recomendado) y otros modelos
    - Retry autom√°tico con backoff exponencial
    - Parsing robusto de respuestas JSON
    - Estimaci√≥n de tokens
    - Health check de API
    """
    
    # L√≠mites de contexto por modelo (aproximados)
    MODEL_CONTEXT_LIMITS = {
        "claude-sonnet-4-20250514": 200000,
        "claude-3-5-sonnet-20241022": 200000,
        "claude-3-opus-20240229": 200000,
        "claude-3-haiku-20240307": 200000,
    }
    
    def __init__(
        self,
        api_key: str,
        model: str = "claude-sonnet-4-20250514",
        max_tokens: int = 2000,
        temperature: float = 0.3,
        default_autonomy: AutonomyLevel = AutonomyLevel.MODERATE,
        timeout_seconds: float = 60.0,
    ):
        """
        Inicializa el Claude Agent.
        
        Args:
            api_key: API key de Anthropic
            model: Modelo a usar
            max_tokens: M√°ximo de tokens en respuesta
            temperature: Temperatura para generaci√≥n (0-1)
            default_autonomy: Nivel de autonom√≠a por defecto
            timeout_seconds: Timeout para llamadas API
        """
        self._api_key = api_key
        self._model = model
        self._max_tokens = max_tokens
        self._temperature = temperature
        self._default_autonomy = default_autonomy
        self._timeout = timeout_seconds
        
        # Cliente de Anthropic
        self._client = anthropic.Anthropic(api_key=api_key)
        
        # M√©tricas internas
        self._total_calls = 0
        self._total_tokens = 0
        self._last_error: Optional[str] = None
        self._last_call_time: Optional[datetime] = None
        
        logger.info(f"ClaudeAgent initialized with model={model}, autonomy={default_autonomy.value}")
    
    @property
    def agent_id(self) -> str:
        return f"claude_{self._model.split('-')[1]}_{self._default_autonomy.value}"
    
    @property
    def model_name(self) -> str:
        return self._model
    
    @property
    def supports_streaming(self) -> bool:
        return True  # Claude soporta streaming
    
    @retry(
        retry=retry_if_exception_type((anthropic.RateLimitError, anthropic.APIConnectionError)),
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=30),
    )
    async def decide(
        self,
        context: AgentContext,
        autonomy_level: Optional[AutonomyLevel] = None
    ) -> AgentDecision:
        """
        Toma una decisi√≥n de trading basada en el contexto.
        
        Args:
            context: Contexto completo del mercado
            autonomy_level: Override del nivel de autonom√≠a
        
        Returns:
            AgentDecision con acciones y razonamiento
        """
        autonomy = autonomy_level or self._default_autonomy
        decision_id = f"dec_{uuid.uuid4().hex[:12]}"
        
        logger.info(f"Making decision {decision_id} with autonomy={autonomy.value}")
        
        # Verificar si debemos saltar
        should_skip, skip_reason = self.should_skip_decision(context)
        if should_skip:
            logger.info(f"Skipping decision: {skip_reason}")
            return self._create_skip_decision(
                decision_id=decision_id,
                context=context,
                autonomy=autonomy,
                reason=skip_reason
            )
        
        # Verificar contexto
        is_valid, issues = self.validate_context(context)
        if not is_valid:
            logger.warning(f"Context validation issues: {issues}")
        
        # Estimar tokens y verificar l√≠mites
        estimated_tokens = self.estimate_tokens(context)
        max_context = self.MODEL_CONTEXT_LIMITS.get(self._model, 100000)
        if estimated_tokens > max_context * 0.9:
            raise LLMContextTooLargeError(
                f"Context too large: {estimated_tokens} tokens",
                tokens_needed=estimated_tokens,
                tokens_available=max_context
            )
        
        # Construir prompts
        system_prompt = self.get_system_prompt(autonomy)
        user_prompt = context.to_prompt_text()
        
        # Llamar a Claude
        start_time = time.time()
        try:
            response = self._client.messages.create(
                model=self._model,
                max_tokens=self._max_tokens,
                temperature=self._temperature,
                system=system_prompt,
                messages=[
                    {"role": "user", "content": user_prompt}
                ],
                timeout=self._timeout,
            )
        except anthropic.RateLimitError as e:
            self._last_error = str(e)
            raise LLMRateLimitError(str(e), retry_after=60)
        except anthropic.APITimeoutError as e:
            self._last_error = str(e)
            raise LLMTimeoutError(str(e), timeout_seconds=self._timeout)
        except anthropic.APIError as e:
            self._last_error = str(e)
            raise LLMAPIError(str(e), status_code=getattr(e, 'status_code', None))
        
        latency_ms = (time.time() - start_time) * 1000
        
        # Actualizar m√©tricas
        self._total_calls += 1
        self._total_tokens += response.usage.input_tokens + response.usage.output_tokens
        self._last_call_time = datetime.utcnow()
        
        # Parsear respuesta
        raw_content = response.content[0].text
        parsed = self._parse_response(raw_content, context, autonomy)
        
        # Construir decisi√≥n
        decision = AgentDecision(
            decision_id=decision_id,
            context_id=context.context_id,
            timestamp=datetime.utcnow(),
            actions=parsed["actions"],
            market_view=parsed["market_view"],
            reasoning=parsed["reasoning"],
            key_factors=parsed["key_factors"],
            confidence=parsed["confidence"],
            model_used=self._model,
            autonomy_level=autonomy,
            tokens_used=response.usage.input_tokens + response.usage.output_tokens,
            latency_ms=latency_ms,
            warnings=parsed.get("warnings", [])
        )
        
        logger.info(
            f"Decision {decision_id} complete: "
            f"view={decision.market_view.value}, "
            f"actions={len(decision.actions)}, "
            f"confidence={decision.confidence:.2f}, "
            f"latency={latency_ms:.0f}ms"
        )
        
        return decision
    
    def get_system_prompt(self, autonomy_level: AutonomyLevel) -> str:
        """Obtiene el system prompt para el nivel de autonom√≠a."""
        return get_system_prompt(autonomy_level)
    
    async def health_check(self) -> dict:
        """Verifica estado del agente y conexi√≥n a Anthropic."""
        try:
            # Llamada m√≠nima para verificar API
            start = time.time()
            response = self._client.messages.create(
                model=self._model,
                max_tokens=10,
                messages=[{"role": "user", "content": "ping"}],
                timeout=10,
            )
            latency = (time.time() - start) * 1000
            
            return {
                "status": "healthy",
                "model": self._model,
                "latency_ms": latency,
                "total_calls": self._total_calls,
                "total_tokens": self._total_tokens,
                "last_error": None
            }
        except Exception as e:
            return {
                "status": "unhealthy",
                "model": self._model,
                "latency_ms": None,
                "total_calls": self._total_calls,
                "total_tokens": self._total_tokens,
                "last_error": str(e)
            }
    
    def estimate_tokens(self, context: AgentContext) -> int:
        """Estima tokens para el contexto dado."""
        # Estimaci√≥n simple: chars / 4
        # En producci√≥n, usar tiktoken o la API de Anthropic
        prompt_text = context.to_prompt_text()
        system_prompt = self.get_system_prompt(context.autonomy_level)
        total_chars = len(prompt_text) + len(system_prompt)
        return total_chars // 4
    
    def _parse_response(
        self,
        raw_response: str,
        context: AgentContext,
        autonomy: AutonomyLevel
    ) -> dict:
        """
        Parsea la respuesta del LLM a estructura interna.
        
        Args:
            raw_response: Texto raw de Claude
            context: Contexto original
            autonomy: Nivel de autonom√≠a
        
        Returns:
            Dict con campos parseados
        
        Raises:
            LLMParseError: Si no se puede parsear
        """
        # Intentar extraer JSON del response
        try:
            # Buscar JSON en la respuesta (puede estar envuelto en markdown)
            json_str = self._extract_json(raw_response)
            data = json.loads(json_str)
        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f"Failed to parse JSON: {e}\nRaw: {raw_response[:500]}")
            raise LLMParseError(f"Invalid JSON response: {e}", raw_response=raw_response)
        
        # Validar campos requeridos
        required_fields = ["market_view", "confidence", "reasoning", "key_factors", "actions"]
        for field in required_fields:
            if field not in data:
                raise LLMParseError(f"Missing required field: {field}", raw_response=raw_response)
        
        # Parsear market_view
        try:
            market_view = MarketView(data["market_view"])
        except ValueError:
            logger.warning(f"Unknown market_view: {data['market_view']}, defaulting to UNCERTAIN")
            market_view = MarketView.UNCERTAIN
        
        # Parsear acciones a Signal
        actions = []
        for action_data in data.get("actions", []):
            try:
                signal = self._parse_action_to_signal(action_data, context)
                actions.append(signal)
            except (KeyError, ValueError) as e:
                logger.warning(f"Failed to parse action: {e}, skipping")
                continue
        
        # Validar acciones seg√∫n autonom√≠a
        if autonomy == AutonomyLevel.CONSERVATIVE and actions:
            logger.warning("Conservative mode should not have actions, clearing")
            actions = []
        
        if autonomy == AutonomyLevel.EXPERIMENTAL and len(actions) > 1:
            logger.warning("Experimental mode limited to 1 action, keeping first")
            actions = actions[:1]
        
        return {
            "market_view": market_view,
            "confidence": max(0.0, min(1.0, float(data["confidence"]))),
            "reasoning": str(data["reasoning"]),
            "key_factors": list(data["key_factors"]),
            "actions": actions,
            "warnings": data.get("warnings", [])
        }
    
    def _extract_json(self, text: str) -> str:
        """Extrae JSON de texto que puede tener markdown u otro formato."""
        # Intentar encontrar bloque de c√≥digo JSON
        import re
        
        # Patr√≥n: ```json ... ``` o ``` ... ```
        code_block = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', text)
        if code_block:
            return code_block.group(1)
        
        # Intentar encontrar JSON directo (empieza con {)
        json_match = re.search(r'\{[\s\S]*\}', text)
        if json_match:
            return json_match.group(0)
        
        # √öltimo recurso: devolver todo
        return text
    
    def _parse_action_to_signal(self, action_data: dict, context: AgentContext) -> Signal:
        """Convierte datos de acci√≥n del LLM a Signal."""
        return Signal(
            strategy_id=f"ai_agent_{context.autonomy_level.value}",
            symbol=action_data["symbol"],
            direction=action_data["direction"].upper(),
            confidence=float(action_data.get("confidence", 0.7)),
            entry_price=float(action_data["entry_price"]),
            stop_loss=float(action_data["stop_loss"]),
            take_profit=float(action_data["take_profit"]),
            size_suggestion=float(action_data.get("size_suggestion", 0.02)),
            regime_at_signal=context.regime.regime,
            reasoning=action_data.get("reasoning", ""),
            metadata={
                "agent_id": self.agent_id,
                "model": self._model,
                "autonomy_level": context.autonomy_level.value,
                "context_id": context.context_id
            }
        )
    
    def _create_skip_decision(
        self,
        decision_id: str,
        context: AgentContext,
        autonomy: AutonomyLevel,
        reason: str
    ) -> AgentDecision:
        """Crea una decisi√≥n vac√≠a cuando se salta el an√°lisis."""
        return AgentDecision(
            decision_id=decision_id,
            context_id=context.context_id,
            timestamp=datetime.utcnow(),
            actions=[],
            market_view=MarketView.UNCERTAIN,
            reasoning=f"Decision skipped: {reason}",
            key_factors=[reason],
            confidence=0.0,
            model_used=self._model,
            autonomy_level=autonomy,
            tokens_used=0,
            latency_ms=0,
            warnings=[f"‚ö†Ô∏è {reason}"]
        )
```

---

## 12. Tarea B2.5: Rate Limiter

**Archivo:** `src/agents/llm/rate_limiter.py`

```python
# src/agents/llm/rate_limiter.py
"""
Rate Limiter - Protecci√≥n contra exceso de llamadas a APIs de LLM.

Implementa rate limiting para:
- Respetar l√≠mites de Anthropic API
- Controlar costos
- Evitar ban por abuso
"""

from __future__ import annotations

import asyncio
import time
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Optional
import logging

from aiolimiter import AsyncLimiter


logger = logging.getLogger(__name__)


@dataclass
class RateLimitConfig:
    """Configuraci√≥n de rate limiting."""
    requests_per_minute: int = 50      # RPM
    tokens_per_minute: int = 40000     # TPM
    requests_per_day: int = 5000       # RPD
    cooldown_seconds: float = 1.0      # Tiempo m√≠nimo entre requests


class RateLimiter:
    """
    Rate limiter para llamadas a LLM APIs.
    
    Implementa m√∫ltiples niveles de limiting:
    - Por minuto (requests y tokens)
    - Por d√≠a (requests)
    - Cooldown entre requests
    """
    
    def __init__(self, config: Optional[RateLimitConfig] = None):
        """
        Inicializa el rate limiter.
        
        Args:
            config: Configuraci√≥n de l√≠mites
        """
        self.config = config or RateLimitConfig()
        
        # Limiters
        self._rpm_limiter = AsyncLimiter(
            self.config.requests_per_minute,
            time_period=60
        )
        self._tpm_limiter = AsyncLimiter(
            self.config.tokens_per_minute,
            time_period=60
        )
        
        # Contadores diarios
        self._daily_requests = 0
        self._daily_reset_time = self._next_daily_reset()
        
        # Cooldown tracking
        self._last_request_time: Optional[float] = None
        
        logger.info(f"RateLimiter initialized: {self.config}")
    
    async def acquire(self, estimated_tokens: int = 1000) -> bool:
        """
        Adquiere permiso para hacer una request.
        
        Args:
            estimated_tokens: Tokens estimados para la request
        
        Returns:
            True si se puede proceder, False si est√° limitado
        
        Raises:
            RateLimitExceeded: Si se excede alg√∫n l√≠mite
        """
        # Verificar reset diario
        self._check_daily_reset()
        
        # Verificar l√≠mite diario
        if self._daily_requests >= self.config.requests_per_day:
            logger.warning("Daily request limit reached")
            return False
        
        # Cooldown
        if self._last_request_time:
            elapsed = time.time() - self._last_request_time
            if elapsed < self.config.cooldown_seconds:
                await asyncio.sleep(self.config.cooldown_seconds - elapsed)
        
        # Adquirir RPM
        await self._rpm_limiter.acquire()
        
        # Adquirir TPM (por tokens estimados)
        for _ in range(max(1, estimated_tokens // 1000)):
            await self._tpm_limiter.acquire()
        
        # Actualizar contadores
        self._daily_requests += 1
        self._last_request_time = time.time()
        
        return True
    
    def get_status(self) -> dict:
        """Obtiene estado actual del rate limiter."""
        return {
            "daily_requests": self._daily_requests,
            "daily_limit": self.config.requests_per_day,
            "daily_remaining": self.config.requests_per_day - self._daily_requests,
            "reset_time": self._daily_reset_time.isoformat(),
            "rpm_limit": self.config.requests_per_minute,
            "tpm_limit": self.config.tokens_per_minute,
        }
    
    def _check_daily_reset(self):
        """Verifica y ejecuta reset diario si corresponde."""
        now = datetime.utcnow()
        if now >= self._daily_reset_time:
            logger.info(f"Daily reset: {self._daily_requests} requests used")
            self._daily_requests = 0
            self._daily_reset_time = self._next_daily_reset()
    
    def _next_daily_reset(self) -> datetime:
        """Calcula pr√≥ximo tiempo de reset (00:00 UTC)."""
        now = datetime.utcnow()
        tomorrow = now + timedelta(days=1)
        return tomorrow.replace(hour=0, minute=0, second=0, microsecond=0)


# Singleton para uso global
_default_limiter: Optional[RateLimiter] = None


def get_rate_limiter(config: Optional[RateLimitConfig] = None) -> RateLimiter:
    """Obtiene el rate limiter global."""
    global _default_limiter
    if _default_limiter is None:
        _default_limiter = RateLimiter(config)
    return _default_limiter
```

---

*Fin de Parte 3 - Implementaci√≥n Claude Agent + Sistema de Prompts*

---

*Documento de Implementaci√≥n - Fase B2: AI Agent*  
*Nexus Trading - Bot de Trading Aut√≥nomo con IA*  
*Versi√≥n 1.0 - Diciembre 2024*
-e 

---

## Integraci√≥n, Configuraci√≥n y Factory

---

## 13. Tarea B2.6: AIAgentStrategy + Factory

**Objetivo:** Integrar el LLM Agent con el sistema de estrategias existente (Fase B1).

---

### 13.1 LLM Agent Factory

**Archivo:** `src/agents/llm/factory.py`

```python
# src/agents/llm/factory.py
"""
LLM Agent Factory - Crea agentes seg√∫n configuraci√≥n.

Permite cambiar entre Claude, GPT-4, Gemini con solo cambiar config.
"""

from __future__ import annotations

import os
from typing import Optional, Type
import logging

from .interfaces import LLMAgent, AutonomyLevel
from .config import LLMAgentConfig, load_agent_config
from .agents.claude_agent import ClaudeAgent


logger = logging.getLogger(__name__)


# Registry de implementaciones disponibles
_AGENT_REGISTRY: dict[str, Type[LLMAgent]] = {
    "claude": ClaudeAgent,
    # Futuras implementaciones:
    # "openai": OpenAIAgent,
    # "gemini": GeminiAgent,
}


class LLMAgentFactory:
    """
    Factory para crear instancias de LLM Agents.
    
    Uso:
        # Desde configuraci√≥n YAML
        agent = LLMAgentFactory.create_from_config()
        
        # Especificando par√°metros
        agent = LLMAgentFactory.create(
            provider="claude",
            model="claude-sonnet-4-20250514",
            autonomy=AutonomyLevel.MODERATE
        )
    """
    
    @classmethod
    def create_from_config(
        cls,
        config_path: Optional[str] = None
    ) -> LLMAgent:
        """
        Crea un agente desde archivo de configuraci√≥n.
        
        Args:
            config_path: Ruta al archivo YAML (default: config/agents.yaml)
        
        Returns:
            Instancia de LLMAgent configurada
        """
        config = load_agent_config(config_path)
        return cls.create_from_config_object(config)
    
    @classmethod
    def create_from_config_object(cls, config: LLMAgentConfig) -> LLMAgent:
        """
        Crea un agente desde objeto de configuraci√≥n.
        
        Args:
            config: Objeto LLMAgentConfig
        
        Returns:
            Instancia de LLMAgent
        """
        provider = config.active_provider
        
        if provider not in _AGENT_REGISTRY:
            available = list(_AGENT_REGISTRY.keys())
            raise ValueError(f"Unknown provider '{provider}'. Available: {available}")
        
        agent_class = _AGENT_REGISTRY[provider]
        provider_config = config.get_provider_config(provider)
        
        # Obtener API key desde env o config
        api_key = cls._get_api_key(provider, provider_config)
        
        logger.info(f"Creating {provider} agent with model={provider_config.get('model')}")
        
        if provider == "claude":
            return ClaudeAgent(
                api_key=api_key,
                model=provider_config.get("model", "claude-sonnet-4-20250514"),
                max_tokens=provider_config.get("max_tokens", 2000),
                temperature=provider_config.get("temperature", 0.3),
                default_autonomy=AutonomyLevel(config.autonomy_level),
                timeout_seconds=provider_config.get("timeout", 60.0),
            )
        
        # Placeholder para otros providers
        raise NotImplementedError(f"Provider {provider} not yet implemented")
    
    @classmethod
    def create(
        cls,
        provider: str = "claude",
        model: Optional[str] = None,
        autonomy: AutonomyLevel = AutonomyLevel.MODERATE,
        api_key: Optional[str] = None,
        **kwargs
    ) -> LLMAgent:
        """
        Crea un agente con par√°metros expl√≠citos.
        
        Args:
            provider: Nombre del provider (claude, openai, gemini)
            model: Modelo espec√≠fico (usa default del provider si no se especifica)
            autonomy: Nivel de autonom√≠a
            api_key: API key (usa env var si no se especifica)
            **kwargs: Par√°metros adicionales para el agente
        
        Returns:
            Instancia de LLMAgent
        """
        if provider not in _AGENT_REGISTRY:
            raise ValueError(f"Unknown provider: {provider}")
        
        # Defaults por provider
        defaults = {
            "claude": {
                "model": "claude-sonnet-4-20250514",
                "max_tokens": 2000,
                "temperature": 0.3,
            },
            "openai": {
                "model": "gpt-4-turbo",
                "max_tokens": 2000,
                "temperature": 0.3,
            },
        }
        
        provider_defaults = defaults.get(provider, {})
        final_model = model or provider_defaults.get("model")
        final_api_key = api_key or cls._get_api_key(provider, {})
        
        agent_class = _AGENT_REGISTRY[provider]
        
        if provider == "claude":
            return ClaudeAgent(
                api_key=final_api_key,
                model=final_model,
                max_tokens=kwargs.get("max_tokens", provider_defaults.get("max_tokens", 2000)),
                temperature=kwargs.get("temperature", provider_defaults.get("temperature", 0.3)),
                default_autonomy=autonomy,
                timeout_seconds=kwargs.get("timeout", 60.0),
            )
        
        raise NotImplementedError(f"Provider {provider} not yet implemented")
    
    @classmethod
    def _get_api_key(cls, provider: str, config: dict) -> str:
        """Obtiene API key desde config o environment."""
        # Primero intentar desde config
        if "api_key" in config and config["api_key"]:
            return config["api_key"]
        
        # Luego desde environment
        env_vars = {
            "claude": "ANTHROPIC_API_KEY",
            "openai": "OPENAI_API_KEY",
            "gemini": "GOOGLE_API_KEY",
        }
        
        env_var = env_vars.get(provider)
        if env_var:
            api_key = os.environ.get(env_var)
            if api_key:
                return api_key
        
        raise ValueError(
            f"No API key found for {provider}. "
            f"Set {env_var} environment variable or provide in config."
        )
    
    @classmethod
    def list_available_providers(cls) -> list[str]:
        """Lista providers disponibles."""
        return list(_AGENT_REGISTRY.keys())
    
    @classmethod
    def register_provider(cls, name: str, agent_class: Type[LLMAgent]):
        """
        Registra un nuevo provider.
        
        Args:
            name: Nombre del provider
            agent_class: Clase que implementa LLMAgent
        """
        if not issubclass(agent_class, LLMAgent):
            raise TypeError(f"{agent_class} must be a subclass of LLMAgent")
        _AGENT_REGISTRY[name] = agent_class
        logger.info(f"Registered LLM provider: {name}")
```

---

### 13.2 Configuraci√≥n de Agentes

**Archivo:** `src/agents/llm/config.py`

```python
# src/agents/llm/config.py
"""
Configuraci√≥n del LLM Agent.

Carga configuraci√≥n desde YAML y proporciona defaults seguros.
"""

from __future__ import annotations

from dataclasses import dataclass, field
from pathlib import Path
from typing import Optional, Any
import os

import yaml


@dataclass
class LLMAgentConfig:
    """Configuraci√≥n completa del sistema de LLM Agents."""
    
    # Provider activo
    active_provider: str = "claude"
    
    # Nivel de autonom√≠a por defecto
    autonomy_level: str = "moderate"
    
    # Configuraci√≥n por provider
    providers: dict[str, dict[str, Any]] = field(default_factory=dict)
    
    # Rate limiting
    rate_limit: dict[str, int] = field(default_factory=lambda: {
        "requests_per_minute": 50,
        "tokens_per_minute": 40000,
        "requests_per_day": 5000,
    })
    
    # Caching
    cache_enabled: bool = True
    cache_ttl_seconds: int = 300  # 5 minutos
    
    def get_provider_config(self, provider: str) -> dict[str, Any]:
        """Obtiene configuraci√≥n de un provider espec√≠fico."""
        return self.providers.get(provider, {})


def load_agent_config(config_path: Optional[str] = None) -> LLMAgentConfig:
    """
    Carga configuraci√≥n desde archivo YAML.
    
    Args:
        config_path: Ruta al archivo (default: config/agents.yaml)
    
    Returns:
        LLMAgentConfig poblado
    """
    if config_path is None:
        # Buscar en ubicaciones standard
        possible_paths = [
            Path("config/agents.yaml"),
            Path("../config/agents.yaml"),
            Path(os.environ.get("NEXUS_CONFIG_PATH", "")) / "agents.yaml",
        ]
        
        for path in possible_paths:
            if path.exists():
                config_path = str(path)
                break
    
    if config_path and Path(config_path).exists():
        with open(config_path, "r") as f:
            data = yaml.safe_load(f)
        
        return LLMAgentConfig(
            active_provider=data.get("ai_agent", {}).get("active", "claude"),
            autonomy_level=data.get("ai_agent", {}).get("autonomy_level", "moderate"),
            providers=data.get("ai_agent", {}).get("models", {}),
            rate_limit=data.get("ai_agent", {}).get("rate_limit", {}),
            cache_enabled=data.get("ai_agent", {}).get("cache_enabled", True),
            cache_ttl_seconds=data.get("ai_agent", {}).get("cache_ttl_seconds", 300),
        )
    
    # Retornar defaults si no hay archivo
    return LLMAgentConfig()


# Configuraci√≥n por defecto para config/agents.yaml
DEFAULT_CONFIG_YAML = """
# AI Agent Configuration
# Este archivo configura el agente de trading basado en LLM

ai_agent:
  # Provider activo: claude, openai, gemini
  active: "claude"
  
  # Nivel de autonom√≠a por defecto
  # - conservative: Solo informaci√≥n, humano decide
  # - moderate: Sugiere operaciones, requiere confirmaci√≥n
  # - experimental: Ejecuci√≥n aut√≥noma con l√≠mites estrictos
  autonomy_level: "moderate"
  
  # Configuraci√≥n por provider
  models:
    claude:
      model: "claude-sonnet-4-20250514"
      max_tokens: 2000
      temperature: 0.3
      timeout: 60
      # api_key: se lee de ANTHROPIC_API_KEY env var
    
    openai:
      model: "gpt-4-turbo"
      max_tokens: 2000
      temperature: 0.3
      timeout: 60
      # api_key: se lee de OPENAI_API_KEY env var
  
  # Rate limiting para proteger la API
  rate_limit:
    requests_per_minute: 50
    tokens_per_minute: 40000
    requests_per_day: 5000
  
  # Cache de decisiones
  cache_enabled: true
  cache_ttl_seconds: 300  # 5 minutos
"""
```

---

### 13.3 AIAgentStrategy (Wrapper TradingStrategy)

**Archivo:** `src/strategies/swing/ai_agent_strategy.py`

```python
# src/strategies/swing/ai_agent_strategy.py
"""
AI Agent Strategy - Wrapper que integra LLMAgent con el sistema de estrategias.

Esta clase adapta el LLMAgent para que funcione como una TradingStrategy m√°s,
permitiendo su ejecuci√≥n junto con otras estrategias como ETF Momentum.
"""

from __future__ import annotations

import asyncio
import logging
from datetime import datetime
from typing import Optional

from src.strategies.interfaces import TradingStrategy, Signal
from src.agents.llm.interfaces import (
    LLMAgent,
    AgentContext,
    AgentDecision,
    AutonomyLevel,
)
from src.agents.llm.factory import LLMAgentFactory
from src.agents.llm.context_builder import ContextBuilder
from src.agents.llm.rate_limiter import get_rate_limiter


logger = logging.getLogger(__name__)


class AIAgentStrategy(TradingStrategy):
    """
    Estrategia de trading basada en AI Agent (LLM).
    
    Integra el LLMAgent con el sistema de estrategias de Fase B1,
    permitiendo su ejecuci√≥n coordinada con otras estrategias.
    
    Caracter√≠sticas:
    - Se comporta como cualquier otra TradingStrategy
    - Genera Signal[] compatibles con el pipeline existente
    - Respeta los reg√≠menes de mercado
    - Incluye rate limiting y caching
    """
    
    def __init__(
        self,
        llm_agent: Optional[LLMAgent] = None,
        context_builder: Optional[ContextBuilder] = None,
        autonomy_level: AutonomyLevel = AutonomyLevel.MODERATE,
        watchlist: Optional[list[str]] = None,
    ):
        """
        Inicializa la estrategia AI Agent.
        
        Args:
            llm_agent: Instancia de LLMAgent (crea desde config si no se provee)
            context_builder: Builder de contexto (crea default si no se provee)
            autonomy_level: Nivel de autonom√≠a
            watchlist: Lista de s√≠mbolos a analizar
        """
        self._llm_agent = llm_agent or LLMAgentFactory.create_from_config()
        self._context_builder = context_builder
        self._autonomy = autonomy_level
        self._watchlist = watchlist or self._default_watchlist()
        
        # Rate limiter
        self._rate_limiter = get_rate_limiter()
        
        # Cache de √∫ltima decisi√≥n
        self._last_decision: Optional[AgentDecision] = None
        self._last_decision_time: Optional[datetime] = None
        
        logger.info(
            f"AIAgentStrategy initialized: "
            f"agent={self._llm_agent.agent_id}, "
            f"autonomy={self._autonomy.value}, "
            f"watchlist={len(self._watchlist)} symbols"
        )
    
    @property
    def strategy_id(self) -> str:
        return f"ai_agent_{self._autonomy.value}"
    
    @property
    def required_regime(self) -> list[str]:
        """
        Reg√≠menes en los que esta estrategia est√° activa.
        
        AI Agent puede operar en BULL y SIDEWAYS.
        En BEAR y VOLATILE, se pausa autom√°ticamente.
        """
        return ["BULL", "SIDEWAYS"]
    
    def generate_signals(
        self,
        market_data: dict,
        regime: dict,
        portfolio: dict
    ) -> list[Signal]:
        """
        Genera se√±ales de trading usando el LLM Agent.
        
        Este m√©todo es s√≠ncrono para compatibilidad con TradingStrategy,
        pero internamente ejecuta la l√≥gica async del LLM.
        
        Args:
            market_data: Datos de mercado para watchlist
            regime: Informaci√≥n de r√©gimen actual
            portfolio: Estado del portfolio
        
        Returns:
            Lista de Signal generadas por el AI Agent
        """
        # Ejecutar async en event loop
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # Ya estamos en un contexto async
                future = asyncio.ensure_future(
                    self._generate_signals_async(market_data, regime, portfolio)
                )
                return asyncio.get_event_loop().run_until_complete(future)
            else:
                return loop.run_until_complete(
                    self._generate_signals_async(market_data, regime, portfolio)
                )
        except RuntimeError:
            # No hay event loop, crear uno
            return asyncio.run(
                self._generate_signals_async(market_data, regime, portfolio)
            )
    
    async def _generate_signals_async(
        self,
        market_data: dict,
        regime: dict,
        portfolio: dict
    ) -> list[Signal]:
        """Implementaci√≥n async de generate_signals."""
        
        # Verificar rate limiting
        can_proceed = await self._rate_limiter.acquire(estimated_tokens=2000)
        if not can_proceed:
            logger.warning("Rate limit reached, skipping AI Agent analysis")
            return []
        
        # Verificar r√©gimen
        current_regime = regime.get("regime", "UNKNOWN")
        if current_regime not in self.required_regime:
            logger.info(f"AI Agent paused: regime {current_regime} not in {self.required_regime}")
            return []
        
        try:
            # Construir contexto
            context = await self._build_context(market_data, regime, portfolio)
            
            # Obtener decisi√≥n del LLM
            decision = await self._llm_agent.decide(context, self._autonomy)
            
            # Guardar para debugging
            self._last_decision = decision
            self._last_decision_time = datetime.utcnow()
            
            # Log de decisi√≥n
            logger.info(
                f"AI Agent decision: "
                f"view={decision.market_view.value}, "
                f"confidence={decision.confidence:.2f}, "
                f"actions={len(decision.actions)}"
            )
            
            if decision.reasoning:
                logger.debug(f"Reasoning: {decision.reasoning[:200]}...")
            
            return decision.actions
            
        except Exception as e:
            logger.error(f"AI Agent error: {e}", exc_info=True)
            return []
    
    def should_close(
        self,
        position: dict,
        market_data: dict,
        regime: dict
    ) -> Optional[Signal]:
        """
        Determina si una posici√≥n debe cerrarse.
        
        El AI Agent puede recomendar cierres basados en:
        - Cambio de r√©gimen
        - Alcance de stop loss o take profit
        - Cambio en las condiciones que motivaron la entrada
        """
        # Verificar cambio de r√©gimen
        current_regime = regime.get("regime", "UNKNOWN")
        position_regime = position.get("regime_at_entry", "UNKNOWN")
        
        # Si el r√©gimen cambi√≥ a BEAR o VOLATILE, cerrar
        if current_regime in ["BEAR", "VOLATILE"] and position_regime not in ["BEAR", "VOLATILE"]:
            logger.info(f"Closing {position['symbol']}: regime changed to {current_regime}")
            return Signal(
                strategy_id=self.strategy_id,
                symbol=position["symbol"],
                direction="CLOSE",
                confidence=0.9,
                entry_price=None,
                stop_loss=None,
                take_profit=None,
                size_suggestion=1.0,  # Cerrar toda la posici√≥n
                regime_at_signal=current_regime,
                reasoning=f"Regime change: {position_regime} ‚Üí {current_regime}",
                metadata={"close_reason": "regime_change"}
            )
        
        # Verificar stop loss / take profit tradicional
        current_price = market_data.get("current_price", 0)
        stop_loss = position.get("stop_loss", 0)
        take_profit = position.get("take_profit", float("inf"))
        
        if current_price <= stop_loss:
            return Signal(
                strategy_id=self.strategy_id,
                symbol=position["symbol"],
                direction="CLOSE",
                confidence=1.0,
                entry_price=None,
                stop_loss=None,
                take_profit=None,
                size_suggestion=1.0,
                regime_at_signal=current_regime,
                reasoning=f"Stop loss hit: {current_price} <= {stop_loss}",
                metadata={"close_reason": "stop_loss"}
            )
        
        if current_price >= take_profit:
            return Signal(
                strategy_id=self.strategy_id,
                symbol=position["symbol"],
                direction="CLOSE",
                confidence=1.0,
                entry_price=None,
                stop_loss=None,
                take_profit=None,
                size_suggestion=1.0,
                regime_at_signal=current_regime,
                reasoning=f"Take profit hit: {current_price} >= {take_profit}",
                metadata={"close_reason": "take_profit"}
            )
        
        return None
    
    async def _build_context(
        self,
        market_data: dict,
        regime: dict,
        portfolio: dict
    ) -> AgentContext:
        """Construye el contexto para el LLM."""
        if self._context_builder:
            return await self._context_builder.build(
                watchlist=self._watchlist,
                autonomy_level=self._autonomy
            )
        
        # Fallback: construir contexto m√≠nimo desde los datos provistos
        from src.agents.llm.interfaces import (
            RegimeInfo,
            MarketContext,
            PortfolioSummary,
            RiskLimits,
            SymbolData,
        )
        import uuid
        
        return AgentContext(
            context_id=f"ctx_{uuid.uuid4().hex[:12]}",
            timestamp=datetime.utcnow(),
            regime=RegimeInfo(
                regime=regime.get("regime", "SIDEWAYS"),
                confidence=regime.get("confidence", 0.5),
                probabilities=regime.get("probabilities", {}),
                model_id=regime.get("model_id", "unknown")
            ),
            market=MarketContext(
                spy_change_pct=market_data.get("spy_change_pct", 0),
                qqq_change_pct=market_data.get("qqq_change_pct", 0),
                vix_level=market_data.get("vix_level", 20),
                vix_change_pct=market_data.get("vix_change_pct", 0),
                market_breadth=market_data.get("market_breadth", 0.5),
                sector_rotation={}
            ),
            portfolio=PortfolioSummary(
                total_value=portfolio.get("total_value", 25000),
                cash_available=portfolio.get("cash_available", 25000),
                invested_value=portfolio.get("invested_value", 0),
                positions=(),
                daily_pnl=portfolio.get("daily_pnl", 0),
                daily_pnl_pct=portfolio.get("daily_pnl_pct", 0),
                total_pnl=portfolio.get("total_pnl", 0),
                total_pnl_pct=portfolio.get("total_pnl_pct", 0)
            ),
            watchlist=(),  # Se poblar√≠a con datos reales
            risk_limits=RiskLimits(
                max_position_pct=5.0,
                max_portfolio_risk_pct=2.0,
                max_daily_trades=5,
                max_daily_loss_pct=3.0,
                current_daily_trades=0,
                current_daily_pnl_pct=0
            ),
            autonomy_level=self._autonomy
        )
    
    def _default_watchlist(self) -> list[str]:
        """Watchlist por defecto para el AI Agent."""
        return [
            # ETFs EU
            "VWCE.DE",   # Vanguard FTSE All-World
            "CSPX.DE",   # iShares S&P 500
            "EUNL.DE",   # iShares Core MSCI World
            
            # ETFs US
            "SPY",       # S&P 500
            "QQQ",       # Nasdaq 100
            "IWM",       # Russell 2000
            "DIA",       # Dow Jones
        ]
    
    def get_last_decision(self) -> Optional[AgentDecision]:
        """Obtiene la √∫ltima decisi√≥n del agente (para debugging)."""
        return self._last_decision


# Funci√≥n helper para crear estrategia desde config
def create_ai_agent_strategy(
    config_path: Optional[str] = None,
    mcp_client=None
) -> AIAgentStrategy:
    """
    Factory function para crear AIAgentStrategy.
    
    Args:
        config_path: Ruta a config/agents.yaml
        mcp_client: Cliente MCP para context builder
    
    Returns:
        AIAgentStrategy configurada
    """
    from src.agents.llm.config import load_agent_config
    
    config = load_agent_config(config_path)
    agent = LLMAgentFactory.create_from_config_object(config)
    
    context_builder = None
    if mcp_client:
        context_builder = ContextBuilder(
            mcp_client=mcp_client,
            default_autonomy=AutonomyLevel(config.autonomy_level)
        )
    
    return AIAgentStrategy(
        llm_agent=agent,
        context_builder=context_builder,
        autonomy_level=AutonomyLevel(config.autonomy_level)
    )
```

---

## 14. Configuraci√≥n YAML

### 14.1 config/agents.yaml

```yaml
# config/agents.yaml
# Configuraci√≥n del AI Agent para Nexus Trading
# Versi√≥n: 1.0

ai_agent:
  # =========================================================================
  # PROVIDER ACTIVO
  # =========================================================================
  # Provider a usar: claude, openai (futuro), gemini (futuro)
  active: "claude"
  
  # =========================================================================
  # NIVEL DE AUTONOM√çA
  # =========================================================================
  # Controla el comportamiento del agente:
  #
  # conservative:
  #   - Solo proporciona an√°lisis e informaci√≥n
  #   - NO genera acciones de trading
  #   - Ideal para aprender y entender el sistema
  #
  # moderate:
  #   - Sugiere operaciones con sizing
  #   - Requiere confirmaci√≥n del usuario
  #   - Recomendado para paper trading
  #
  # experimental:
  #   - Ejecuci√≥n aut√≥noma con l√≠mites estrictos
  #   - Max 2% por posici√≥n, max 1 trade por ciclo
  #   - REQUIERE kill switches activos
  #   - Solo para usuarios experimentados
  #
  autonomy_level: "moderate"
  
  # =========================================================================
  # CONFIGURACI√ìN DE MODELOS
  # =========================================================================
  models:
    claude:
      # Modelo de Anthropic a usar
      # Opciones: claude-sonnet-4-20250514 (recomendado), claude-3-opus-20240229
      model: "claude-sonnet-4-20250514"
      
      # M√°ximo tokens en respuesta
      max_tokens: 2000
      
      # Temperatura (0-1): m√°s bajo = m√°s determin√≠stico
      temperature: 0.3
      
      # Timeout en segundos para llamadas API
      timeout: 60
      
      # API key: preferir variable de entorno ANTHROPIC_API_KEY
      # api_key: "sk-ant-..."  # NO COMMITEAR
    
    # Placeholder para futuros providers
    openai:
      model: "gpt-4-turbo"
      max_tokens: 2000
      temperature: 0.3
      timeout: 60
    
    gemini:
      model: "gemini-pro"
      max_tokens: 2000
      temperature: 0.3
      timeout: 60
  
  # =========================================================================
  # RATE LIMITING
  # =========================================================================
  # Protege contra exceso de llamadas a la API
  rate_limit:
    # Requests por minuto (Anthropic default: 50)
    requests_per_minute: 50
    
    # Tokens por minuto (Anthropic default: 40,000)
    tokens_per_minute: 40000
    
    # Requests por d√≠a (para controlar costos)
    requests_per_day: 500
  
  # =========================================================================
  # CACHING
  # =========================================================================
  # Cache de contexto y decisiones
  cache_enabled: true
  
  # Tiempo de vida del cache en segundos
  # Decisiones se consideran v√°lidas por este tiempo
  cache_ttl_seconds: 300  # 5 minutos
  
  # =========================================================================
  # WATCHLIST
  # =========================================================================
  # S√≠mbolos que el AI Agent analiza
  watchlist:
    # ETFs Europeos
    - "VWCE.DE"   # Vanguard FTSE All-World
    - "CSPX.DE"   # iShares S&P 500
    - "EUNL.DE"   # iShares Core MSCI World
    
    # ETFs US
    - "SPY"       # S&P 500
    - "QQQ"       # Nasdaq 100
    - "IWM"       # Russell 2000
    - "DIA"       # Dow Jones
```

---

### 14.2 Actualizaci√≥n config/strategies.yaml

```yaml
# config/strategies.yaml
# A√±adir secci√≥n para AI Agent

strategies:
  # ETF Momentum (existente de Fase B1)
  etf_momentum:
    enabled: true
    required_regime: ["BULL"]
    max_positions: 5
    min_momentum_score: 0.6
    rsi_oversold: 35
    rsi_overbought: 75
    
  # AI Agent Strategy (NUEVO)
  ai_agent_swing:
    enabled: true
    required_regime: ["BULL", "SIDEWAYS"]
    
    # Config espec√≠fica
    autonomy_level: "moderate"  # Override del config/agents.yaml si se desea
    
    # L√≠mites para esta estrategia
    max_positions: 3
    max_position_size_pct: 5.0
    
    # Integraci√≥n con otras estrategias
    # Si true, las se√±ales del AI Agent requieren confirmaci√≥n de ETF Momentum
    require_momentum_confirmation: false
    
  # Mean Reversion (futuro)
  mean_reversion:
    enabled: false
    required_regime: ["SIDEWAYS"]
```

---

## 15. Scripts de Verificaci√≥n

### 15.1 Script de Verificaci√≥n de Fase B2

**Archivo:** `scripts/verify_fase_b2.py`

```python
#!/usr/bin/env python3
"""
Script de verificaci√≥n para Fase B2: AI Agent.

Verifica que todos los componentes del AI Agent est√©n correctamente
implementados y funcionando.

Uso:
    python scripts/verify_fase_b2.py
    
Exit codes:
    0: Todos los checks pasaron
    1: Alg√∫n check fall√≥
"""

import sys
import os
import asyncio
from pathlib import Path

# A√±adir src al path
sys.path.insert(0, str(Path(__file__).parent.parent))


def print_header(text: str):
    print(f"\n{'='*60}")
    print(f"  {text}")
    print('='*60)


def print_check(name: str, passed: bool, detail: str = ""):
    status = "‚úÖ" if passed else "‚ùå"
    print(f"  {status} {name}")
    if detail:
        print(f"      {detail}")


def check_imports() -> bool:
    """Verifica que todos los m√≥dulos se pueden importar."""
    print_header("CHECK 1: Imports")
    all_passed = True
    
    modules = [
        ("src.agents.llm.interfaces", "Interfaces base"),
        ("src.agents.llm.factory", "LLM Agent Factory"),
        ("src.agents.llm.config", "Configuraci√≥n"),
        ("src.agents.llm.context_builder", "Context Builder"),
        ("src.agents.llm.rate_limiter", "Rate Limiter"),
        ("src.agents.llm.prompts", "Sistema de Prompts"),
        ("src.agents.llm.agents.claude_agent", "Claude Agent"),
        ("src.strategies.swing.ai_agent_strategy", "AI Agent Strategy"),
    ]
    
    for module_name, description in modules:
        try:
            __import__(module_name)
            print_check(description, True)
        except ImportError as e:
            print_check(description, False, str(e))
            all_passed = False
    
    return all_passed


def check_interfaces() -> bool:
    """Verifica que las interfaces est√©n correctamente definidas."""
    print_header("CHECK 2: Interfaces")
    all_passed = True
    
    try:
        from src.agents.llm.interfaces import (
            AutonomyLevel,
            MarketView,
            AgentContext,
            AgentDecision,
            LLMAgent,
        )
        
        # Verificar AutonomyLevel
        levels = [AutonomyLevel.CONSERVATIVE, AutonomyLevel.MODERATE, AutonomyLevel.EXPERIMENTAL]
        print_check("AutonomyLevel enum", len(levels) == 3, f"Niveles: {[l.value for l in levels]}")
        
        # Verificar MarketView
        views = [MarketView.BULLISH, MarketView.BEARISH, MarketView.NEUTRAL, MarketView.UNCERTAIN]
        print_check("MarketView enum", len(views) == 4)
        
        # Verificar LLMAgent ABC
        from abc import ABC
        print_check("LLMAgent es ABC", issubclass(LLMAgent, ABC))
        
        # Verificar m√©todos abstractos
        abstract_methods = ['agent_id', 'model_name', 'decide', 'get_system_prompt', 'health_check', 'estimate_tokens']
        has_all = all(hasattr(LLMAgent, m) for m in abstract_methods)
        print_check("LLMAgent m√©todos abstractos", has_all)
        
    except Exception as e:
        print_check("Interfaces", False, str(e))
        all_passed = False
    
    return all_passed


def check_prompts() -> bool:
    """Verifica que los prompts est√©n definidos."""
    print_header("CHECK 3: Sistema de Prompts")
    all_passed = True
    
    try:
        from src.agents.llm.prompts import get_system_prompt, get_prompt_token_estimate
        from src.agents.llm.interfaces import AutonomyLevel
        
        for level in AutonomyLevel:
            prompt = get_system_prompt(level)
            tokens = get_prompt_token_estimate(level)
            
            # Verificar que el prompt no est√° vac√≠o y tiene contenido significativo
            has_content = len(prompt) > 1000
            has_format = "json" in prompt.lower()
            has_safety = "nunca" in prompt.lower() or "never" in prompt.lower()
            
            print_check(
                f"Prompt {level.value}",
                has_content and has_format,
                f"~{tokens} tokens, formato JSON: {has_format}"
            )
            
            if not has_content:
                all_passed = False
    
    except Exception as e:
        print_check("Prompts", False, str(e))
        all_passed = False
    
    return all_passed


def check_config_files() -> bool:
    """Verifica que los archivos de configuraci√≥n existan."""
    print_header("CHECK 4: Archivos de Configuraci√≥n")
    all_passed = True
    
    config_files = [
        ("config/agents.yaml", "Config AI Agent"),
    ]
    
    for file_path, description in config_files:
        exists = Path(file_path).exists()
        print_check(description, exists, file_path)
        if not exists:
            all_passed = False
    
    # Verificar que strategies.yaml tiene secci√≥n ai_agent
    strategies_path = Path("config/strategies.yaml")
    if strategies_path.exists():
        content = strategies_path.read_text()
        has_ai_agent = "ai_agent" in content
        print_check("strategies.yaml tiene ai_agent", has_ai_agent)
        if not has_ai_agent:
            all_passed = False
    
    return all_passed


def check_factory() -> bool:
    """Verifica que el factory funcione."""
    print_header("CHECK 5: LLM Agent Factory")
    all_passed = True
    
    try:
        from src.agents.llm.factory import LLMAgentFactory
        
        # Verificar providers disponibles
        providers = LLMAgentFactory.list_available_providers()
        print_check("Providers registrados", "claude" in providers, f"Disponibles: {providers}")
        
        # Verificar creaci√≥n (sin API key, deber√≠a fallar de forma controlada)
        try:
            # Esto fallar√° si no hay API key, pero verifica que el c√≥digo existe
            if os.environ.get("ANTHROPIC_API_KEY"):
                agent = LLMAgentFactory.create(provider="claude")
                print_check("Crear Claude Agent", True, f"ID: {agent.agent_id}")
            else:
                print_check("Crear Claude Agent", True, "Skipped (no API key)")
        except ValueError as e:
            if "API key" in str(e):
                print_check("Crear Claude Agent", True, "Error esperado: no API key")
            else:
                print_check("Crear Claude Agent", False, str(e))
                all_passed = False
    
    except Exception as e:
        print_check("Factory", False, str(e))
        all_passed = False
    
    return all_passed


def check_ai_agent_strategy() -> bool:
    """Verifica que AIAgentStrategy implemente TradingStrategy."""
    print_header("CHECK 6: AI Agent Strategy")
    all_passed = True
    
    try:
        from src.strategies.swing.ai_agent_strategy import AIAgentStrategy
        from src.strategies.interfaces import TradingStrategy
        
        # Verificar herencia
        print_check("Hereda de TradingStrategy", issubclass(AIAgentStrategy, TradingStrategy))
        
        # Verificar propiedades requeridas
        # No podemos instanciar sin agent, pero verificamos que los m√©todos existen
        required_methods = ['strategy_id', 'required_regime', 'generate_signals', 'should_close']
        has_all = all(hasattr(AIAgentStrategy, m) for m in required_methods)
        print_check("M√©todos de TradingStrategy", has_all)
        
    except Exception as e:
        print_check("AI Agent Strategy", False, str(e))
        all_passed = False
    
    return all_passed


async def check_rate_limiter() -> bool:
    """Verifica que el rate limiter funcione."""
    print_header("CHECK 7: Rate Limiter")
    all_passed = True
    
    try:
        from src.agents.llm.rate_limiter import RateLimiter, RateLimitConfig
        
        config = RateLimitConfig(
            requests_per_minute=10,
            requests_per_day=100
        )
        limiter = RateLimiter(config)
        
        # Verificar acquire
        can_proceed = await limiter.acquire(estimated_tokens=100)
        print_check("Rate limiter acquire", can_proceed)
        
        # Verificar status
        status = limiter.get_status()
        print_check("Rate limiter status", "daily_requests" in status, f"Requests: {status['daily_requests']}")
        
    except Exception as e:
        print_check("Rate Limiter", False, str(e))
        all_passed = False
    
    return all_passed


def run_tests() -> bool:
    """Ejecuta tests unitarios."""
    print_header("CHECK 8: Tests Unitarios")
    
    import subprocess
    result = subprocess.run(
        ["python", "-m", "pytest", "tests/agents/llm/", "-v", "--tb=short"],
        capture_output=True,
        text=True
    )
    
    passed = result.returncode == 0
    print_check("pytest tests/agents/llm/", passed)
    
    if not passed:
        print("\n  Output:")
        for line in result.stdout.split('\n')[-20:]:
            print(f"    {line}")
    
    return passed


async def main():
    """Ejecuta todas las verificaciones."""
    print("\n" + "="*60)
    print("    VERIFICACI√ìN FASE B2: AI AGENT")
    print("="*60)
    
    checks = [
        ("Imports", check_imports),
        ("Interfaces", check_interfaces),
        ("Prompts", check_prompts),
        ("Config Files", check_config_files),
        ("Factory", check_factory),
        ("AI Agent Strategy", check_ai_agent_strategy),
    ]
    
    all_passed = True
    
    for name, check_func in checks:
        try:
            if asyncio.iscoroutinefunction(check_func):
                passed = await check_func()
            else:
                passed = check_func()
            if not passed:
                all_passed = False
        except Exception as e:
            print_check(name, False, f"Exception: {e}")
            all_passed = False
    
    # Rate limiter es async
    try:
        passed = await check_rate_limiter()
        if not passed:
            all_passed = False
    except Exception as e:
        print_check("Rate Limiter", False, str(e))
        all_passed = False
    
    # Tests unitarios (opcional)
    if Path("tests/agents/llm").exists():
        try:
            passed = run_tests()
            if not passed:
                all_passed = False
        except Exception as e:
            print_check("Tests", False, str(e))
    
    # Resumen
    print_header("RESUMEN")
    if all_passed:
        print("  ‚úÖ Todos los checks pasaron")
        print("\n  Fase B2 lista para integraci√≥n.")
        print("  Siguiente paso: Fase C1 (Sistema de M√©tricas)")
        return 0
    else:
        print("  ‚ùå Algunos checks fallaron")
        print("\n  Revisar errores antes de continuar.")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
```

---

*Fin de Parte 4 - Integraci√≥n, Configuraci√≥n y Factory*

---

*Documento de Implementaci√≥n - Fase B2: AI Agent*  
*Nexus Trading - Bot de Trading Aut√≥nomo con IA*  
*Versi√≥n 1.0 - Diciembre 2024*
-e 

---

## Tests, Checklist Final y Troubleshooting

---

## 16. Tests Unitarios

### 16.1 Tests de Interfaces

**Archivo:** `tests/agents/llm/test_interfaces.py`

```python
# tests/agents/llm/test_interfaces.py
"""Tests para interfaces del LLM Agent."""

import pytest
from datetime import datetime
from src.agents.llm.interfaces import (
    AutonomyLevel,
    MarketView,
    PortfolioPosition,
    PortfolioSummary,
    SymbolData,
    RegimeInfo,
    RiskLimits,
    MarketContext,
    AgentContext,
    AgentDecision,
    LLMAgent,
    LLMAgentError,
    LLMAPIError,
    LLMRateLimitError,
)
from src.strategies.interfaces import Signal


class TestAutonomyLevel:
    """Tests para AutonomyLevel enum."""
    
    def test_values(self):
        assert AutonomyLevel.CONSERVATIVE.value == "conservative"
        assert AutonomyLevel.MODERATE.value == "moderate"
        assert AutonomyLevel.EXPERIMENTAL.value == "experimental"
    
    def test_from_string(self):
        assert AutonomyLevel("conservative") == AutonomyLevel.CONSERVATIVE
        assert AutonomyLevel("moderate") == AutonomyLevel.MODERATE
    
    def test_invalid_value(self):
        with pytest.raises(ValueError):
            AutonomyLevel("invalid")


class TestPortfolioPosition:
    """Tests para PortfolioPosition dataclass."""
    
    @pytest.fixture
    def position(self):
        return PortfolioPosition(
            symbol="VWCE.DE",
            quantity=10,
            avg_entry_price=100.0,
            current_price=110.0,
            unrealized_pnl=100.0,
            unrealized_pnl_pct=10.0,
            holding_days=5
        )
    
    def test_market_value(self, position):
        assert position.market_value == 1100.0
    
    def test_immutability(self, position):
        with pytest.raises(AttributeError):
            position.quantity = 20


class TestPortfolioSummary:
    """Tests para PortfolioSummary dataclass."""
    
    @pytest.fixture
    def portfolio(self):
        return PortfolioSummary(
            total_value=25000.0,
            cash_available=20000.0,
            invested_value=5000.0,
            positions=(),
            daily_pnl=50.0,
            daily_pnl_pct=0.2,
            total_pnl=500.0,
            total_pnl_pct=2.0
        )
    
    def test_cash_pct(self, portfolio):
        assert portfolio.cash_pct == 80.0
    
    def test_num_positions(self, portfolio):
        assert portfolio.num_positions == 0
    
    def test_cash_pct_zero_total(self):
        portfolio = PortfolioSummary(
            total_value=0,
            cash_available=0,
            invested_value=0,
            positions=(),
            daily_pnl=0,
            daily_pnl_pct=0,
            total_pnl=0,
            total_pnl_pct=0
        )
        assert portfolio.cash_pct == 100.0


class TestRiskLimits:
    """Tests para RiskLimits dataclass."""
    
    def test_can_trade_true(self):
        limits = RiskLimits(
            max_position_pct=5.0,
            max_portfolio_risk_pct=2.0,
            max_daily_trades=5,
            max_daily_loss_pct=3.0,
            current_daily_trades=2,
            current_daily_pnl_pct=-1.0
        )
        assert limits.can_trade is True
        assert limits.remaining_trades == 3
    
    def test_can_trade_false_trades_exhausted(self):
        limits = RiskLimits(
            max_position_pct=5.0,
            max_portfolio_risk_pct=2.0,
            max_daily_trades=5,
            max_daily_loss_pct=3.0,
            current_daily_trades=5,
            current_daily_pnl_pct=0
        )
        assert limits.can_trade is False
        assert limits.remaining_trades == 0
    
    def test_can_trade_false_loss_exceeded(self):
        limits = RiskLimits(
            max_position_pct=5.0,
            max_portfolio_risk_pct=2.0,
            max_daily_trades=5,
            max_daily_loss_pct=3.0,
            current_daily_trades=1,
            current_daily_pnl_pct=-4.0
        )
        assert limits.can_trade is False


class TestAgentContext:
    """Tests para AgentContext dataclass."""
    
    @pytest.fixture
    def context(self):
        return AgentContext(
            context_id="ctx_test123",
            timestamp=datetime(2024, 12, 15, 10, 30, 0),
            regime=RegimeInfo(
                regime="BULL",
                confidence=0.75,
                probabilities={"BULL": 0.75, "BEAR": 0.1, "SIDEWAYS": 0.1, "VOLATILE": 0.05},
                model_id="hmm_v1"
            ),
            market=MarketContext(
                spy_change_pct=0.5,
                qqq_change_pct=0.8,
                vix_level=18.5,
                vix_change_pct=-2.0,
                market_breadth=0.65,
                sector_rotation={}
            ),
            portfolio=PortfolioSummary(
                total_value=25000,
                cash_available=20000,
                invested_value=5000,
                positions=(),
                daily_pnl=50,
                daily_pnl_pct=0.2,
                total_pnl=500,
                total_pnl_pct=2.0
            ),
            watchlist=(),
            risk_limits=RiskLimits(
                max_position_pct=5.0,
                max_portfolio_risk_pct=2.0,
                max_daily_trades=5,
                max_daily_loss_pct=3.0,
                current_daily_trades=1,
                current_daily_pnl_pct=0.2
            ),
            autonomy_level=AutonomyLevel.MODERATE
        )
    
    def test_to_prompt_text_contains_required_sections(self, context):
        text = context.to_prompt_text()
        assert "R√âGIMEN" in text
        assert "PORTFOLIO" in text
        assert "BULL" in text
        assert "MODERATE" in text.lower()
    
    def test_to_dict_serializable(self, context):
        import json
        d = context.to_dict()
        json_str = json.dumps(d)  # No debe lanzar
        assert "context_id" in d
        assert d["context_id"] == "ctx_test123"


class TestAgentDecision:
    """Tests para AgentDecision dataclass."""
    
    def test_confidence_validation_valid(self):
        decision = AgentDecision(
            decision_id="dec_test",
            context_id="ctx_test",
            timestamp=datetime.utcnow(),
            actions=[],
            market_view=MarketView.BULLISH,
            reasoning="Test reasoning",
            key_factors=["factor1"],
            confidence=0.75,
            model_used="claude-sonnet",
            autonomy_level=AutonomyLevel.MODERATE,
            tokens_used=100,
            latency_ms=150
        )
        assert decision.confidence == 0.75
    
    def test_confidence_validation_invalid_high(self):
        with pytest.raises(ValueError):
            AgentDecision(
                decision_id="dec_test",
                context_id="ctx_test",
                timestamp=datetime.utcnow(),
                actions=[],
                market_view=MarketView.BULLISH,
                reasoning="Test",
                key_factors=[],
                confidence=1.5,  # Invalid
                model_used="test",
                autonomy_level=AutonomyLevel.MODERATE,
                tokens_used=100,
                latency_ms=150
            )
    
    def test_confidence_validation_invalid_low(self):
        with pytest.raises(ValueError):
            AgentDecision(
                decision_id="dec_test",
                context_id="ctx_test",
                timestamp=datetime.utcnow(),
                actions=[],
                market_view=MarketView.BULLISH,
                reasoning="Test",
                key_factors=[],
                confidence=-0.1,  # Invalid
                model_used="test",
                autonomy_level=AutonomyLevel.MODERATE,
                tokens_used=100,
                latency_ms=150
            )
    
    def test_has_actions_false(self):
        decision = AgentDecision(
            decision_id="dec_test",
            context_id="ctx_test",
            timestamp=datetime.utcnow(),
            actions=[],
            market_view=MarketView.NEUTRAL,
            reasoning="No opportunities",
            key_factors=[],
            confidence=0.8,
            model_used="test",
            autonomy_level=AutonomyLevel.MODERATE,
            tokens_used=100,
            latency_ms=150
        )
        assert decision.has_actions is False
        assert decision.action_summary == "No actions recommended"
    
    def test_to_json(self):
        decision = AgentDecision(
            decision_id="dec_test",
            context_id="ctx_test",
            timestamp=datetime.utcnow(),
            actions=[],
            market_view=MarketView.BULLISH,
            reasoning="Test",
            key_factors=["factor1"],
            confidence=0.8,
            model_used="test",
            autonomy_level=AutonomyLevel.MODERATE,
            tokens_used=100,
            latency_ms=150
        )
        json_str = decision.to_json()
        import json
        data = json.loads(json_str)
        assert data["decision_id"] == "dec_test"
        assert data["market_view"] == "bullish"


class TestExceptions:
    """Tests para excepciones espec√≠ficas."""
    
    def test_llm_api_error(self):
        error = LLMAPIError("API failed", status_code=500, response="Internal error")
        assert str(error) == "API failed"
        assert error.status_code == 500
    
    def test_llm_rate_limit_error(self):
        error = LLMRateLimitError("Rate limited", retry_after=60)
        assert error.retry_after == 60
```

---

### 16.2 Tests de Prompts

**Archivo:** `tests/agents/llm/test_prompts.py`

```python
# tests/agents/llm/test_prompts.py
"""Tests para el sistema de prompts."""

import pytest
from src.agents.llm.interfaces import AutonomyLevel
from src.agents.llm.prompts import get_system_prompt, get_prompt_token_estimate


class TestPromptSystem:
    """Tests para el sistema de prompts."""
    
    @pytest.mark.parametrize("level", [
        AutonomyLevel.CONSERVATIVE,
        AutonomyLevel.MODERATE,
        AutonomyLevel.EXPERIMENTAL,
    ])
    def test_prompt_exists(self, level):
        prompt = get_system_prompt(level)
        assert prompt is not None
        assert len(prompt) > 0
    
    @pytest.mark.parametrize("level", [
        AutonomyLevel.CONSERVATIVE,
        AutonomyLevel.MODERATE,
        AutonomyLevel.EXPERIMENTAL,
    ])
    def test_prompt_has_minimum_content(self, level):
        prompt = get_system_prompt(level)
        # Debe tener al menos 1000 caracteres
        assert len(prompt) > 1000
    
    @pytest.mark.parametrize("level", [
        AutonomyLevel.CONSERVATIVE,
        AutonomyLevel.MODERATE,
        AutonomyLevel.EXPERIMENTAL,
    ])
    def test_prompt_has_json_format(self, level):
        prompt = get_system_prompt(level)
        assert "json" in prompt.lower()
    
    @pytest.mark.parametrize("level", [
        AutonomyLevel.CONSERVATIVE,
        AutonomyLevel.MODERATE,
        AutonomyLevel.EXPERIMENTAL,
    ])
    def test_prompt_has_safety_section(self, level):
        prompt = get_system_prompt(level)
        # Debe mencionar restricciones de seguridad
        assert "nunca" in prompt.lower() or "never" in prompt.lower()
    
    def test_conservative_no_actions(self):
        prompt = get_system_prompt(AutonomyLevel.CONSERVATIVE)
        # Conservative debe indicar que actions est√° vac√≠o
        assert "actions" in prompt.lower()
        assert "[]" in prompt or "vac√≠o" in prompt.lower() or "empty" in prompt.lower()
    
    def test_experimental_kill_switch(self):
        prompt = get_system_prompt(AutonomyLevel.EXPERIMENTAL)
        # Experimental debe mencionar kill switch
        assert "kill" in prompt.lower() or "emergencia" in prompt.lower()
    
    def test_token_estimate(self):
        for level in AutonomyLevel:
            tokens = get_prompt_token_estimate(level)
            # Debe ser un n√∫mero razonable
            assert 500 < tokens < 10000
    
    def test_invalid_level_raises(self):
        with pytest.raises((ValueError, KeyError)):
            get_system_prompt("invalid_level")
```

---

### 16.3 Tests de Claude Agent

**Archivo:** `tests/agents/llm/test_claude_agent.py`

```python
# tests/agents/llm/test_claude_agent.py
"""Tests para Claude Agent."""

import pytest
from unittest.mock import Mock, AsyncMock, patch
from datetime import datetime

from src.agents.llm.interfaces import (
    AutonomyLevel,
    AgentContext,
    RegimeInfo,
    MarketContext,
    PortfolioSummary,
    RiskLimits,
    LLMParseError,
)
from src.agents.llm.agents.claude_agent import ClaudeAgent


class TestClaudeAgent:
    """Tests para ClaudeAgent."""
    
    @pytest.fixture
    def mock_anthropic_client(self):
        """Mock del cliente de Anthropic."""
        with patch('anthropic.Anthropic') as mock:
            yield mock
    
    @pytest.fixture
    def sample_context(self):
        """Contexto de prueba."""
        return AgentContext(
            context_id="ctx_test",
            timestamp=datetime.utcnow(),
            regime=RegimeInfo(
                regime="BULL",
                confidence=0.75,
                probabilities={"BULL": 0.75},
                model_id="test"
            ),
            market=MarketContext(
                spy_change_pct=0.5,
                qqq_change_pct=0.8,
                vix_level=18,
                vix_change_pct=-1,
                market_breadth=0.6,
                sector_rotation={}
            ),
            portfolio=PortfolioSummary(
                total_value=25000,
                cash_available=20000,
                invested_value=5000,
                positions=(),
                daily_pnl=50,
                daily_pnl_pct=0.2,
                total_pnl=500,
                total_pnl_pct=2.0
            ),
            watchlist=(),
            risk_limits=RiskLimits(
                max_position_pct=5.0,
                max_portfolio_risk_pct=2.0,
                max_daily_trades=5,
                max_daily_loss_pct=3.0,
                current_daily_trades=1,
                current_daily_pnl_pct=0.2
            ),
            autonomy_level=AutonomyLevel.MODERATE
        )
    
    def test_agent_id(self):
        """Verifica formato del agent_id."""
        with patch('anthropic.Anthropic'):
            agent = ClaudeAgent(
                api_key="test_key",
                model="claude-sonnet-4-20250514",
                default_autonomy=AutonomyLevel.MODERATE
            )
            assert "claude" in agent.agent_id
            assert "moderate" in agent.agent_id
    
    def test_model_name(self):
        """Verifica model_name."""
        with patch('anthropic.Anthropic'):
            agent = ClaudeAgent(
                api_key="test_key",
                model="claude-sonnet-4-20250514"
            )
            assert agent.model_name == "claude-sonnet-4-20250514"
    
    def test_supports_streaming(self):
        """Claude soporta streaming."""
        with patch('anthropic.Anthropic'):
            agent = ClaudeAgent(api_key="test_key")
            assert agent.supports_streaming is True
    
    def test_get_system_prompt(self):
        """Verifica que retorna prompt v√°lido."""
        with patch('anthropic.Anthropic'):
            agent = ClaudeAgent(api_key="test_key")
            
            for level in AutonomyLevel:
                prompt = agent.get_system_prompt(level)
                assert len(prompt) > 1000
    
    def test_estimate_tokens(self, sample_context):
        """Verifica estimaci√≥n de tokens."""
        with patch('anthropic.Anthropic'):
            agent = ClaudeAgent(api_key="test_key")
            tokens = agent.estimate_tokens(sample_context)
            assert tokens > 0
            assert isinstance(tokens, int)
    
    def test_validate_context_valid(self, sample_context):
        """Contexto v√°lido pasa validaci√≥n."""
        with patch('anthropic.Anthropic'):
            agent = ClaudeAgent(api_key="test_key")
            is_valid, issues = agent.validate_context(sample_context)
            # El contexto de prueba puede tener issues por watchlist vac√≠a
            # pero no deber√≠a ser cr√≠tico
            assert isinstance(is_valid, bool)
            assert isinstance(issues, list)
    
    def test_should_skip_volatile_regime(self, sample_context):
        """Debe saltar si r√©gimen es VOLATILE."""
        with patch('anthropic.Anthropic'):
            agent = ClaudeAgent(api_key="test_key")
            
            # Modificar contexto para r√©gimen VOLATILE
            volatile_context = AgentContext(
                context_id=sample_context.context_id,
                timestamp=sample_context.timestamp,
                regime=RegimeInfo(
                    regime="VOLATILE",
                    confidence=0.8,
                    probabilities={"VOLATILE": 0.8},
                    model_id="test"
                ),
                market=sample_context.market,
                portfolio=sample_context.portfolio,
                watchlist=sample_context.watchlist,
                risk_limits=sample_context.risk_limits,
                autonomy_level=sample_context.autonomy_level
            )
            
            should_skip, reason = agent.should_skip_decision(volatile_context)
            assert should_skip is True
            assert "VOLATILE" in reason
    
    def test_extract_json_from_markdown(self):
        """Verifica extracci√≥n de JSON desde markdown."""
        with patch('anthropic.Anthropic'):
            agent = ClaudeAgent(api_key="test_key")
            
            markdown_response = '''
            Here's my analysis:
            
            ```json
            {"market_view": "bullish", "confidence": 0.8}
            ```
            '''
            
            extracted = agent._extract_json(markdown_response)
            assert "market_view" in extracted
    
    def test_extract_json_direct(self):
        """Verifica extracci√≥n de JSON directo."""
        with patch('anthropic.Anthropic'):
            agent = ClaudeAgent(api_key="test_key")
            
            direct_json = '{"market_view": "bullish", "confidence": 0.8}'
            extracted = agent._extract_json(direct_json)
            assert extracted == direct_json


class TestClaudeAgentParsing:
    """Tests para parsing de respuestas."""
    
    @pytest.fixture
    def agent(self):
        with patch('anthropic.Anthropic'):
            return ClaudeAgent(api_key="test_key")
    
    @pytest.fixture
    def sample_context(self):
        return AgentContext(
            context_id="ctx_test",
            timestamp=datetime.utcnow(),
            regime=RegimeInfo(regime="BULL", confidence=0.75, probabilities={}, model_id="test"),
            market=MarketContext(
                spy_change_pct=0.5, qqq_change_pct=0.8, vix_level=18,
                vix_change_pct=-1, market_breadth=0.6, sector_rotation={}
            ),
            portfolio=PortfolioSummary(
                total_value=25000, cash_available=20000, invested_value=5000,
                positions=(), daily_pnl=50, daily_pnl_pct=0.2,
                total_pnl=500, total_pnl_pct=2.0
            ),
            watchlist=(),
            risk_limits=RiskLimits(
                max_position_pct=5.0, max_portfolio_risk_pct=2.0, max_daily_trades=5,
                max_daily_loss_pct=3.0, current_daily_trades=1, current_daily_pnl_pct=0.2
            ),
            autonomy_level=AutonomyLevel.MODERATE
        )
    
    def test_parse_valid_response(self, agent, sample_context):
        """Parsea respuesta v√°lida correctamente."""
        valid_response = '''
        {
            "market_view": "bullish",
            "confidence": 0.8,
            "reasoning": "Market looks good",
            "key_factors": ["factor1", "factor2"],
            "actions": [],
            "warnings": []
        }
        '''
        
        parsed = agent._parse_response(valid_response, sample_context, AutonomyLevel.MODERATE)
        assert parsed["confidence"] == 0.8
        assert len(parsed["key_factors"]) == 2
    
    def test_parse_invalid_json_raises(self, agent, sample_context):
        """JSON inv√°lido lanza LLMParseError."""
        invalid_response = "This is not JSON"
        
        with pytest.raises(LLMParseError):
            agent._parse_response(invalid_response, sample_context, AutonomyLevel.MODERATE)
    
    def test_parse_missing_field_raises(self, agent, sample_context):
        """Campo faltante lanza LLMParseError."""
        missing_field = '{"market_view": "bullish"}'  # Falta confidence, reasoning, etc.
        
        with pytest.raises(LLMParseError):
            agent._parse_response(missing_field, sample_context, AutonomyLevel.MODERATE)
```

---

### 16.4 Tests de Rate Limiter

**Archivo:** `tests/agents/llm/test_rate_limiter.py`

```python
# tests/agents/llm/test_rate_limiter.py
"""Tests para Rate Limiter."""

import pytest
import asyncio
from datetime import datetime

from src.agents.llm.rate_limiter import RateLimiter, RateLimitConfig


class TestRateLimiter:
    """Tests para RateLimiter."""
    
    @pytest.fixture
    def limiter(self):
        config = RateLimitConfig(
            requests_per_minute=10,
            tokens_per_minute=10000,
            requests_per_day=100
        )
        return RateLimiter(config)
    
    @pytest.mark.asyncio
    async def test_acquire_success(self, limiter):
        """Primera adquisici√≥n debe ser exitosa."""
        result = await limiter.acquire(estimated_tokens=100)
        assert result is True
    
    @pytest.mark.asyncio
    async def test_acquire_increments_counter(self, limiter):
        """Acquire incrementa contador diario."""
        initial = limiter._daily_requests
        await limiter.acquire()
        assert limiter._daily_requests == initial + 1
    
    def test_get_status(self, limiter):
        """Status retorna informaci√≥n correcta."""
        status = limiter.get_status()
        
        assert "daily_requests" in status
        assert "daily_limit" in status
        assert "daily_remaining" in status
        assert "reset_time" in status
        assert "rpm_limit" in status
    
    @pytest.mark.asyncio
    async def test_daily_limit_blocks(self):
        """Cuando se alcanza l√≠mite diario, retorna False."""
        config = RateLimitConfig(
            requests_per_minute=100,
            requests_per_day=2  # L√≠mite muy bajo
        )
        limiter = RateLimiter(config)
        
        # Primeras dos deben pasar
        await limiter.acquire()
        await limiter.acquire()
        
        # Tercera debe fallar
        result = await limiter.acquire()
        assert result is False
```

---

## 17. Checklist de Verificaci√≥n Final

```
FASE B2: AI AGENT
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

TAREA B2.1: INTERFACES
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
[ ] src/agents/llm/__init__.py creado
[ ] src/agents/llm/interfaces.py creado
[ ] AutonomyLevel enum (CONSERVATIVE, MODERATE, EXPERIMENTAL)
[ ] MarketView enum (BULLISH, BEARISH, NEUTRAL, UNCERTAIN)
[ ] PortfolioPosition dataclass con market_value property
[ ] PortfolioSummary dataclass con cash_pct y num_positions
[ ] SymbolData dataclass con to_summary()
[ ] RegimeInfo dataclass con to_summary()
[ ] RiskLimits dataclass con can_trade y remaining_trades
[ ] MarketContext dataclass con to_summary()
[ ] AgentContext dataclass con to_prompt_text() y to_dict()
[ ] AgentDecision dataclass con validaci√≥n de confidence
[ ] LLMAgent ABC con m√©todos abstractos
[ ] Excepciones: LLMAPIError, LLMRateLimitError, LLMParseError, etc.
[ ] Tests tests/agents/llm/test_interfaces.py

TAREA B2.2: CONTEXT BUILDER
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
[ ] src/agents/llm/context_builder.py creado
[ ] ContextBuilder clase con build() async
[ ] Integraci√≥n con mcp-ml-models para r√©gimen
[ ] Integraci√≥n con mcp-market-data para quotes
[ ] Integraci√≥n con mcp-ibkr para portfolio
[ ] Integraci√≥n con mcp-technical para indicadores
[ ] Manejo de errores con defaults
[ ] Cache con TTL configurable
[ ] Tests tests/agents/llm/test_context_builder.py

TAREA B2.3: SISTEMA DE PROMPTS
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
[ ] src/agents/llm/prompts/__init__.py creado
[ ] src/agents/llm/prompts/base.py creado
[ ] src/agents/llm/prompts/conservative.py creado
[ ] src/agents/llm/prompts/moderate.py creado
[ ] src/agents/llm/prompts/experimental.py creado
[ ] get_system_prompt(autonomy_level) funciona
[ ] Prompt CONSERVATIVE indica actions = []
[ ] Prompt MODERATE incluye sizing
[ ] Prompt EXPERIMENTAL tiene l√≠mites estrictos y kill switch
[ ] Todos los prompts tienen formato JSON
[ ] Todos los prompts tienen secci√≥n de seguridad
[ ] Tests tests/agents/llm/test_prompts.py

TAREA B2.4: CLAUDE AGENT
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
[ ] src/agents/llm/agents/__init__.py creado
[ ] src/agents/llm/agents/claude_agent.py creado
[ ] ClaudeAgent implementa LLMAgent ABC
[ ] decide() async con retry autom√°tico
[ ] get_system_prompt() retorna prompt correcto
[ ] health_check() verifica conexi√≥n API
[ ] estimate_tokens() estima correctamente
[ ] _parse_response() maneja JSON y markdown
[ ] Validaci√≥n de contexto
[ ] should_skip_decision() funciona
[ ] Tests tests/agents/llm/test_claude_agent.py

TAREA B2.5: RATE LIMITER
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
[ ] src/agents/llm/rate_limiter.py creado
[ ] RateLimitConfig dataclass
[ ] RateLimiter con acquire() async
[ ] L√≠mite por minuto (RPM)
[ ] L√≠mite por d√≠a (RPD)
[ ] L√≠mite por tokens (TPM)
[ ] Cooldown entre requests
[ ] get_status() retorna info √∫til
[ ] Tests tests/agents/llm/test_rate_limiter.py

TAREA B2.6: FACTORY E INTEGRACI√ìN
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
[ ] src/agents/llm/factory.py creado
[ ] src/agents/llm/config.py creado
[ ] LLMAgentFactory.create_from_config() funciona
[ ] LLMAgentFactory.create() con par√°metros expl√≠citos
[ ] LLMAgentConfig carga YAML correctamente
[ ] src/strategies/swing/ai_agent_strategy.py creado
[ ] AIAgentStrategy implementa TradingStrategy
[ ] AIAgentStrategy.generate_signals() funciona
[ ] AIAgentStrategy.should_close() funciona
[ ] Tests tests/agents/llm/test_factory.py

TAREA B2.7: CONFIGURACI√ìN
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
[ ] config/agents.yaml creado
[ ] config/strategies.yaml actualizado con ai_agent_swing
[ ] Variable de entorno ANTHROPIC_API_KEY documentada
[ ] scripts/verify_fase_b2.py creado
[ ] Documentaci√≥n actualizada

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

GATE DE AVANCE A FASE C1:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
[ ] python scripts/verify_fase_b2.py retorna 0 (√©xito)
[ ] pytest tests/agents/llm/ pasa (>80% cobertura)
[ ] ClaudeAgent puede hacer health_check sin errores
[ ] AIAgentStrategy se registra correctamente en StrategyRegistry
[ ] Config YAML se carga sin errores
[ ] Sistema de prompts funciona para los 3 niveles

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
```

---

## 18. Troubleshooting

### Error: "ANTHROPIC_API_KEY not found"

```bash
# Linux/Mac
export ANTHROPIC_API_KEY="sk-ant-..."

# Windows PowerShell
$env:ANTHROPIC_API_KEY = "sk-ant-..."

# O en .env file
echo "ANTHROPIC_API_KEY=sk-ant-..." >> .env
```

### Error: "anthropic module not found"

```bash
pip install anthropic>=0.40.0
```

### Error: "Rate limit exceeded"

```python
# Verificar status del rate limiter
from src.agents.llm.rate_limiter import get_rate_limiter

limiter = get_rate_limiter()
status = limiter.get_status()
print(f"Requests restantes hoy: {status['daily_remaining']}")

# Si es necesario, esperar
import asyncio
await asyncio.sleep(60)  # Esperar 1 minuto
```

### Error: "LLMParseError: Invalid JSON"

El LLM devolvi√≥ una respuesta que no es JSON v√°lido. Posibles causas:
1. Prompt no suficientemente claro
2. Modelo confundido por contexto muy largo
3. Error transitorio del modelo

```python
# Debugging: ver respuesta raw
try:
    decision = await agent.decide(context)
except LLMParseError as e:
    print(f"Raw response: {e.raw_response[:500]}")
```

### Error: "Context too large"

```python
# Reducir watchlist
context = await builder.build(
    watchlist=["SPY", "QQQ"],  # Menos s√≠mbolos
    autonomy_level=AutonomyLevel.MODERATE
)

# O truncar datos hist√≥ricos
# Modificar context_builder para limitar recent_trades
```

### AIAgentStrategy no genera se√±ales

1. Verificar r√©gimen:
```python
print(f"R√©gimen actual: {regime}")
print(f"Requerido: {strategy.required_regime}")
```

2. Verificar risk limits:
```python
print(f"Can trade: {context.risk_limits.can_trade}")
print(f"Remaining trades: {context.risk_limits.remaining_trades}")
```

3. Verificar autonom√≠a:
```python
# Conservative NUNCA genera acciones
print(f"Autonomy: {context.autonomy_level}")
```

### Tests fallan por estado compartido

```python
# Resetear rate limiter entre tests
@pytest.fixture(autouse=True)
def reset_rate_limiter():
    from src.agents.llm import rate_limiter
    rate_limiter._default_limiter = None
    yield
```

### Prompts muy largos consumen muchos tokens

```python
# Verificar tokens del prompt
from src.agents.llm.prompts import get_prompt_token_estimate

for level in AutonomyLevel:
    tokens = get_prompt_token_estimate(level)
    print(f"{level.value}: ~{tokens} tokens")
```

---

## 19. Referencias Cruzadas

| Tema | Documento | Secci√≥n |
|------|-----------|---------|
| Interfaz TradingStrategy | fase_b1_estrategias_swing.md | Tarea B1.1 |
| Signal dataclass | fase_b1_estrategias_swing.md | Tarea B1.2 |
| StrategyRegistry | fase_b1_estrategias_swing.md | Tarea B1.4 |
| StrategyRunner | fase_b1_estrategias_swing.md | Tarea B1.5 |
| RegimeDetector | fase_a2_ml_modular.md | Tarea A2.1 |
| mcp-ml-models | fase_a1_extensiones_base.md | Tarea A1.4 |
| Agentes Core | fase_3_agentes_core.md | Tareas 3.1-3.4 |
| Risk Manager | fase_3_agentes_core.md | Tarea 3.3 |
| Sistema de M√©tricas | fase_c1_metricas.md | (pr√≥ximo) |

---

## 20. Siguiente Fase

Una vez completada la Fase B2:

1. **Verificar:** `python scripts/verify_fase_b2.py` retorna 0
2. **Verificar:** `pytest tests/agents/llm/` pasa con >80% cobertura
3. **Verificar:** AIAgentStrategy se integra con StrategyRunner
4. **Siguiente documento:** `fase_c1_metricas.md`
5. **Contenido Fase C1:**
   - Collector de trades
   - Aggregator de m√©tricas (Sharpe, MaxDD, etc.)
   - Sistema de experimentos A/B
   - Dashboard Grafana
   - Alertas y notificaciones

---

*Fin de Parte 5 - Tests, Checklist Final y Troubleshooting*

---

*Documento de Implementaci√≥n - Fase B2: AI Agent*  
*Nexus Trading - Bot de Trading Aut√≥nomo con IA*  
*Versi√≥n 1.0 - Diciembre 2024*
