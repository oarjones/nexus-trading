# üìä Fase 1: Data Pipeline

## Documento de Implementaci√≥n

**Versi√≥n:** 1.0  
**Duraci√≥n estimada:** 3 semanas  
**Dependencias:** Fase 0 completada  
**Docs t√©cnicos:** Doc 2 (secciones 5, 6, 7, 8)

---

## 1. Objetivos de la Fase

| Objetivo | Criterio de √©xito |
|----------|-------------------|
| Conector Yahoo Finance | Descarga OHLCV de 50+ s√≠mbolos sin errores |
| Conector IBKR | Conexi√≥n a paper trading, quotes en tiempo real |
| Pipeline de ingesta | Datos en TimescaleDB, validaciones pasando |
| Feature Store | 30+ features calculados, queries < 100ms |
| Scheduler | Actualizaci√≥n autom√°tica diaria funcionando |
| Calidad de datos | < 1% NaN en features, alertas configuradas |

---

## 2. Arquitectura del Pipeline

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Yahoo Finance  ‚îÇ     ‚îÇ    IBKR API     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                       ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚ñº
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   Data Ingester ‚îÇ
            ‚îÇ  (validaciones) ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚ñº           ‚ñº           ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ  Redis   ‚îÇ ‚îÇTimescaleDB‚îÇ ‚îÇ  Logs   ‚îÇ
   ‚îÇ (cache)  ‚îÇ ‚îÇ (OHLCV)  ‚îÇ ‚îÇ         ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ Feature Engine  ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚ñº           ‚ñº           ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Parquet  ‚îÇ ‚îÇ Postgres ‚îÇ ‚îÇ  Redis   ‚îÇ
   ‚îÇ (datos)  ‚îÇ ‚îÇ(metadata)‚îÇ ‚îÇ (cache)  ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 3. Universo de S√≠mbolos Inicial

| Mercado | S√≠mbolos | Fuente | Prioridad |
|---------|----------|--------|-----------|
| Acciones EU | SAN, BBVA, ITX, IBE, REP, SAP, ASML, BMW | Yahoo | Alta |
| ETFs EU | EXW1, VWCE, CSPX | Yahoo | Alta |
| Forex | EURUSD=X, GBPUSD=X, USDJPY=X | Yahoo | Media |
| Crypto | BTC-EUR, ETH-EUR | Yahoo/Kraken | Media |
| US (referencia) | SPY, QQQ, AAPL, MSFT | Yahoo | Baja |

**Total inicial:** ~25 s√≠mbolos (escalable a 100+)

---

## 4. Tareas

### Tarea 1.1: Crear m√≥dulo de configuraci√≥n de s√≠mbolos

**Estado:** ‚¨ú Pendiente

**Objetivo:** Centralizar definici√≥n de s√≠mbolos, timeframes y fuentes.

**Referencias:** Doc 2 sec 6.2 (cat√°logo de features)

**Subtareas:**
- [ ] Crear `src/data/symbols.py` con clase SymbolRegistry
- [ ] Definir estructura de datos para s√≠mbolo (ticker, nombre, mercado, fuente, timezone)
- [ ] Cargar desde YAML configurable
- [ ] M√©todos de filtrado por mercado/tipo

**Input:** Lista de s√≠mbolos objetivo (secci√≥n 3)

**Output:** M√≥dulo `symbols.py` + `config/symbols.yaml`

**Validaci√≥n:** `SymbolRegistry.get_by_market("EU")` retorna lista correcta

**Pseudoc√≥digo:**
```python
# src/data/symbols.py
@dataclass
class Symbol:
    ticker: str          # "SAN.MC"
    name: str            # "Banco Santander"
    market: str          # "EU", "US", "FOREX", "CRYPTO"
    source: str          # "yahoo", "ibkr", "kraken"
    timezone: str        # "Europe/Madrid"
    currency: str        # "EUR"
    
class SymbolRegistry:
    def __init__(self, config_path: str):
        # Cargar desde YAML
        pass
    
    def get_all(self) -> list[Symbol]: ...
    def get_by_market(self, market: str) -> list[Symbol]: ...
    def get_by_source(self, source: str) -> list[Symbol]: ...
```

---

### Tarea 1.2: Implementar conector Yahoo Finance

**Estado:** ‚¨ú Pendiente

**Objetivo:** Descargar datos OHLCV hist√≥ricos y recientes de Yahoo Finance.

**Referencias:** Doc 2 sec 7.1 (pipeline de ingesta)

**Subtareas:**
- [ ] Instalar `yfinance` y a√±adir a requirements
- [ ] Crear `src/data/providers/yahoo.py`
- [ ] Implementar descarga hist√≥rica (5 a√±os)
- [ ] Implementar descarga incremental (√∫ltimo d√≠a)
- [ ] Manejo de errores y reintentos
- [ ] Rate limiting (evitar ban)

**Input:** Lista de s√≠mbolos, rango de fechas

**Output:** DataFrame con OHLCV estandarizado

**Validaci√≥n:** Descarga 5 a√±os de SPY sin errores, columnas correctas

**Pseudoc√≥digo:**
```python
# src/data/providers/yahoo.py
class YahooProvider:
    def __init__(self, rate_limit: float = 0.5):
        self.rate_limit = rate_limit  # segundos entre requests
    
    def get_historical(
        self, 
        symbol: str, 
        start: date, 
        end: date,
        interval: str = "1d"
    ) -> pd.DataFrame:
        # 1. Llamar yfinance.download()
        # 2. Renombrar columnas a est√°ndar (open, high, low, close, volume)
        # 3. A√±adir columnas: symbol, timeframe, source
        # 4. Validar datos (no vac√≠o, no todo NaN)
        # 5. Retornar DataFrame limpio
        pass
    
    def get_latest(self, symbol: str, days: int = 5) -> pd.DataFrame:
        # Descarga incremental para actualizaci√≥n diaria
        pass
```

**Estructura de DataFrame de salida:**
```
| time (index) | symbol | timeframe | open | high | low | close | volume | source |
```

---

### Tarea 1.3: Implementar conector IBKR (b√°sico)

**Estado:** ‚¨ú Pendiente

**Objetivo:** Conexi√≥n b√°sica a IBKR para quotes y datos hist√≥ricos.

**Referencias:** Doc 3 sec 7.5 (mcp-ibkr tools)

**Subtareas:**
- [ ] Instalar `ib_insync` y a√±adir a requirements
- [ ] Crear `src/data/providers/ibkr.py`
- [ ] Implementar conexi√≥n a TWS/Gateway
- [ ] Implementar `get_quote()` para precio actual
- [ ] Implementar `get_historical()` b√°sico
- [ ] Manejo de desconexiones

**Input:** S√≠mbolo, credenciales IBKR (host, port, client_id)

**Output:** Quote o DataFrame OHLCV

**Validaci√≥n:** Conecta a paper trading, obtiene quote de AAPL

**Pseudoc√≥digo:**
```python
# src/data/providers/ibkr.py
class IBKRProvider:
    def __init__(self, host: str, port: int, client_id: int):
        self.ib = IB()
        self.connected = False
    
    async def connect(self) -> bool:
        # 1. Intentar conexi√≥n
        # 2. Verificar que es paper trading (safety check)
        # 3. Retornar estado
        pass
    
    async def get_quote(self, symbol: str) -> dict:
        # Retorna {bid, ask, last, volume, timestamp}
        pass
    
    async def get_historical(
        self, 
        symbol: str,
        duration: str,  # "1 Y", "6 M", etc.
        bar_size: str   # "1 day", "1 hour", etc.
    ) -> pd.DataFrame:
        pass
    
    def disconnect(self):
        pass
```

**Nota:** IBKR requiere TWS o IB Gateway corriendo. Para desarrollo inicial, Yahoo es suficiente.

---

### Tarea 1.4: Crear servicio de ingesta a TimescaleDB

**Estado:** ‚¨ú Pendiente

**Objetivo:** Persistir datos OHLCV en hypertable con upsert.

**Referencias:** Doc 2 sec 3.1 (hypertable ohlcv), sec 7.1 (pipeline)

**Subtareas:**
- [ ] Crear `src/data/ingestion.py`
- [ ] Implementar bulk insert eficiente
- [ ] Implementar upsert (ON CONFLICT)
- [ ] A√±adir validaciones pre-insert (Doc 2 sec 8.1)
- [ ] Logging de registros insertados/actualizados

**Input:** DataFrame OHLCV estandarizado

**Output:** Registros en `market_data.ohlcv`

**Validaci√≥n:** Insertar 1000 registros < 2 segundos, sin duplicados

**Pseudoc√≥digo:**
```python
# src/data/ingestion.py
class OHLCVIngester:
    def __init__(self, db_url: str):
        self.engine = create_engine(db_url)
    
    def ingest(self, df: pd.DataFrame) -> dict:
        # 1. Validar DataFrame (columnas, tipos, no vac√≠o)
        # 2. Aplicar validaciones de calidad (Doc 2 sec 8.1)
        #    - precio > 0
        #    - volumen >= 0
        #    - timestamp no futuro
        # 3. Filtrar registros inv√°lidos (log warning)
        # 4. Bulk upsert con ON CONFLICT
        # 5. Retornar {inserted: N, updated: M, rejected: K}
        pass
    
    def _validate_row(self, row: pd.Series) -> tuple[bool, str]:
        # Retorna (is_valid, reason_if_invalid)
        pass
```

**SQL de upsert:**
```sql
INSERT INTO market_data.ohlcv (time, symbol, timeframe, open, high, low, close, volume, source)
VALUES (...)
ON CONFLICT (time, symbol, timeframe) 
DO UPDATE SET open=EXCLUDED.open, high=EXCLUDED.high, ...
```

---

### Tarea 1.5: Implementar c√°lculo de indicadores t√©cnicos

**Estado:** ‚¨ú Pendiente

**Objetivo:** Calcular indicadores t√©cnicos sobre OHLCV y persistir.

**Referencias:** Doc 2 sec 3.2 (hypertable indicators), sec 6.2 (cat√°logo)

**Subtareas:**
- [ ] Instalar `ta-lib` o `pandas-ta` y a√±adir a requirements
- [ ] Crear `src/data/indicators.py`
- [ ] Implementar c√°lculo de indicadores base (tabla abajo)
- [ ] Persistir en `market_data.indicators`
- [ ] Optimizar para c√°lculo vectorizado

**Input:** OHLCV de TimescaleDB para un s√≠mbolo

**Output:** Indicadores en `market_data.indicators`

**Validaci√≥n:** RSI(14) de SPY calculado correctamente (comparar con TradingView)

**Indicadores a implementar (Fase 1):**

| Indicador | Funci√≥n | Par√°metros |
|-----------|---------|------------|
| SMA | Media m√≥vil simple | 20, 50, 200 |
| EMA | Media m√≥vil exponencial | 12, 26 |
| RSI | Relative Strength Index | 14 |
| MACD | Moving Average Convergence | 12, 26, 9 |
| ATR | Average True Range | 14 |
| BB | Bandas de Bollinger | 20, 2 |
| ADX | Average Directional Index | 14 |

**Pseudoc√≥digo:**
```python
# src/data/indicators.py
class IndicatorEngine:
    INDICATORS = {
        'sma_20': lambda df: df['close'].rolling(20).mean(),
        'sma_50': lambda df: df['close'].rolling(50).mean(),
        'rsi_14': lambda df: ta.rsi(df['close'], 14),
        'macd_hist': lambda df: ta.macd(df['close'])['histogram'],
        # ... resto de indicadores
    }
    
    def calculate_all(self, df: pd.DataFrame) -> pd.DataFrame:
        # 1. Verificar datos suficientes (min 200 rows para SMA200)
        # 2. Calcular cada indicador
        # 3. Retornar DataFrame con columnas: time, symbol, timeframe, indicator, value
        pass
    
    def calculate_single(self, df: pd.DataFrame, indicator: str) -> pd.Series:
        pass
```

---

### Tarea 1.6: Implementar Feature Store

**Estado:** ‚¨ú Pendiente

**Objetivo:** Generar y almacenar features para ML y estrategias.

**Referencias:** Doc 2 sec 6 (Feature Store completo)

**Subtareas:**
- [ ] Crear estructura de directorios para Parquet
- [ ] Crear `src/data/feature_store.py`
- [ ] Implementar generaci√≥n de features (cat√°logo Doc 2 sec 6.2)
- [ ] Implementar tabla de metadata en PostgreSQL
- [ ] Implementar lectura eficiente por s√≠mbolo/rango
- [ ] Cache en Redis para features del d√≠a actual

**Input:** OHLCV + Indicadores de TimescaleDB

**Output:** Archivos Parquet + metadata en PostgreSQL + cache Redis

**Validaci√≥n:** Cargar features de AAPL √∫ltimos 30 d√≠as < 50ms

**Estructura de directorios:**
```
data/features/
‚îú‚îÄ‚îÄ symbol=SAN.MC/
‚îÇ   ‚îú‚îÄ‚îÄ 2024-01/features.parquet
‚îÇ   ‚îú‚îÄ‚îÄ 2024-02/features.parquet
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ symbol=EURUSD=X/
    ‚îî‚îÄ‚îÄ ...
```

**Features a generar (30+):**

| Categor√≠a | Features |
|-----------|----------|
| Momentum | returns_1d, returns_5d, returns_20d, rsi_14, macd_hist |
| Volatilidad | volatility_20d, atr_14, bb_width, bb_position |
| Volumen | volume_ratio_20d, obv_slope |
| Tendencia | sma_ratio_50, sma_ratio_200, adx_14, trend_strength |
| Derivados | rsi_slope, macd_slope, momentum_5d |

**Pseudoc√≥digo:**
```python
# src/data/feature_store.py
class FeatureStore:
    def __init__(self, base_path: str, db_url: str, redis_url: str):
        self.base_path = Path(base_path)
        self.engine = create_engine(db_url)
        self.redis = Redis.from_url(redis_url)
    
    def generate_features(self, symbol: str, start: date, end: date) -> pd.DataFrame:
        # 1. Cargar OHLCV + indicadores de TimescaleDB
        # 2. Calcular features derivados
        # 3. Aplicar transformaciones (z-score rolling, winsorization)
        # 4. Retornar DataFrame de features
        pass
    
    def save(self, symbol: str, df: pd.DataFrame):
        # 1. Particionar por mes
        # 2. Guardar Parquet
        # 3. Actualizar metadata en PostgreSQL
        # 4. Cache d√≠a actual en Redis
        pass
    
    def load(self, symbol: str, start: date, end: date) -> pd.DataFrame:
        # 1. Verificar cache Redis para hoy
        # 2. Cargar Parquet necesarios
        # 3. Filtrar por rango
        pass
    
    def _apply_transforms(self, df: pd.DataFrame) -> pd.DataFrame:
        # Z-score rolling (60 d√≠as), winsorization 1-99%
        pass
```

**Tabla metadata (Doc 2 sec 6.1):**
```sql
-- Ya definida en fase 0, verificar que existe
SELECT * FROM features.catalog LIMIT 1;
```

---

### Tarea 1.7: Crear scheduler de actualizaci√≥n

**Estado:** ‚¨ú Pendiente

**Objetivo:** Automatizar descarga diaria y generaci√≥n de features.

**Referencias:** Doc 2 sec 7.3 (scheduling)

**Subtareas:**
- [ ] Instalar APScheduler y a√±adir a requirements
- [ ] Crear `src/data/scheduler.py`
- [ ] Job: Actualizaci√≥n OHLCV post-cierre mercado EU (18:30 CET)
- [ ] Job: C√°lculo de indicadores (18:35 CET)
- [ ] Job: Generaci√≥n de features (18:45 CET)
- [ ] Logging de ejecuci√≥n y errores

**Input:** Configuraci√≥n de jobs en YAML

**Output:** Scheduler corriendo, datos actualizados diariamente

**Validaci√≥n:** Ejecutar manualmente, verificar datos en BD

**Pseudoc√≥digo:**
```python
# src/data/scheduler.py
class DataScheduler:
    def __init__(self, config_path: str):
        self.scheduler = BackgroundScheduler()
        self.config = load_config(config_path)
    
    def setup_jobs(self):
        # Actualizaci√≥n OHLCV (despu√©s de cierre EU)
        self.scheduler.add_job(
            self.job_update_ohlcv,
            'cron', hour=18, minute=30, timezone='Europe/Madrid',
            id='ohlcv_daily'
        )
        
        # C√°lculo de indicadores
        self.scheduler.add_job(
            self.job_calculate_indicators,
            'cron', hour=18, minute=35, timezone='Europe/Madrid',
            id='indicators_daily'
        )
        
        # Generaci√≥n de features
        self.scheduler.add_job(
            self.job_generate_features,
            'cron', hour=18, minute=45, timezone='Europe/Madrid',
            id='features_daily'
        )
    
    def job_update_ohlcv(self):
        # 1. Obtener lista de s√≠mbolos activos
        # 2. Para cada s√≠mbolo: descargar √∫ltimos 5 d√≠as
        # 3. Ingestar a TimescaleDB
        # 4. Log resultado
        pass
    
    def job_calculate_indicators(self):
        # 1. Para cada s√≠mbolo con datos nuevos
        # 2. Recalcular indicadores (√∫ltimos 250 d√≠as para ventanas largas)
        # 3. Persistir
        pass
    
    def job_generate_features(self):
        # 1. Para cada s√≠mbolo
        # 2. Generar features del d√≠a
        # 3. Guardar en Feature Store
        pass
    
    def start(self):
        self.scheduler.start()
    
    def shutdown(self):
        self.scheduler.shutdown()
```

**Config `config/scheduler.yaml`:**
```yaml
jobs:
  ohlcv_update:
    enabled: true
    hour: 18
    minute: 30
    timezone: Europe/Madrid
    
  indicators:
    enabled: true
    hour: 18
    minute: 35
    
  features:
    enabled: true
    hour: 18
    minute: 45
```

---

### Tarea 1.8: Implementar validaciones y alertas de calidad

**Estado:** ‚¨ú Pendiente

**Objetivo:** Detectar problemas de datos y alertar.

**Referencias:** Doc 2 sec 8 (calidad de datos)

**Subtareas:**
- [ ] Crear `src/data/quality.py`
- [ ] Implementar validaciones de Doc 2 sec 8.1
- [ ] Implementar checks de completitud (gaps)
- [ ] Alertas a log (Telegram en fase posterior)
- [ ] Dashboard panel de calidad en Grafana

**Input:** Datos reci√©n ingestados

**Output:** Alertas si problemas, m√©tricas a InfluxDB

**Validaci√≥n:** Insertar datos con NaN, verificar alerta generada

**Validaciones (Doc 2 sec 8.1):**

| Validaci√≥n | Severidad | Acci√≥n |
|------------|-----------|--------|
| Precio ‚â§ 0 | Error | Descartar registro |
| Volumen < 0 | Error | Descartar registro |
| Timestamp futuro | Error | Descartar registro |
| Gap > 10% vs anterior | Warning | Aceptar, marcar para revisi√≥n |
| Sin datos > 5 d√≠as | Warning | Alertar |
| NaN > 5% en features | Warning | Alertar |

**Pseudoc√≥digo:**
```python
# src/data/quality.py
class DataQualityChecker:
    def __init__(self, influx_client, alert_handler):
        self.influx = influx_client
        self.alerter = alert_handler
    
    def check_ohlcv(self, df: pd.DataFrame) -> tuple[pd.DataFrame, list[dict]]:
        # 1. Aplicar validaciones
        # 2. Separar v√°lidos de inv√°lidos
        # 3. Generar lista de issues
        # 4. Retornar (df_valid, issues)
        pass
    
    def check_features(self, df: pd.DataFrame) -> list[dict]:
        # 1. Contar NaN por columna
        # 2. Si > 5% en alguna columna -> warning
        # 3. Retornar issues
        pass
    
    def check_completeness(self, symbol: str, expected_days: int = 5) -> list[dict]:
        # 1. Query √∫ltimos N d√≠as de mercado
        # 2. Verificar que hay datos para cada d√≠a
        # 3. Retornar gaps encontrados
        pass
    
    def report_metrics(self, metrics: dict):
        # Escribir a InfluxDB para dashboard
        pass
```

---

### Tarea 1.9: Crear script de carga hist√≥rica inicial

**Estado:** ‚¨ú Pendiente

**Objetivo:** Script para poblar BD con datos hist√≥ricos (5 a√±os).

**Subtareas:**
- [ ] Crear `scripts/load_historical.py`
- [ ] Descargar 5 a√±os de cada s√≠mbolo
- [ ] Calcular todos los indicadores
- [ ] Generar features hist√≥ricos
- [ ] Progreso y logging

**Input:** Lista de s√≠mbolos, fecha inicio (2019-01-01)

**Output:** BD poblada con datos hist√≥ricos

**Validaci√≥n:** Query de 5 a√±os de SPY retorna ~1250 registros

**Pseudoc√≥digo:**
```python
# scripts/load_historical.py
def main():
    registry = SymbolRegistry('config/symbols.yaml')
    yahoo = YahooProvider()
    ingester = OHLCVIngester(db_url)
    indicator_engine = IndicatorEngine()
    feature_store = FeatureStore(...)
    
    symbols = registry.get_all()
    start_date = date(2019, 1, 1)
    end_date = date.today()
    
    for symbol in tqdm(symbols):
        logger.info(f"Procesando {symbol.ticker}...")
        
        # 1. Descargar hist√≥rico
        df = yahoo.get_historical(symbol.ticker, start_date, end_date)
        
        # 2. Ingestar OHLCV
        result = ingester.ingest(df)
        logger.info(f"  OHLCV: {result}")
        
        # 3. Calcular indicadores
        indicators = indicator_engine.calculate_all(df)
        # Persistir indicadores...
        
        # 4. Generar features
        features = feature_store.generate_features(symbol.ticker, start_date, end_date)
        feature_store.save(symbol.ticker, features)
        
        # Rate limiting
        time.sleep(1)
    
    logger.info("Carga hist√≥rica completada")

if __name__ == "__main__":
    main()
```

---

### Tarea 1.10: Crear script de verificaci√≥n de pipeline

**Estado:** ‚¨ú Pendiente

**Objetivo:** Script que valida todo el pipeline de datos.

**Subtareas:**
- [ ] Crear `scripts/verify_data_pipeline.py`
- [ ] Verificar conexi√≥n a fuentes
- [ ] Verificar datos en TimescaleDB
- [ ] Verificar indicadores calculados
- [ ] Verificar Feature Store
- [ ] Verificar scheduler configurado

**Input:** Ninguno (usa configuraci√≥n existente)

**Output:** Reporte de estado del pipeline

**Validaci√≥n:** Ejecutar despu√©s de carga hist√≥rica, todo ‚úÖ

**Pseudoc√≥digo:**
```python
# scripts/verify_data_pipeline.py
def check_yahoo_connection():
    # Intentar descargar 1 d√≠a de SPY
    pass

def check_timescale_data():
    # Contar registros en market_data.ohlcv
    # Verificar rango de fechas
    # Verificar s√≠mbolos presentes
    pass

def check_indicators():
    # Verificar que hay indicadores para s√≠mbolos con OHLCV
    # Verificar que no hay NaN excesivos
    pass

def check_feature_store():
    # Verificar que existen archivos Parquet
    # Verificar metadata en PostgreSQL
    # Test de lectura
    pass

def check_scheduler():
    # Verificar que config existe
    # Verificar que jobs est√°n definidos
    pass

def main():
    checks = [
        ("Yahoo Finance", check_yahoo_connection),
        ("TimescaleDB OHLCV", check_timescale_data),
        ("Indicadores", check_indicators),
        ("Feature Store", check_feature_store),
        ("Scheduler Config", check_scheduler),
    ]
    
    for name, check_fn in checks:
        ok, msg = check_fn()
        status = "‚úÖ" if ok else "‚ùå"
        print(f"{status} {name}: {msg}")
```

---

## 5. Dependencias Python Adicionales

A√±adir a `requirements.txt`:

```
# Data providers
yfinance>=0.2.33
ib_insync>=0.9.86

# Technical analysis
pandas-ta>=0.3.14b
# o ta-lib (requiere instalaci√≥n sistema)

# Scheduling
apscheduler>=3.10.4

# Progress bars
tqdm>=4.66.0

# Parquet
pyarrow>=14.0.0
```

---

## 6. Checklist de Finalizaci√≥n

```
Fase 1: Data Pipeline
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

[ ] Tarea 1.1: M√≥dulo de s√≠mbolos
[ ] Tarea 1.2: Conector Yahoo Finance
[ ] Tarea 1.3: Conector IBKR (b√°sico)
[ ] Tarea 1.4: Ingesta a TimescaleDB
[ ] Tarea 1.5: C√°lculo de indicadores
[ ] Tarea 1.6: Feature Store
[ ] Tarea 1.7: Scheduler de actualizaci√≥n
[ ] Tarea 1.8: Validaciones y alertas
[ ] Tarea 1.9: Carga hist√≥rica inicial
[ ] Tarea 1.10: Script de verificaci√≥n

Gate de avance:
[ ] verify_data_pipeline.py pasa 100%
[ ] 5 a√±os de datos para 20+ s√≠mbolos
[ ] Features sin NaN > 5%
[ ] Scheduler ejecuta sin errores
```

---

## 7. Troubleshooting

### Yahoo Finance rate limit

```python
# Si obtienes errores 429, aumentar delay entre requests
yahoo = YahooProvider(rate_limit=2.0)  # 2 segundos entre requests
```

### TimescaleDB hypertable no existe

```sql
-- Verificar que se cre√≥ en Fase 0
SELECT * FROM timescaledb_information.hypertables;

-- Si no existe, ejecutar init script manualmente
\i init-scripts/06_tables_market_data.sql
```

### Indicadores con NaN al inicio

Es normal: SMA(200) requiere 200 datos previos. El Feature Store debe manejar esto:
```python
# Eliminar primeras N filas donde hay NaN por ventana
df = df.dropna()
```

### IBKR no conecta

1. Verificar que TWS/Gateway est√° corriendo
2. Verificar que API est√° habilitada en TWS: File ‚Üí Global Configuration ‚Üí API
3. Verificar puerto (7497 paper, 7496 live)
4. Verificar que `client_id` no est√° en uso

---

## 8. Referencias Cruzadas

| Tema | Documento | Secci√≥n |
|------|-----------|---------|
| Esquema OHLCV | Doc 2 | 3.1 |
| Esquema indicadores | Doc 2 | 3.2 |
| Feature Store dise√±o | Doc 2 | 6 |
| Cat√°logo de features | Doc 2 | 6.2 |
| Pipeline de ingesta | Doc 2 | 7.1 |
| Validaciones calidad | Doc 2 | 8.1 |
| Scheduling | Doc 2 | 7.3 |
| Infraestructura Docker | Fase 0 | - |

---

## 9. Siguiente Fase

Una vez completada la Fase 1:
- **Verificar:** Script `verify_data_pipeline.py` pasa al 100%
- **Verificar:** Datos hist√≥ricos cargados (5 a√±os, 20+ s√≠mbolos)
- **Siguiente:** `fase_2_mcp_servers.md`
- **Paralelo posible:** Fase 2 puede comenzar antes si Fase 0 est√° completa

---

*Fase 1 - Data Pipeline*  
*Bot de Trading Aut√≥nomo con IA*
