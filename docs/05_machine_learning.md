# üß† Arquitectura T√©cnica - Documento 5/7

## Machine Learning

**Versi√≥n:** 1.0  
**Fecha:** Diciembre 2024  
**Proyecto:** Bot de Trading Aut√≥nomo con IA

---

## 1. Visi√≥n General

### 1.1 Rol del ML en el Sistema

| Componente | Modelo | Prop√≥sito |
|------------|--------|-----------|
| Predicci√≥n de retornos | TFT (Temporal Fusion Transformer) | Direcci√≥n y magnitud esperada |
| Detecci√≥n de r√©gimen | HMM (Hidden Markov Model) | Estado del mercado |
| Meta-labeling | Gradient Boosting | Filtrar se√±ales de baja calidad |
| Sentiment | FinBERT | Clasificaci√≥n de noticias |

### 1.2 Principio Fundamental

**No predecir precios exactos.** Predecir:
- Probabilidad de movimiento > X% en horizonte Y
- R√©gimen actual (trending/ranging/volatile)
- Confianza de se√±ales t√©cnicas

---

## 2. Modelos Implementados

### 2.1 Temporal Fusion Transformer (TFT)

**Uso:** Predicci√≥n probabil√≠stica de retornos a 1-5 d√≠as.

| Aspecto | Especificaci√≥n |
|---------|----------------|
| Input est√°tico | Sector, pa√≠s, market cap bucket |
| Input conocido futuro | D√≠a semana, es earnings, es festivo |
| Input observado | Features t√©cnicos (30+), ver Doc 2 sec 6.2 |
| Output | Cuantiles p10, p50, p90 de retorno |
| Horizonte | 1d, 3d, 5d (modelos separados) |

**Ventajas:** Interpretabilidad (attention weights), maneja m√∫ltiples horizontes, predicciones con incertidumbre.

**Hiperpar√°metros base:**

| Par√°metro | Valor |
|-----------|-------|
| hidden_size | 64 |
| attention_heads | 4 |
| dropout | 0.1 |
| learning_rate | 1e-3 |
| batch_size | 64 |
| max_epochs | 100 (early stopping patience=10) |

### 2.2 Hidden Markov Model (R√©gimen)

**Uso:** Detectar estado del mercado. Referencia: Doc 1, secci√≥n 4.6.

| Estado | Caracter√≠sticas observadas |
|--------|---------------------------|
| Trending Bull | ADX alto, retornos positivos, vol baja |
| Trending Bear | ADX alto, retornos negativos, vol alta |
| Range-bound | ADX bajo, retornos ~0, vol baja |
| High Volatility | VIX elevado, vol alta |

**Features de entrada:** ADX(14), retorno 20d, volatilidad 20d, VIX (si disponible).

**Output:** Probabilidad de cada estado. Usar estado con p > 0.6; si ninguno, asumir Range-bound.

### 2.3 Meta-Labeling (Filtro de Se√±ales)

**Concepto:** Modelo secundario que predice si una se√±al del modelo primario ser√° rentable.

| Aspecto | Especificaci√≥n |
|---------|----------------|
| Input | Se√±al primaria + features de contexto |
| Output | Probabilidad de trade ganador |
| Modelo | LightGBM |
| Threshold | Solo ejecutar si p > 0.55 |

**Features de contexto:**
- Confianza de se√±al primaria
- R√©gimen actual
- Volatilidad relativa (actual / media 60d)
- Distancia a soporte/resistencia
- Volumen relativo

**Beneficio:** Reduce false positives ~30%, mejora profit factor.

### 2.4 FinBERT (Sentiment)

**Uso:** Clasificar noticias. Referencia: Doc 3, secci√≥n 4.3.

| Aspecto | Especificaci√≥n |
|---------|----------------|
| Modelo base | ProsusAI/finbert |
| Input | T√≠tulo + primeras 200 palabras |
| Output | {positive, negative, neutral} + score |
| Agregaci√≥n | Media ponderada por recencia (decay 12h) |

---

## 3. Feature Engineering

### 3.1 Cat√°logo de Features

Referencia completa: Doc 2, secci√≥n 6.2. Resumen:

| Categor√≠a | Ejemplos | Count |
|-----------|----------|-------|
| Momentum | returns_1d/5d/20d, rsi_14, macd_hist | 8 |
| Volatilidad | volatility_20d, atr_14, bb_width | 5 |
| Volumen | volume_ratio_20d, obv_slope | 4 |
| Tendencia | sma_ratio_50/200, adx_14 | 5 |
| Cross-sectional | sector_momentum, market_beta_60d | 3 |
| Sentiment | news_sentiment_24h (si disponible) | 1 |
| R√©gimen | regime_probs (del HMM) | 4 |
| **Total** | | **~30** |

### 3.2 Transformaciones

| Transformaci√≥n | Aplicaci√≥n | Raz√≥n |
|----------------|------------|-------|
| Z-score rolling (60d) | Todos los features num√©ricos | Estacionariedad |
| Winsorization (1%, 99%) | Antes de z-score | Outliers |
| Log transform | Volumen, market cap | Distribuci√≥n sesgada |
| One-hot | Sector, d√≠a semana | Categ√≥ricos |

**Cr√≠tico:** Z-score debe ser rolling, NO global. Evita data leakage.

### 3.3 Labeling (Triple Barrier Method)

En lugar de clasificar retorno simple, usar triple barrier:

```
upper_barrier = entry_price * (1 + profit_target)
lower_barrier = entry_price * (1 - stop_loss)
time_barrier = entry_time + max_holding_days

Label:
  +1 si toca upper primero
  -1 si toca lower primero
   0 si expira tiempo (o precio final)
```

**Par√°metros default:** profit_target=2%, stop_loss=1%, max_days=5

---

## 4. Pipeline de Training

### 4.1 Divisi√≥n Temporal

```
2018 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 2021 ‚îÄ‚îÄ‚îÄ‚îÄ 2023 ‚îÄ‚îÄ‚îÄ‚îÄ 2024
|      TRAIN (60%)      | VAL (20%) | TEST (20%)|
                        |‚Üê embargo ‚Üí|
```

| Set | Uso | Reglas |
|-----|-----|--------|
| Train | Entrenar modelo | OK re-usar m√∫ltiples veces |
| Validation | Tuning hiperpar√°metros | Re-usar con cautela |
| Test | Evaluaci√≥n final | UNA sola vez por modelo |

**Embargo:** 5 d√≠as entre sets para evitar leakage temporal.

### 4.2 Purged K-Fold Cross-Validation

Para tuning en Train set:

| Par√°metro | Valor |
|-----------|-------|
| n_splits | 5 |
| embargo_days | 5 |
| purge_days | max(feature_lookback) |

**Proceso:** Eliminar datos en ventana de purge/embargo entre train/val de cada fold.

### 4.3 Walk-Forward Validation

Simula deployment real:

```
FOR window in rolling_windows(train_data, size=2y, step=3m):
    model = train(window)
    result = evaluate(model, next_3_months)
    results.append(result)

final_metrics = aggregate(results)
varianza = std(results)

IF varianza > 0.5 * mean(results):
    WARN "Overfitting probable"
```

### 4.4 Proceso de Training

1. **Cargar features** desde Feature Store (Doc 2, sec 6)
2. **Generar labels** con triple barrier
3. **Split temporal** con embargo
4. **Purged CV** para hiperpar√°metros (Optuna, 50 trials)
5. **Entrenar modelo final** en Train completo
6. **Evaluar en Validation**
7. **Si m√©tricas OK** ‚Üí guardar modelo versionado
8. **Test** solo cuando modelo va a producci√≥n

---

## 5. Validaci√≥n y Anti-Overfitting

### 5.1 Se√±ales de Overfitting

| Se√±al | Indicador | Acci√≥n |
|-------|-----------|--------|
| Train >> Val performance | Sharpe train 2x Sharpe val | Simplificar modelo, m√°s regularizaci√≥n |
| Alta varianza en WF | std(results) > 0.5 * mean | Reducir complejidad |
| Degradaci√≥n en producci√≥n | Live << Paper | Revertir, investigar |

### 5.2 T√©cnicas de Regularizaci√≥n

| T√©cnica | Implementaci√≥n |
|---------|----------------|
| Dropout | 0.1-0.3 en TFT |
| Early stopping | patience=10 en val loss |
| L2 regularization | weight_decay=1e-4 |
| Feature selection | Eliminar MDI < 0.01 |
| Ensemble | Bagging temporal (5 modelos, windows distintas) |

### 5.3 Calibraci√≥n de Probabilidades

**Problema:** Modelo dice "70% confianza" pero acierta solo 55%.

**M√©trica:** Expected Calibration Error (ECE)

```
ECE = Œ£ (|accuracy_bin - confidence_bin| * samples_bin / total)
```

**Target:** ECE < 0.05

**Soluci√≥n si mal calibrado:**
1. Platt scaling (regresi√≥n log√≠stica post-hoc)
2. Isotonic regression
3. Temperature scaling (para neural nets)

**Monitoreo:** Risk Manager verifica calibraci√≥n rolling 30d (Doc 1, sec 4.5).

---

## 6. MLOps Pragm√°tico

### 6.1 Fases de Madurez

Referencia: Doc 1, secci√≥n 9.

| Fase | Herramientas | Trigger |
|------|--------------|---------|
| 1 (Actual) | DVC, YAML logs, timestamps en nombres | Inicio |
| 2 | MLflow local, model registry b√°sico | 2+ modelos en prod |
| 3 | MLflow completo, A/B testing, auto-retrain | Sistema rentable |

### 6.2 Fase 1: Versionado B√°sico

**Estructura de archivos:**

```
models/
‚îú‚îÄ‚îÄ tft_1d/
‚îÇ   ‚îú‚îÄ‚îÄ v1_20241201_abc123/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model.pt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ features_used.json
‚îÇ   ‚îî‚îÄ‚îÄ v2_20241215_def456/
‚îú‚îÄ‚îÄ hmm_regime/
‚îî‚îÄ‚îÄ metalabel/
```

**Convenci√≥n de nombres:** `v{N}_{YYYYMMDD}_{hash_config[:6]}`

**Metadata m√≠nima (metrics.json):**

```json
{
  "train_period": "2018-01-01/2021-12-31",
  "val_period": "2022-01-01/2023-12-31",
  "sharpe_val": 1.23,
  "ece": 0.04,
  "feature_count": 30,
  "trained_at": "2024-12-01T10:30:00Z"
}
```

### 6.3 Retraining Schedule

| Modelo | Frecuencia | Trigger adicional |
|--------|------------|-------------------|
| TFT | Trimestral | Sharpe rolling 3m < 0.5 |
| HMM | Semestral | Cambio estructural detectado |
| Meta-label | Mensual | Win rate < 40% en mes |
| FinBERT | No retrain | Modelo pre-entrenado |

**Proceso de retrain:**

1. Incluir datos nuevos en Train
2. Mover Val antiguo a Train, nuevo per√≠odo a Val
3. Entrenar con mismos hiperpar√°metros (o re-tune si degradaci√≥n)
4. Comparar m√©tricas vs modelo actual
5. Si mejora > 5%: promover; si no: mantener actual

### 6.4 Rollback

**Criterio:** Modelo nuevo underperforma > 2 semanas en paper.

**Proceso:**
1. Revertir a versi√≥n anterior en config
2. Restart del MCP server `mcp-ml-models`
3. Log en audit con raz√≥n
4. Investigar causa antes de siguiente intento

---

## 7. Integraci√≥n con Sistema

### 7.1 MCP Server: mcp-ml-models

Referencia: Doc 3, secci√≥n 7.4.

| Tool | Input | Output |
|------|-------|--------|
| `predict` | model_name, features | prediction, confidence, calibration_score |
| `get_model_info` | model_name | version, metrics, last_trained |
| `ensemble_predict` | model_names[], features | combined_prediction, individual |
| `get_regime` | - | regime, probability, since |

### 7.2 Flujo de Predicci√≥n

```
Feature Store ‚Üí mcp-ml-models ‚Üí Technical Agent ‚Üí Orchestrator
                     ‚Üì
              Redis cache (TTL 5min)
```

**Cache:** Predicciones se cachean en Redis con TTL 5min para evitar llamadas repetidas.

### 7.3 Ejemplo de Llamada

```python
# Desde Technical Analyst Agent
response = mcp_client.call_tool(
    "mcp-ml-models",
    "predict",
    {
        "model_name": "tft_1d",
        "features": feature_vector,
        "symbol": "AAPL"
    }
)
# response: {"prediction": 0.65, "confidence": 0.72, "calibration": 0.95}
```

---

## 8. M√©tricas de Monitoreo

### 8.1 M√©tricas en Producci√≥n

| M√©trica | Frecuencia | Alerta si |
|---------|------------|-----------|
| Prediction latency | Por request | > 500ms |
| Calibration error (rolling 30d) | Diario | ECE > 0.10 |
| Feature drift | Diario | KS test p < 0.01 |
| Model staleness | Diario | > 90 d√≠as sin retrain |

### 8.2 Feature Drift Detection

Comparar distribuci√≥n de features en producci√≥n vs training:

```
FOR each feature:
    ks_stat, p_value = ks_test(prod_distribution, train_distribution)
    IF p_value < 0.01:
        ALERT f"Drift detectado en {feature}"
```

**Acci√≥n:** Si > 20% features con drift ‚Üí trigger retraining.

---

## 9. Referencias Cruzadas

| Tema | Documento | Secci√≥n |
|------|-----------|---------|
| Feature Store completo | Doc 2 | 6 |
| Cat√°logo de features | Doc 2 | 6.2 |
| R√©gimen detection uso | Doc 1 | 4.6 |
| Calibration-aware throttle | Doc 1 | 4.5 |
| MCP server tools | Doc 3 | 7.4 |
| M√©tricas de trading | Doc 4 | 3.5 |
| Estrategias que usan ML | Doc 4 | 1 |

---

*Documento 5 de 7 - Arquitectura T√©cnica del Bot de Trading*  
*Versi√≥n 1.0*
